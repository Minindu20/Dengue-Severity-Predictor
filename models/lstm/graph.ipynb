{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.566708Z",
     "start_time": "2025-02-15T13:38:30.314206Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.748349Z",
     "start_time": "2025-02-15T13:38:36.567725Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('data/final_combined_dataset.csv')",
   "id": "976294d865676d08",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.775497Z",
     "start_time": "2025-02-15T13:38:36.748891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['week'] = pd.to_numeric(df['week'], errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ],
   "id": "225dd2926b04170f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.883118Z",
     "start_time": "2025-02-15T13:38:36.777508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add date_ordinal\n",
    "df['date_ordinal'] = df['date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "# Extract year and month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Add cyclic month representation\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Add cyclic week representation\n",
    "df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52)\n",
    "df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52)"
   ],
   "id": "1daed1012eab0f29",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.903760Z",
     "start_time": "2025-02-15T13:38:36.884525Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "77ef5e34e984caf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52234 entries, 0 to 52233\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                Non-Null Count  Dtype         \n",
      "---  ------                                --------------  -----         \n",
      " 0   date                                  52234 non-null  datetime64[ns]\n",
      " 1   week                                  52234 non-null  int64         \n",
      " 2   cases                                 52234 non-null  int64         \n",
      " 3   population                            52234 non-null  int64         \n",
      " 4   tempe_min                             52234 non-null  float64       \n",
      " 5   humidity_max                          52234 non-null  float64       \n",
      " 6   humidity_avg                          52234 non-null  float64       \n",
      " 7   humidity_min                          52234 non-null  float64       \n",
      " 8   temp_avg                              52234 non-null  float64       \n",
      " 9   temp_max                              52234 non-null  float64       \n",
      " 10  city                                  52234 non-null  object        \n",
      " 11  geocode                               52234 non-null  int64         \n",
      " 12  vim                                   52234 non-null  float64       \n",
      " 13  vim_monthly                           52234 non-null  float64       \n",
      " 14  precipitation_avg_ordinary_kriging    52234 non-null  float64       \n",
      " 15  precipitation_max_ordinary_kriging    52234 non-null  float64       \n",
      " 16  precipitation_avg_regression_kriging  52234 non-null  float64       \n",
      " 17  precipitation_max_regression_kriging  52234 non-null  float64       \n",
      " 18  long                                  52234 non-null  float64       \n",
      " 19  lat                                   52234 non-null  float64       \n",
      " 20  cases_per_100k                        52234 non-null  float64       \n",
      " 21  nearby_cases_weighted                 52234 non-null  float64       \n",
      " 22  date_ordinal                          52234 non-null  int64         \n",
      " 23  year                                  52234 non-null  int32         \n",
      " 24  month                                 52234 non-null  int32         \n",
      " 25  month_sin                             52234 non-null  float64       \n",
      " 26  month_cos                             52234 non-null  float64       \n",
      " 27  week_sin                              52234 non-null  float64       \n",
      " 28  week_cos                              52234 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(20), int32(2), int64(5), object(1)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.919001Z",
     "start_time": "2025-02-15T13:38:36.904766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "geocode_list = [3303807]\n",
    "df = df[df['geocode'].isin(geocode_list)]\n",
    "df = df.drop(columns=['geocode'])"
   ],
   "id": "cef9a909215d7dff",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:36.987325Z",
     "start_time": "2025-02-15T13:38:36.920010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['cases_lag1'] = df['cases'].shift(1)\n",
    "df['cases_lag2'] = df['cases'].shift(2)\n",
    "df['cases_lag3'] = df['cases'].shift(3)\n",
    "df['cases_lag4'] = df['cases'].shift(4)\n",
    "\n",
    "# lag nearby_cases_weighted 4 weeks\n",
    "df['nearby_cases_weighted_lag1'] = df['nearby_cases_weighted'].shift(1)\n",
    "df['nearby_cases_weighted_lag2'] = df['nearby_cases_weighted'].shift(2)\n",
    "df['nearby_cases_weighted_lag3'] = df['nearby_cases_weighted'].shift(3)\n",
    "df['nearby_cases_weighted_lag4'] = df['nearby_cases_weighted'].shift(4)\n",
    "\n",
    "df"
   ],
   "id": "b1dcbd7938099e50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date    week  cases  population  tempe_min  humidity_max  \\\n",
       "0     2012-01-01  201201     32      207044  19.000000     79.428571   \n",
       "1     2012-01-08  201202     40      207044  19.714286     82.285714   \n",
       "2     2012-01-15  201203     19      207044  20.000000     83.000000   \n",
       "3     2012-01-22  201204     33      207044  19.285714     83.000000   \n",
       "4     2012-01-29  201205     36      207044  18.857143     80.857143   \n",
       "...          ...     ...    ...         ...        ...           ...   \n",
       "52229 2022-11-27  202248      1      273988  21.857143     95.875069   \n",
       "52230 2022-12-04  202249      0      273988  21.857143     92.543531   \n",
       "52231 2022-12-11  202250      2      273988  21.000000     94.213747   \n",
       "52232 2022-12-18  202251      1      273988  21.000000     91.312065   \n",
       "52233 2022-12-25  202252      0      273988  22.333333     92.282320   \n",
       "\n",
       "       humidity_avg  humidity_min   temp_avg   temp_max  ...  week_sin  \\\n",
       "0         55.514486     35.000000  25.048951  29.571429  ...  1.000000   \n",
       "1         62.357393     47.428571  23.737513  26.571429  ...  0.992709   \n",
       "2         65.236264     45.571429  24.413187  28.714286  ...  0.970942   \n",
       "3         60.362637     43.428571  24.879121  28.857143  ...  0.935016   \n",
       "4         50.885924     33.142857  25.989992  30.428571  ...  0.885456   \n",
       "...             ...           ...        ...        ...  ...       ...   \n",
       "52229     82.840922     61.313170  25.507143  30.857143  ...  0.663123   \n",
       "52230     80.151192     64.110460  24.903139  28.142857  ...  0.568065   \n",
       "52231     79.480439     59.964030  24.597222  28.500000  ...  0.464723   \n",
       "52232     84.229947     73.950180  23.184295  26.000000  ...  0.354605   \n",
       "52233     83.456510     71.528758  24.840404  27.666667  ...  0.239316   \n",
       "\n",
       "           week_cos  cases_lag1  cases_lag2  cases_lag3  cases_lag4  \\\n",
       "0      7.185429e-13         NaN         NaN         NaN         NaN   \n",
       "1     -1.205367e-01        32.0         NaN         NaN         NaN   \n",
       "2     -2.393157e-01        40.0        32.0         NaN         NaN   \n",
       "3     -3.546049e-01        19.0        40.0        32.0         NaN   \n",
       "4     -4.647232e-01        33.0        19.0        40.0        32.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "52229 -7.485107e-01         1.0         0.0         1.0         1.0   \n",
       "52230 -8.229839e-01         1.0         1.0         0.0         1.0   \n",
       "52231 -8.854560e-01         0.0         1.0         1.0         0.0   \n",
       "52232 -9.350162e-01         2.0         0.0         1.0         1.0   \n",
       "52233 -9.709418e-01         1.0         2.0         0.0         1.0   \n",
       "\n",
       "       nearby_cases_weighted_lag1  nearby_cases_weighted_lag2  \\\n",
       "0                             NaN                         NaN   \n",
       "1                        6.913995                         NaN   \n",
       "2                       32.825012                    6.913995   \n",
       "3                       14.685214                   32.825012   \n",
       "4                        2.809255                   14.685214   \n",
       "...                           ...                         ...   \n",
       "52229                    0.000000                    0.887888   \n",
       "52230                    0.000000                    0.000000   \n",
       "52231                    0.938861                    0.000000   \n",
       "52232                   12.281740                    0.938861   \n",
       "52233                    0.000000                   12.281740   \n",
       "\n",
       "       nearby_cases_weighted_lag3  nearby_cases_weighted_lag4  \n",
       "0                             NaN                         NaN  \n",
       "1                             NaN                         NaN  \n",
       "2                             NaN                         NaN  \n",
       "3                        6.913995                         NaN  \n",
       "4                       32.825012                    6.913995  \n",
       "...                           ...                         ...  \n",
       "52229                    2.076361                    0.000000  \n",
       "52230                    0.887888                    2.076361  \n",
       "52231                    0.000000                    0.887888  \n",
       "52232                    0.000000                    0.000000  \n",
       "52233                    0.938861                    0.000000  \n",
       "\n",
       "[52234 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>week</th>\n",
       "      <th>cases</th>\n",
       "      <th>population</th>\n",
       "      <th>tempe_min</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>humidity_avg</th>\n",
       "      <th>humidity_min</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>cases_lag1</th>\n",
       "      <th>cases_lag2</th>\n",
       "      <th>cases_lag3</th>\n",
       "      <th>cases_lag4</th>\n",
       "      <th>nearby_cases_weighted_lag1</th>\n",
       "      <th>nearby_cases_weighted_lag2</th>\n",
       "      <th>nearby_cases_weighted_lag3</th>\n",
       "      <th>nearby_cases_weighted_lag4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>201201</td>\n",
       "      <td>32</td>\n",
       "      <td>207044</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>79.428571</td>\n",
       "      <td>55.514486</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>25.048951</td>\n",
       "      <td>29.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.185429e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>201202</td>\n",
       "      <td>40</td>\n",
       "      <td>207044</td>\n",
       "      <td>19.714286</td>\n",
       "      <td>82.285714</td>\n",
       "      <td>62.357393</td>\n",
       "      <td>47.428571</td>\n",
       "      <td>23.737513</td>\n",
       "      <td>26.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>-1.205367e-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.913995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-15</td>\n",
       "      <td>201203</td>\n",
       "      <td>19</td>\n",
       "      <td>207044</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>65.236264</td>\n",
       "      <td>45.571429</td>\n",
       "      <td>24.413187</td>\n",
       "      <td>28.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>-2.393157e-01</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.825012</td>\n",
       "      <td>6.913995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-22</td>\n",
       "      <td>201204</td>\n",
       "      <td>33</td>\n",
       "      <td>207044</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>60.362637</td>\n",
       "      <td>43.428571</td>\n",
       "      <td>24.879121</td>\n",
       "      <td>28.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>-3.546049e-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.685214</td>\n",
       "      <td>32.825012</td>\n",
       "      <td>6.913995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>201205</td>\n",
       "      <td>36</td>\n",
       "      <td>207044</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>80.857143</td>\n",
       "      <td>50.885924</td>\n",
       "      <td>33.142857</td>\n",
       "      <td>25.989992</td>\n",
       "      <td>30.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>-4.647232e-01</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.809255</td>\n",
       "      <td>14.685214</td>\n",
       "      <td>32.825012</td>\n",
       "      <td>6.913995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52229</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>202248</td>\n",
       "      <td>1</td>\n",
       "      <td>273988</td>\n",
       "      <td>21.857143</td>\n",
       "      <td>95.875069</td>\n",
       "      <td>82.840922</td>\n",
       "      <td>61.313170</td>\n",
       "      <td>25.507143</td>\n",
       "      <td>30.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>-7.485107e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887888</td>\n",
       "      <td>2.076361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52230</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>202249</td>\n",
       "      <td>0</td>\n",
       "      <td>273988</td>\n",
       "      <td>21.857143</td>\n",
       "      <td>92.543531</td>\n",
       "      <td>80.151192</td>\n",
       "      <td>64.110460</td>\n",
       "      <td>24.903139</td>\n",
       "      <td>28.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>-8.229839e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887888</td>\n",
       "      <td>2.076361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52231</th>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>202250</td>\n",
       "      <td>2</td>\n",
       "      <td>273988</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>94.213747</td>\n",
       "      <td>79.480439</td>\n",
       "      <td>59.964030</td>\n",
       "      <td>24.597222</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>-8.854560e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52232</th>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>202251</td>\n",
       "      <td>1</td>\n",
       "      <td>273988</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>91.312065</td>\n",
       "      <td>84.229947</td>\n",
       "      <td>73.950180</td>\n",
       "      <td>23.184295</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-9.350162e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.281740</td>\n",
       "      <td>0.938861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52233</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>202252</td>\n",
       "      <td>0</td>\n",
       "      <td>273988</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>92.282320</td>\n",
       "      <td>83.456510</td>\n",
       "      <td>71.528758</td>\n",
       "      <td>24.840404</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>-9.709418e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.281740</td>\n",
       "      <td>0.938861</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52234 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.003565Z",
     "start_time": "2025-02-15T13:38:36.988335Z"
    }
   },
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "8648faeb237ab34d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                    0\n",
       "week                                    0\n",
       "cases                                   0\n",
       "population                              0\n",
       "tempe_min                               0\n",
       "humidity_max                            0\n",
       "humidity_avg                            0\n",
       "humidity_min                            0\n",
       "temp_avg                                0\n",
       "temp_max                                0\n",
       "city                                    0\n",
       "vim                                     0\n",
       "vim_monthly                             0\n",
       "precipitation_avg_ordinary_kriging      0\n",
       "precipitation_max_ordinary_kriging      0\n",
       "precipitation_avg_regression_kriging    0\n",
       "precipitation_max_regression_kriging    0\n",
       "long                                    0\n",
       "lat                                     0\n",
       "cases_per_100k                          0\n",
       "nearby_cases_weighted                   0\n",
       "date_ordinal                            0\n",
       "year                                    0\n",
       "month                                   0\n",
       "month_sin                               0\n",
       "month_cos                               0\n",
       "week_sin                                0\n",
       "week_cos                                0\n",
       "cases_lag1                              1\n",
       "cases_lag2                              2\n",
       "cases_lag3                              3\n",
       "cases_lag4                              4\n",
       "nearby_cases_weighted_lag1              1\n",
       "nearby_cases_weighted_lag2              2\n",
       "nearby_cases_weighted_lag3              3\n",
       "nearby_cases_weighted_lag4              4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.012291Z",
     "start_time": "2025-02-15T13:38:37.005575Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "bbea59b36d0ee86f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52234, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.039925Z",
     "start_time": "2025-02-15T13:38:37.017301Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.dropna()",
   "id": "ffc5df1e7be740f0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.068027Z",
     "start_time": "2025-02-15T13:38:37.041931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = df[df['date'].dt.year <= 2020]\n",
    "test_df = df[df['date'].dt.year >= 2021]\n",
    "\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ],
   "id": "6955f5a4c909df69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (42766, 36)\n",
      "Test set shape: (9464, 36)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.090003Z",
     "start_time": "2025-02-15T13:38:37.069032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train_df.drop(columns=['cases_per_100k', 'cases'])\n",
    "y_train = train_df[['cases', 'city']]\n",
    "\n",
    "X_test = test_df.drop(columns=['cases_per_100k', 'cases'])\n",
    "y_test = test_df[['cases', 'city']]\n",
    "\n",
    "test_df = test_df.iloc[4:].reset_index(drop=True)"
   ],
   "id": "31de3ec32eaba524",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.163784Z",
     "start_time": "2025-02-15T13:38:37.092034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_not_scale = ['week_sin', 'week_cos', 'month_sin', 'month_cos', 'cases', 'cases_per_100k']\n",
    "numeric_cols = [\n",
    "    col for col in df.select_dtypes(include=['float64', 'int64', 'int32']).columns\n",
    "    if col not in columns_to_not_scale\n",
    "]\n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the selected numeric features\n",
    "X_train[numeric_cols] = feature_scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = feature_scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Separate the city column from y_train and y_test (assuming 'city' is a column in y_train and y_test)\n",
    "city_train = y_train['city']\n",
    "city_test = y_test['city']\n",
    "\n",
    "# Separate the target (cases) column from y_train and y_test\n",
    "y_train_cases = y_train.drop('city', axis=1)  # Remove the 'city' column from y_train\n",
    "y_test_cases = y_test.drop('city', axis=1)  # Remove the 'city' column from y_test\n",
    "\n",
    "# Scale the target (cases) values\n",
    "y_train = target_scaler.fit_transform(y_train_cases)\n",
    "y_test = target_scaler.transform(y_test_cases)\n",
    "\n",
    "# Recombine the city column with the scaled target values\n",
    "y_train = pd.DataFrame(y_train, columns=['cases'])\n",
    "y_train['city'] = city_train.reset_index(drop=True)\n",
    "\n",
    "y_test = pd.DataFrame(y_test, columns=['cases'])\n",
    "y_test['city'] = city_test.reset_index(drop=True)"
   ],
   "id": "f6745920aeb9b516",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:37.170630Z",
     "start_time": "2025-02-15T13:38:37.165826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature columns you want to select\n",
    "feature_cols = [\n",
    "    'temp_avg', 'humidity_avg', 'cases_lag1', 'cases_lag2', 'nearby_cases_weighted_lag1', 'precipitation_max_regression_kriging', 'week_sin', 'month_sin', 'week_cos', 'month_cos']"
   ],
   "id": "391a10ddb0ac7bbd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:38:42.286227Z",
     "start_time": "2025-02-15T13:38:37.171636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to create overlapping sequences\n",
    "def create_sequences(data, target, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length].values)  # Select seq_length rows as input\n",
    "        y.append(target.iloc[i + seq_length])  # Select the next row as the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 4\n",
    "\n",
    "# Group data by city\n",
    "city_groups_xtrain = X_train.groupby('city')\n",
    "city_groups_xtest = X_test.groupby('city')\n",
    "\n",
    "city_groups_ytrain = y_train.groupby('city')\n",
    "city_groups_ytest = y_test.groupby('city')\n",
    "\n",
    "# Initialize dictionaries to store the processed data for each city\n",
    "X_train_citywise_seq = {}\n",
    "y_train_citywise_seq = {}\n",
    "X_test_citywise_seq = {}\n",
    "y_test_citywise_seq = {}\n",
    "\n",
    "# Process training data city-wise\n",
    "for city, X_train_city in city_groups_xtrain:\n",
    "    y_train_city = city_groups_ytrain.get_group(city)  # Get the corresponding target group\n",
    "    # Reset index to ensure continuous indexing\n",
    "    y_train_city = y_train_city.reset_index(drop=True)\n",
    "    X_seq, y_seq = create_sequences(X_train_city[feature_cols], y_train_city['cases'], seq_length)  # Use 'cases' as target\n",
    "    X_train_citywise_seq[city] = X_seq\n",
    "    y_train_citywise_seq[city] = y_seq\n",
    "    print(f\"Processed X_train and y_train for city: {city}, X_seq shape: {X_seq.shape}, y_seq shape: {y_seq.shape}\")\n",
    "\n",
    "# Process testing data city-wise\n",
    "for city, X_test_city in city_groups_xtest:\n",
    "    y_test_city = city_groups_ytest.get_group(city)  # Get the corresponding target group\n",
    "    # Reset index to ensure continuous indexing\n",
    "    y_test_city = y_test_city.reset_index(drop=True)\n",
    "    X_seq, y_seq = create_sequences(X_test_city[feature_cols], y_test_city['cases'], seq_length)  # Use 'cases' as target\n",
    "    X_test_citywise_seq[city] = X_seq\n",
    "    y_test_citywise_seq[city] = y_seq\n",
    "    print(f\"Processed X_test and y_test for city: {city}, X_seq shape: {X_seq.shape}, y_seq shape: {y_seq.shape}\")\n"
   ],
   "id": "d20ee8580d545799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X_train and y_train for city: angra dos reis, X_seq shape: (462, 4, 10), y_seq shape: (462,)\n",
      "Processed X_train and y_train for city: aperibé, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: araruama, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: areal, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: armação dos búzios, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: arraial do cabo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: barra do piraí, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: barra mansa, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: belford roxo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: bom jardim, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: bom jesus do itabapoana, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cabo frio, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cachoeiras de macacu, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cambuci, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: campos dos goytacazes, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cantagalo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: carapebus, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cardoso moreira, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: carmo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: casimiro de abreu, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: comendador levy gasparian, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: conceição de macabu, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: cordeiro, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: duas barras, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: duque de caxias, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: engenheiro paulo de frontin, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: guapimirim, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: iguaba grande, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: itaboraí, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: itaguaí, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: italva, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: itaocara, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: itaperuna, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: itatiaia, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: japeri, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: laje do muriaé, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: macaé, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: macuco, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: magé, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: mangaratiba, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: maricá, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: mendes, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: miguel pereira, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: miracema, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: natividade, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: nilópolis, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: niterói, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: nova friburgo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: nova iguaçu, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: paracambi, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: paraty, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: paraíba do sul, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: paty do alferes, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: petrópolis, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: pinheiral, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: piraí, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: porciúncula, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: porto real, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: quatis, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: queimados, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: quissamã, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: resende, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: rio bonito, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: rio claro, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: rio das flores, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: rio das ostras, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: rio de janeiro, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: santa maria madalena, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: santo antônio de pádua, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: sapucaia, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: saquarema, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: seropédica, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: silva jardim, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: sumidouro, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são fidélis, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são francisco de itabapoana, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são gonçalo, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são josé de ubá, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são josé do vale do rio preto, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são joão da barra, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são joão de meriti, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são pedro da aldeia, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: são sebastião do alto, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: tanguá, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: teresópolis, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: trajano de moraes, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: três rios, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: valença, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: varre-sai, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: vassouras, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_train and y_train for city: volta redonda, X_seq shape: (466, 4, 10), y_seq shape: (466,)\n",
      "Processed X_test and y_test for city: angra dos reis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: aperibé, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: araruama, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: areal, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: armação dos búzios, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: arraial do cabo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: barra do piraí, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: barra mansa, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: belford roxo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: bom jardim, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: bom jesus do itabapoana, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cabo frio, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cachoeiras de macacu, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cambuci, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: campos dos goytacazes, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cantagalo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: carapebus, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cardoso moreira, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: carmo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: casimiro de abreu, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: comendador levy gasparian, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: conceição de macabu, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: cordeiro, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: duas barras, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: duque de caxias, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: engenheiro paulo de frontin, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: guapimirim, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: iguaba grande, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: itaboraí, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: itaguaí, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: italva, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: itaocara, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: itaperuna, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: itatiaia, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: japeri, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: laje do muriaé, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: macaé, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: macuco, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: magé, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: mangaratiba, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: maricá, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: mendes, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: miguel pereira, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: miracema, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: natividade, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: nilópolis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: niterói, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: nova friburgo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: nova iguaçu, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: paracambi, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: paraty, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: paraíba do sul, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: paty do alferes, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: petrópolis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: pinheiral, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: piraí, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: porciúncula, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: porto real, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: quatis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: queimados, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: quissamã, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: resende, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: rio bonito, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: rio claro, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: rio das flores, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: rio das ostras, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: rio de janeiro, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: santa maria madalena, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: santo antônio de pádua, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: sapucaia, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: saquarema, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: seropédica, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: silva jardim, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: sumidouro, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são fidélis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são francisco de itabapoana, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são gonçalo, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são josé de ubá, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são josé do vale do rio preto, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são joão da barra, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são joão de meriti, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são pedro da aldeia, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: são sebastião do alto, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: tanguá, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: teresópolis, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: trajano de moraes, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: três rios, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: valença, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: varre-sai, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: vassouras, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n",
      "Processed X_test and y_test for city: volta redonda, X_seq shape: (100, 4, 10), y_seq shape: (100,)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:55:38.205249Z",
     "start_time": "2025-02-15T13:38:42.287251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define sequence length for LSTM\n",
    "seq_length = 4\n",
    "\n",
    "# Function to build and compile the model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)  # Predicting a single value (cases)\n",
    "    ])\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Loop through each city dataset\n",
    "city_models = {}\n",
    "city_histories = {}\n",
    "city_predictions = {}\n",
    "\n",
    "for city in X_train_citywise_seq.keys():\n",
    "    print(f\"Processing city: {city}\")\n",
    "\n",
    "    # Get city-specific data\n",
    "    X_train_city = X_train_citywise_seq[city]\n",
    "    y_train_city = y_train_citywise_seq[city]\n",
    "    X_test_city = X_test_citywise_seq[city]\n",
    "    y_test_city = y_test_citywise_seq[city]\n",
    "\n",
    "    # Ensure input shape matches the LSTM model\n",
    "    input_shape = (seq_length, X_train_city.shape[2])\n",
    "\n",
    "    # Build the model\n",
    "    model = build_lstm_model(input_shape)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_city, y_train_city,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_city, y_test_city),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_mae = model.evaluate(X_test_city, y_test_city)\n",
    "    print(f\"City: {city}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
    "\n",
    "    # Save the model for this city\n",
    "    model.save(f\"lstm_dengue_prediction_model_{city}.h5\")\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = model.predict(X_test_city)\n",
    "\n",
    "    # Store results\n",
    "    city_models[city] = model\n",
    "    city_histories[city] = history\n",
    "    city_predictions[city] = predictions\n",
    "\n",
    "    print(f\"Completed processing for city: {city}\\n\")"
   ],
   "id": "5bf58486b6ce4ea4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: angra dos reis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 50ms/step - loss: 6.2341e-04 - mae: 0.0191 - val_loss: 1.8910e-04 - val_mae: 0.0120\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.9871e-04 - mae: 0.0130 - val_loss: 5.0985e-05 - val_mae: 0.0061\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.7557e-04 - mae: 0.0102 - val_loss: 3.0141e-05 - val_mae: 0.0046\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4886e-04 - mae: 0.0086 - val_loss: 2.8090e-05 - val_mae: 0.0039\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.2187e-04 - mae: 0.0075 - val_loss: 4.1051e-05 - val_mae: 0.0047\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1471e-04 - mae: 0.0071 - val_loss: 2.3903e-05 - val_mae: 0.0035\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0466e-04 - mae: 0.0062 - val_loss: 2.1022e-05 - val_mae: 0.0031\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.0135e-05 - mae: 0.0051 - val_loss: 1.2103e-05 - val_mae: 0.0024\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.8906e-05 - mae: 0.0053 - val_loss: 1.4648e-05 - val_mae: 0.0031\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.7373e-05 - mae: 0.0054 - val_loss: 4.3945e-06 - val_mae: 0.0015\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.5778e-05 - mae: 0.0048 - val_loss: 7.4578e-06 - val_mae: 0.0023\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.3994e-05 - mae: 0.0045 - val_loss: 2.8775e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.3495e-05 - mae: 0.0042 - val_loss: 9.4411e-06 - val_mae: 0.0026\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.4446e-05 - mae: 0.0044 - val_loss: 1.5375e-05 - val_mae: 0.0035\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.1937e-05 - mae: 0.0047 - val_loss: 2.7732e-06 - val_mae: 0.0014\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0024e-05 - mae: 0.0041 - val_loss: 2.8084e-06 - val_mae: 0.0014\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.6482e-05 - mae: 0.0042 - val_loss: 6.9731e-06 - val_mae: 0.0025\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.0170e-05 - mae: 0.0045 - val_loss: 1.1555e-06 - val_mae: 6.3630e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.2466e-05 - mae: 0.0040 - val_loss: 4.9924e-06 - val_mae: 0.0020\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.8140e-05 - mae: 0.0043 - val_loss: 2.0735e-06 - val_mae: 0.0011\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8498e-05 - mae: 0.0037 - val_loss: 1.8156e-06 - val_mae: 9.6635e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.3963e-05 - mae: 0.0041 - val_loss: 1.9786e-06 - val_mae: 0.0011\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1155e-05 - mae: 0.0039 - val_loss: 5.6333e-06 - val_mae: 0.0021\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.7675e-05 - mae: 0.0044 - val_loss: 2.4170e-06 - val_mae: 0.0012\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6453e-05 - mae: 0.0039 - val_loss: 1.4200e-06 - val_mae: 6.7938e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9089e-05 - mae: 0.0035 - val_loss: 2.8382e-06 - val_mae: 0.0012\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.0265e-05 - mae: 0.0035 - val_loss: 4.8716e-06 - val_mae: 0.0019\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.9864e-05 - mae: 0.0040 - val_loss: 1.7354e-06 - val_mae: 8.3268e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7460e-05 - mae: 0.0039 - val_loss: 1.5589e-06 - val_mae: 7.0656e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.5263e-05 - mae: 0.0035 - val_loss: 2.5577e-06 - val_mae: 0.0013\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.3055e-05 - mae: 0.0037 - val_loss: 2.0582e-06 - val_mae: 0.0010\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.8801e-05 - mae: 0.0033 - val_loss: 2.4003e-06 - val_mae: 0.0011\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.4527e-05 - mae: 0.0034 - val_loss: 1.5235e-06 - val_mae: 8.2364e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.3960e-05 - mae: 0.0039 - val_loss: 2.4422e-06 - val_mae: 0.0013\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.7561e-05 - mae: 0.0040 - val_loss: 1.7192e-06 - val_mae: 7.5302e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.5804e-05 - mae: 0.0032 - val_loss: 9.1861e-06 - val_mae: 0.0027\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.0146e-05 - mae: 0.0036 - val_loss: 6.3537e-06 - val_mae: 0.0021\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.6869e-05 - mae: 0.0038 - val_loss: 2.0934e-06 - val_mae: 0.0011\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.4071e-05 - mae: 0.0040 - val_loss: 2.0034e-06 - val_mae: 9.3446e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.3401e-05 - mae: 0.0036 - val_loss: 2.2829e-06 - val_mae: 0.0012\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.0707e-05 - mae: 0.0031 - val_loss: 2.4081e-05 - val_mae: 0.0046\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.2644e-05 - mae: 0.0046 - val_loss: 2.1380e-06 - val_mae: 9.2163e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.2321e-05 - mae: 0.0037 - val_loss: 1.9788e-06 - val_mae: 8.0929e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.7770e-05 - mae: 0.0036 - val_loss: 2.7567e-06 - val_mae: 0.0012\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.9962e-05 - mae: 0.0038 - val_loss: 1.6185e-06 - val_mae: 8.1535e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.1338e-05 - mae: 0.0038 - val_loss: 1.8611e-06 - val_mae: 8.7147e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.5115e-05 - mae: 0.0039 - val_loss: 1.8242e-06 - val_mae: 7.2087e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0313e-05 - mae: 0.0042 - val_loss: 1.4679e-06 - val_mae: 7.1898e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.3243e-05 - mae: 0.0033 - val_loss: 3.4270e-06 - val_mae: 0.0015\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.5245e-05 - mae: 0.0031 - val_loss: 2.1198e-06 - val_mae: 8.1903e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.7435e-06 - mae: 7.0823e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: angra dos reis, Test Loss: 2.1197915884840768e-06, Test MAE: 0.0008190259104594588\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 85ms/step\n",
      "Completed processing for city: angra dos reis\n",
      "\n",
      "Processing city: aperibé\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 38ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 5.1908e-05 - val_mae: 0.0055\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9604e-04 - mae: 0.0139 - val_loss: 7.8736e-05 - val_mae: 0.0077\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.9912e-04 - mae: 0.0110 - val_loss: 5.6073e-05 - val_mae: 0.0059\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3576e-04 - mae: 0.0088 - val_loss: 3.0486e-05 - val_mae: 0.0045\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.7346e-05 - mae: 0.0073 - val_loss: 2.1392e-05 - val_mae: 0.0039\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7006e-05 - mae: 0.0064 - val_loss: 1.0453e-05 - val_mae: 0.0026\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.1452e-05 - mae: 0.0046 - val_loss: 5.9604e-06 - val_mae: 0.0018\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6941e-05 - mae: 0.0036 - val_loss: 5.8758e-06 - val_mae: 0.0017\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6255e-05 - mae: 0.0027 - val_loss: 4.1754e-06 - val_mae: 0.0014\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5950e-05 - mae: 0.0027 - val_loss: 4.9414e-06 - val_mae: 0.0014\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.8450e-06 - mae: 0.0019 - val_loss: 2.2848e-06 - val_mae: 9.8115e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.6749e-06 - mae: 0.0020 - val_loss: 2.2746e-06 - val_mae: 0.0011\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.8104e-06 - mae: 0.0017 - val_loss: 1.9363e-06 - val_mae: 0.0010\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.2304e-06 - mae: 0.0013 - val_loss: 3.7736e-06 - val_mae: 0.0015\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.4559e-06 - mae: 0.0013 - val_loss: 1.6917e-06 - val_mae: 7.3601e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.2520e-06 - mae: 0.0012 - val_loss: 1.6615e-06 - val_mae: 6.8843e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7194e-06 - mae: 9.1030e-04 - val_loss: 1.3503e-06 - val_mae: 0.0010\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9341e-06 - mae: 9.9098e-04 - val_loss: 2.4777e-06 - val_mae: 0.0012\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.6331e-06 - mae: 0.0010 - val_loss: 1.0236e-06 - val_mae: 8.7068e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5514e-06 - mae: 7.8441e-04 - val_loss: 2.5270e-06 - val_mae: 0.0013\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5905e-06 - mae: 0.0010 - val_loss: 7.3218e-07 - val_mae: 4.7146e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2017e-06 - mae: 7.8800e-04 - val_loss: 7.1578e-07 - val_mae: 6.8206e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4918e-06 - mae: 8.9821e-04 - val_loss: 8.9891e-07 - val_mae: 5.4373e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3211e-06 - mae: 6.7159e-04 - val_loss: 1.5418e-06 - val_mae: 9.8817e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4414e-06 - mae: 7.0230e-04 - val_loss: 7.4738e-07 - val_mae: 4.4540e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6167e-06 - mae: 6.2594e-04 - val_loss: 5.1832e-07 - val_mae: 4.3759e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3087e-06 - mae: 5.8405e-04 - val_loss: 5.1318e-07 - val_mae: 4.9671e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.7136e-06 - mae: 6.2172e-04 - val_loss: 9.0081e-07 - val_mae: 6.3950e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2707e-06 - mae: 6.5961e-04 - val_loss: 8.0326e-07 - val_mae: 8.3488e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0179e-06 - mae: 6.5908e-04 - val_loss: 1.6391e-06 - val_mae: 0.0012\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.4644e-07 - mae: 5.3514e-04 - val_loss: 5.3150e-07 - val_mae: 2.7016e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.4110e-07 - mae: 4.5565e-04 - val_loss: 1.8828e-06 - val_mae: 0.0013\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5780e-06 - mae: 7.8833e-04 - val_loss: 6.2135e-07 - val_mae: 3.8633e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6668e-06 - mae: 7.2132e-04 - val_loss: 5.5565e-07 - val_mae: 2.8904e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1398e-06 - mae: 5.3227e-04 - val_loss: 4.7211e-07 - val_mae: 4.0206e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1838e-06 - mae: 6.8127e-04 - val_loss: 1.0489e-06 - val_mae: 7.5949e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1472e-06 - mae: 5.6031e-04 - val_loss: 1.1181e-06 - val_mae: 0.0010\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.4694e-07 - mae: 7.2140e-04 - val_loss: 5.3316e-07 - val_mae: 2.6503e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4873e-06 - mae: 5.8521e-04 - val_loss: 1.3189e-06 - val_mae: 0.0011\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.5526e-06 - mae: 7.5255e-04 - val_loss: 2.2500e-06 - val_mae: 0.0013\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0356e-06 - mae: 6.3024e-04 - val_loss: 7.5234e-07 - val_mae: 5.2938e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.2771e-07 - mae: 4.6889e-04 - val_loss: 7.2332e-07 - val_mae: 7.7575e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.8945e-07 - mae: 5.8816e-04 - val_loss: 6.7652e-07 - val_mae: 7.3818e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6211e-07 - mae: 4.9427e-04 - val_loss: 5.2595e-07 - val_mae: 5.7092e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.6930e-07 - mae: 5.4411e-04 - val_loss: 6.9231e-07 - val_mae: 7.5120e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.5155e-07 - mae: 5.2859e-04 - val_loss: 4.7800e-07 - val_mae: 4.5594e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2649e-07 - mae: 4.4546e-04 - val_loss: 5.1235e-07 - val_mae: 5.4703e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.9304e-07 - mae: 5.1449e-04 - val_loss: 4.9063e-07 - val_mae: 4.9850e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.3902e-07 - mae: 4.5667e-04 - val_loss: 1.3114e-06 - val_mae: 9.1616e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.9429e-07 - mae: 5.3831e-04 - val_loss: 5.0837e-07 - val_mae: 5.3929e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8043e-07 - mae: 5.3329e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: aperibé, Test Loss: 5.083652467874344e-07, Test MAE: 0.0005392868770286441\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 98ms/step\n",
      "Completed processing for city: aperibé\n",
      "\n",
      "Processing city: araruama\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 39ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 1.3946e-04 - val_mae: 0.0101\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1659e-04 - mae: 0.0140 - val_loss: 9.0743e-05 - val_mae: 0.0080\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.8638e-04 - mae: 0.0109 - val_loss: 2.2554e-05 - val_mae: 0.0037\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 1.1864e-04 - mae: 0.0085 - val_loss: 2.7852e-05 - val_mae: 0.0043\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5245e-05 - mae: 0.0066 - val_loss: 1.0534e-05 - val_mae: 0.0025\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8022e-05 - mae: 0.0053 - val_loss: 2.6457e-05 - val_mae: 0.0043\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.2865e-05 - mae: 0.0042 - val_loss: 9.7155e-06 - val_mae: 0.0024\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3591e-05 - mae: 0.0035 - val_loss: 5.9842e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7173e-05 - mae: 0.0030 - val_loss: 1.8021e-06 - val_mae: 0.0012\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5783e-05 - mae: 0.0028 - val_loss: 4.8741e-06 - val_mae: 0.0018\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3937e-05 - mae: 0.0026 - val_loss: 9.7938e-06 - val_mae: 0.0029\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5010e-05 - mae: 0.0025 - val_loss: 1.0296e-06 - val_mae: 9.1792e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1051e-05 - mae: 0.0023 - val_loss: 5.2830e-06 - val_mae: 0.0021\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.0215e-05 - mae: 0.0021 - val_loss: 3.8822e-06 - val_mae: 0.0018\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.8936e-06 - mae: 0.0021 - val_loss: 4.8776e-06 - val_mae: 0.0021\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.9893e-06 - mae: 0.0019 - val_loss: 7.3820e-07 - val_mae: 7.6448e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.2279e-06 - mae: 0.0019 - val_loss: 4.5065e-06 - val_mae: 0.0020\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.3088e-06 - mae: 0.0018 - val_loss: 1.4677e-06 - val_mae: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8903e-06 - mae: 0.0015 - val_loss: 2.4610e-06 - val_mae: 0.0014\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.9586e-06 - mae: 0.0016 - val_loss: 4.3104e-06 - val_mae: 0.0020\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.2500e-06 - mae: 0.0017 - val_loss: 3.6565e-06 - val_mae: 0.0018\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.8284e-06 - mae: 0.0015 - val_loss: 5.2531e-07 - val_mae: 6.3175e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9600e-06 - mae: 0.0015 - val_loss: 6.1249e-07 - val_mae: 6.7315e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.6467e-06 - mae: 0.0015 - val_loss: 3.5880e-07 - val_mae: 5.3534e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.5539e-06 - mae: 0.0014 - val_loss: 1.1027e-06 - val_mae: 9.5642e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.4251e-06 - mae: 0.0016 - val_loss: 2.2924e-07 - val_mae: 4.3628e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.3924e-06 - mae: 0.0016 - val_loss: 1.7181e-07 - val_mae: 3.3090e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.8567e-06 - mae: 0.0013 - val_loss: 2.2929e-06 - val_mae: 0.0015\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.7634e-06 - mae: 0.0015 - val_loss: 9.9407e-07 - val_mae: 9.3488e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.4373e-06 - mae: 0.0015 - val_loss: 2.7434e-06 - val_mae: 0.0016\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.5981e-06 - mae: 0.0015 - val_loss: 2.4130e-07 - val_mae: 4.3609e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.8414e-06 - mae: 0.0013 - val_loss: 2.6444e-07 - val_mae: 4.5504e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.8623e-06 - mae: 0.0012 - val_loss: 1.4580e-06 - val_mae: 0.0012\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.0037e-06 - mae: 0.0013 - val_loss: 8.0315e-07 - val_mae: 8.5245e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.6502e-06 - mae: 0.0013 - val_loss: 3.0334e-07 - val_mae: 4.9548e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.6774e-06 - mae: 0.0012 - val_loss: 2.1564e-07 - val_mae: 4.1329e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.0106e-06 - mae: 0.0013 - val_loss: 2.8791e-07 - val_mae: 4.8709e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.2727e-06 - mae: 0.0011 - val_loss: 5.2094e-07 - val_mae: 6.8560e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.7545e-06 - mae: 0.0015 - val_loss: 6.8419e-07 - val_mae: 7.9772e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.2859e-06 - mae: 0.0011 - val_loss: 1.6410e-06 - val_mae: 0.0013\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.5946e-06 - mae: 0.0012 - val_loss: 7.1360e-06 - val_mae: 0.0027\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.9904e-06 - mae: 0.0016 - val_loss: 5.1872e-08 - val_mae: 2.1366e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.7991e-06 - mae: 0.0010 - val_loss: 2.9364e-06 - val_mae: 0.0017\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1487e-06 - mae: 0.0013 - val_loss: 1.3400e-07 - val_mae: 3.2916e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5339e-06 - mae: 0.0011 - val_loss: 8.6882e-08 - val_mae: 2.6865e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.6403e-06 - mae: 0.0013 - val_loss: 3.7329e-08 - val_mae: 1.3133e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5655e-06 - mae: 0.0012 - val_loss: 3.0180e-08 - val_mae: 1.5237e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8164e-06 - mae: 0.0011 - val_loss: 2.4308e-06 - val_mae: 0.0015\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.0374e-06 - mae: 0.0012 - val_loss: 7.7939e-06 - val_mae: 0.0028\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6442e-06 - mae: 0.0013 - val_loss: 3.7544e-06 - val_mae: 0.0019\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.7534e-06 - mae: 0.0019 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: araruama, Test Loss: 3.7544448332482716e-06, Test MAE: 0.0019312375225126743\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED0E4E0CC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED0E4E0CC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/4\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 284ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED0E4E0CC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED0E4E0CC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 93ms/step\n",
      "Completed processing for city: araruama\n",
      "\n",
      "Processing city: areal\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 36ms/step - loss: 8.3328e-04 - mae: 0.0218 - val_loss: 7.2048e-05 - val_mae: 0.0067\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.5766e-04 - mae: 0.0098 - val_loss: 2.2075e-05 - val_mae: 0.0043\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.0132e-04 - mae: 0.0077 - val_loss: 1.6712e-05 - val_mae: 0.0035\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.5250e-05 - mae: 0.0057 - val_loss: 1.2315e-05 - val_mae: 0.0029\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.5560e-05 - mae: 0.0053 - val_loss: 1.1002e-05 - val_mae: 0.0028\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.3191e-05 - mae: 0.0045 - val_loss: 6.5654e-06 - val_mae: 0.0022\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.5392e-05 - mae: 0.0040 - val_loss: 4.8761e-06 - val_mae: 0.0020\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.6335e-05 - mae: 0.0031 - val_loss: 6.2375e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.6000e-05 - mae: 0.0030 - val_loss: 2.8327e-06 - val_mae: 0.0013\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.2816e-05 - mae: 0.0026 - val_loss: 2.3870e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.2269e-06 - mae: 0.0022 - val_loss: 1.5281e-06 - val_mae: 8.9776e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.0765e-06 - mae: 0.0020 - val_loss: 1.1216e-06 - val_mae: 9.1978e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.2884e-06 - mae: 0.0017 - val_loss: 8.1718e-07 - val_mae: 7.6380e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.5148e-06 - mae: 0.0016 - val_loss: 8.5218e-07 - val_mae: 8.6507e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.8496e-06 - mae: 0.0018 - val_loss: 6.7955e-07 - val_mae: 5.4309e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.9298e-06 - mae: 0.0012 - val_loss: 7.1276e-07 - val_mae: 7.8213e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.6849e-06 - mae: 0.0013 - val_loss: 3.6562e-07 - val_mae: 4.8601e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.3583e-06 - mae: 0.0012 - val_loss: 7.5534e-07 - val_mae: 7.7748e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3641e-06 - mae: 0.0013 - val_loss: 3.0650e-07 - val_mae: 5.1302e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3258e-06 - mae: 0.0010 - val_loss: 2.0838e-07 - val_mae: 3.7991e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6913e-06 - mae: 0.0011 - val_loss: 4.2873e-07 - val_mae: 5.8378e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.8191e-06 - mae: 9.5490e-04 - val_loss: 5.4946e-07 - val_mae: 6.2989e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.1475e-06 - mae: 0.0010 - val_loss: 5.4366e-07 - val_mae: 6.5012e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.8972e-06 - mae: 9.3544e-04 - val_loss: 1.3071e-07 - val_mae: 3.2241e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1322e-06 - mae: 9.3859e-04 - val_loss: 5.6686e-07 - val_mae: 6.8216e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.6778e-06 - mae: 8.6216e-04 - val_loss: 2.9937e-07 - val_mae: 4.6639e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.5565e-06 - mae: 8.0906e-04 - val_loss: 2.9600e-07 - val_mae: 4.7281e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1135e-06 - mae: 8.9530e-04 - val_loss: 9.5652e-08 - val_mae: 2.6123e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.1919e-06 - mae: 7.4355e-04 - val_loss: 9.5294e-08 - val_mae: 2.5837e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4432e-06 - mae: 7.3854e-04 - val_loss: 1.1370e-06 - val_mae: 0.0010\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7258e-06 - mae: 8.9627e-04 - val_loss: 1.7934e-06 - val_mae: 0.0013\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.9011e-06 - mae: 9.3568e-04 - val_loss: 7.1733e-07 - val_mae: 8.1854e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.6135e-06 - mae: 9.0271e-04 - val_loss: 1.9353e-07 - val_mae: 3.8906e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7165e-06 - mae: 8.3484e-04 - val_loss: 8.1617e-08 - val_mae: 2.3139e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.5135e-06 - mae: 6.7712e-04 - val_loss: 6.3078e-07 - val_mae: 7.6790e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.5688e-06 - mae: 8.9721e-04 - val_loss: 2.8751e-07 - val_mae: 5.0122e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.2783e-06 - mae: 7.0108e-04 - val_loss: 3.4915e-08 - val_mae: 1.5739e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.2706e-06 - mae: 7.6352e-04 - val_loss: 1.0746e-07 - val_mae: 2.8372e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4225e-06 - mae: 8.1322e-04 - val_loss: 4.8437e-07 - val_mae: 6.7322e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.3776e-06 - mae: 7.9255e-04 - val_loss: 3.3232e-07 - val_mae: 5.5109e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.2780e-06 - mae: 7.4479e-04 - val_loss: 3.1045e-07 - val_mae: 5.3152e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2600e-06 - mae: 7.1591e-04 - val_loss: 7.0163e-07 - val_mae: 8.2133e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4168e-06 - mae: 8.2048e-04 - val_loss: 1.2071e-06 - val_mae: 0.0011\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4505e-06 - mae: 8.3879e-04 - val_loss: 5.9277e-07 - val_mae: 7.5387e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.2721e-06 - mae: 7.7050e-04 - val_loss: 2.0009e-07 - val_mae: 4.1869e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.1312e-06 - mae: 7.3163e-04 - val_loss: 1.0016e-07 - val_mae: 2.8331e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.2840e-07 - mae: 5.7836e-04 - val_loss: 6.3522e-07 - val_mae: 7.8317e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.3158e-06 - mae: 7.3920e-04 - val_loss: 7.5799e-07 - val_mae: 8.5823e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.3291e-07 - mae: 6.4602e-04 - val_loss: 1.1417e-07 - val_mae: 3.0758e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.0287e-06 - mae: 7.0215e-04 - val_loss: 1.2587e-07 - val_mae: 3.2307e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.3929e-07 - mae: 3.4093e-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: areal, Test Loss: 1.2586855291374377e-07, Test MAE: 0.0003230728325434029\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 89ms/step\n",
      "Completed processing for city: areal\n",
      "\n",
      "Processing city: armação dos búzios\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 8.3742e-05 - val_mae: 0.0077\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.3208e-04 - mae: 0.0088 - val_loss: 7.7388e-05 - val_mae: 0.0077\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.4463e-05 - mae: 0.0071 - val_loss: 1.1766e-05 - val_mae: 0.0028\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.0537e-05 - mae: 0.0056 - val_loss: 9.7780e-06 - val_mae: 0.0024\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.5766e-05 - mae: 0.0045 - val_loss: 7.3031e-06 - val_mae: 0.0020\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1491e-05 - mae: 0.0035 - val_loss: 6.7819e-06 - val_mae: 0.0020\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5444e-05 - mae: 0.0031 - val_loss: 2.0792e-06 - val_mae: 0.0012\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.3660e-05 - mae: 0.0026 - val_loss: 2.3602e-06 - val_mae: 0.0014\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4677e-05 - mae: 0.0027 - val_loss: 6.5504e-07 - val_mae: 6.4984e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.2375e-06 - mae: 0.0022 - val_loss: 9.2551e-07 - val_mae: 8.0768e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.3312e-06 - mae: 0.0021 - val_loss: 3.3825e-07 - val_mae: 4.8163e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.3977e-06 - mae: 0.0019 - val_loss: 5.0211e-07 - val_mae: 6.0406e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.0213e-06 - mae: 0.0017 - val_loss: 3.2172e-07 - val_mae: 4.3797e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6836e-06 - mae: 0.0019 - val_loss: 5.1604e-07 - val_mae: 5.4148e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5343e-06 - mae: 0.0017 - val_loss: 8.0194e-07 - val_mae: 7.3889e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.2957e-06 - mae: 0.0016 - val_loss: 1.1426e-06 - val_mae: 9.5057e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6325e-06 - mae: 0.0015 - val_loss: 5.5354e-07 - val_mae: 5.4903e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5831e-06 - mae: 0.0015 - val_loss: 2.7047e-07 - val_mae: 4.3701e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.0455e-06 - mae: 0.0015 - val_loss: 5.6741e-07 - val_mae: 6.7938e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7258e-06 - mae: 0.0012 - val_loss: 1.3468e-06 - val_mae: 0.0010\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.6199e-06 - mae: 0.0013 - val_loss: 1.6530e-06 - val_mae: 0.0012\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.0958e-06 - mae: 0.0014 - val_loss: 6.6548e-07 - val_mae: 7.3526e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.3023e-06 - mae: 0.0011 - val_loss: 2.7800e-07 - val_mae: 3.9262e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3768e-06 - mae: 0.0013 - val_loss: 2.7039e-07 - val_mae: 4.6994e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4728e-06 - mae: 0.0010 - val_loss: 2.8122e-07 - val_mae: 3.7692e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9464e-06 - mae: 0.0010 - val_loss: 2.5012e-07 - val_mae: 3.8591e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.6401e-06 - mae: 0.0011 - val_loss: 5.0452e-07 - val_mae: 5.2595e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.7188e-06 - mae: 0.0012 - val_loss: 4.3965e-07 - val_mae: 6.0805e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.9621e-06 - mae: 8.6131e-04 - val_loss: 5.3213e-07 - val_mae: 5.5427e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4698e-06 - mae: 9.0932e-04 - val_loss: 2.2613e-07 - val_mae: 4.2229e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9770e-06 - mae: 8.3168e-04 - val_loss: 8.3049e-07 - val_mae: 7.8323e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9500e-06 - mae: 8.5133e-04 - val_loss: 2.3427e-07 - val_mae: 4.3746e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.5171e-06 - mae: 8.7474e-04 - val_loss: 8.4743e-07 - val_mae: 7.9407e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4170e-06 - mae: 9.1269e-04 - val_loss: 8.4961e-07 - val_mae: 8.2956e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.2235e-06 - mae: 9.6888e-04 - val_loss: 2.7860e-07 - val_mae: 3.3769e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8695e-06 - mae: 8.2984e-04 - val_loss: 2.0754e-07 - val_mae: 3.6858e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.6507e-06 - mae: 9.1084e-04 - val_loss: 4.8899e-07 - val_mae: 6.3732e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.2786e-06 - mae: 9.6994e-04 - val_loss: 1.1947e-06 - val_mae: 9.9885e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2180e-06 - mae: 8.8408e-04 - val_loss: 1.1585e-06 - val_mae: 9.8060e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4519e-06 - mae: 8.8516e-04 - val_loss: 4.7127e-07 - val_mae: 5.3185e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.1681e-06 - mae: 7.7991e-04 - val_loss: 2.5444e-07 - val_mae: 4.6937e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6323e-06 - mae: 7.2636e-04 - val_loss: 2.2173e-07 - val_mae: 3.0868e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.6003e-06 - mae: 6.7284e-04 - val_loss: 6.3416e-07 - val_mae: 7.2005e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.2532e-06 - mae: 7.7806e-04 - val_loss: 3.3330e-07 - val_mae: 4.0515e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7493e-06 - mae: 7.5321e-04 - val_loss: 2.0699e-07 - val_mae: 3.0057e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3380e-06 - mae: 5.8415e-04 - val_loss: 1.9968e-06 - val_mae: 0.0013\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9447e-06 - mae: 8.3773e-04 - val_loss: 7.9965e-07 - val_mae: 7.8591e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7901e-06 - mae: 7.2955e-04 - val_loss: 2.1588e-07 - val_mae: 4.3193e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5831e-06 - mae: 6.8477e-04 - val_loss: 2.0666e-07 - val_mae: 2.8538e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3746e-06 - mae: 6.6470e-04 - val_loss: 7.2740e-07 - val_mae: 7.6973e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.3773e-07 - mae: 7.6557e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: armação dos búzios, Test Loss: 7.27404483313876e-07, Test MAE: 0.0007697311230003834\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 89ms/step\n",
      "Completed processing for city: armação dos búzios\n",
      "\n",
      "Processing city: arraial do cabo\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 38ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 6.9775e-05 - val_mae: 0.0069\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8206e-04 - mae: 0.0111 - val_loss: 4.3710e-05 - val_mae: 0.0051\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1712e-04 - mae: 0.0087 - val_loss: 1.2102e-05 - val_mae: 0.0026\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.7667e-05 - mae: 0.0065 - val_loss: 1.1160e-05 - val_mae: 0.0027\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9715e-05 - mae: 0.0058 - val_loss: 6.0495e-06 - val_mae: 0.0022\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6407e-05 - mae: 0.0047 - val_loss: 6.4851e-06 - val_mae: 0.0023\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.6559e-05 - mae: 0.0040 - val_loss: 5.1767e-06 - val_mae: 0.0019\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.9506e-05 - mae: 0.0040 - val_loss: 5.4235e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8930e-05 - mae: 0.0033 - val_loss: 2.6919e-06 - val_mae: 0.0013\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7021e-05 - mae: 0.0031 - val_loss: 3.9769e-06 - val_mae: 0.0017\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5638e-05 - mae: 0.0029 - val_loss: 1.8790e-06 - val_mae: 0.0012\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0012e-05 - mae: 0.0022 - val_loss: 8.3500e-07 - val_mae: 7.9629e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.2180e-06 - mae: 0.0021 - val_loss: 3.6384e-06 - val_mae: 0.0019\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.1585e-06 - mae: 0.0021 - val_loss: 4.1548e-06 - val_mae: 0.0020\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2001e-06 - mae: 0.0018 - val_loss: 7.9912e-08 - val_mae: 2.0989e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.8780e-06 - mae: 0.0017 - val_loss: 1.8614e-07 - val_mae: 3.9284e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3823e-06 - mae: 0.0015 - val_loss: 3.9064e-06 - val_mae: 0.0020\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.9101e-06 - mae: 0.0016 - val_loss: 2.6774e-06 - val_mae: 0.0016\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.6264e-06 - mae: 0.0015 - val_loss: 4.4645e-07 - val_mae: 6.3585e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6860e-06 - mae: 0.0013 - val_loss: 6.4292e-08 - val_mae: 1.8147e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6251e-06 - mae: 0.0012 - val_loss: 7.8122e-08 - val_mae: 1.9696e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4212e-06 - mae: 0.0012 - val_loss: 4.7034e-07 - val_mae: 6.3203e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4809e-06 - mae: 0.0011 - val_loss: 5.1842e-07 - val_mae: 6.6491e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3976e-06 - mae: 0.0011 - val_loss: 2.7206e-07 - val_mae: 4.3495e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0412e-06 - mae: 0.0010 - val_loss: 2.4279e-07 - val_mae: 4.3186e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.9270e-06 - mae: 0.0010 - val_loss: 4.5302e-07 - val_mae: 5.9705e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4663e-06 - mae: 0.0012 - val_loss: 1.6382e-07 - val_mae: 3.6457e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7507e-06 - mae: 0.0011 - val_loss: 7.0752e-07 - val_mae: 7.7047e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.6408e-06 - mae: 0.0011 - val_loss: 8.4319e-07 - val_mae: 8.6196e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5319e-06 - mae: 9.8472e-04 - val_loss: 7.2226e-07 - val_mae: 7.7879e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6305e-06 - mae: 9.0774e-04 - val_loss: 1.2138e-07 - val_mae: 2.8237e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9128e-06 - mae: 8.5642e-04 - val_loss: 8.4538e-07 - val_mae: 8.5062e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.8407e-06 - mae: 0.0010 - val_loss: 1.2061e-07 - val_mae: 2.9601e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.0676e-06 - mae: 0.0010 - val_loss: 8.0473e-07 - val_mae: 8.2918e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8255e-06 - mae: 9.2973e-04 - val_loss: 1.2525e-07 - val_mae: 3.3073e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2439e-06 - mae: 8.9535e-04 - val_loss: 3.1370e-07 - val_mae: 4.8929e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2200e-06 - mae: 9.4193e-04 - val_loss: 1.0848e-07 - val_mae: 2.9034e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7827e-06 - mae: 7.2596e-04 - val_loss: 2.7948e-06 - val_mae: 0.0016\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1697e-06 - mae: 0.0011 - val_loss: 3.4138e-07 - val_mae: 5.0895e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.3533e-06 - mae: 0.0010 - val_loss: 8.0054e-07 - val_mae: 8.4193e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0827e-06 - mae: 8.9407e-04 - val_loss: 2.2179e-07 - val_mae: 4.1498e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.1196e-06 - mae: 9.2066e-04 - val_loss: 3.2312e-07 - val_mae: 4.9070e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0014e-06 - mae: 7.8391e-04 - val_loss: 5.1998e-07 - val_mae: 6.6331e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.4020e-06 - mae: 8.8436e-04 - val_loss: 9.1930e-08 - val_mae: 2.3723e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0123e-06 - mae: 9.4413e-04 - val_loss: 2.1882e-06 - val_mae: 0.0015\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9198e-06 - mae: 8.8840e-04 - val_loss: 2.9744e-06 - val_mae: 0.0017\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5651e-06 - mae: 0.0010 - val_loss: 1.4226e-07 - val_mae: 3.4123e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.8653e-06 - mae: 8.9944e-04 - val_loss: 1.6345e-06 - val_mae: 0.0012\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6701e-06 - mae: 9.0426e-04 - val_loss: 1.3931e-07 - val_mae: 2.5618e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2290e-06 - mae: 7.7419e-04 - val_loss: 2.0467e-07 - val_mae: 3.6062e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7025e-07 - mae: 3.2274e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: arraial do cabo, Test Loss: 2.0466526962081844e-07, Test MAE: 0.0003606225654948503\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 144ms/step\n",
      "Completed processing for city: arraial do cabo\n",
      "\n",
      "Processing city: barra do piraí\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 46ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 1.3822e-04 - val_mae: 0.0090\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0161e-04 - mae: 0.0158 - val_loss: 2.3026e-04 - val_mae: 0.0129\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7359e-04 - mae: 0.0150 - val_loss: 7.7850e-05 - val_mae: 0.0072\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1012e-04 - mae: 0.0112 - val_loss: 2.3803e-05 - val_mae: 0.0039\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7104e-04 - mae: 0.0100 - val_loss: 7.5335e-05 - val_mae: 0.0067\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1840e-04 - mae: 0.0085 - val_loss: 2.3635e-05 - val_mae: 0.0043\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.9667e-05 - mae: 0.0069 - val_loss: 2.1795e-05 - val_mae: 0.0042\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.0445e-05 - mae: 0.0054 - val_loss: 1.6882e-05 - val_mae: 0.0036\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4108e-05 - mae: 0.0049 - val_loss: 1.3574e-05 - val_mae: 0.0032\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.2822e-05 - mae: 0.0041 - val_loss: 1.0789e-05 - val_mae: 0.0030\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6077e-05 - mae: 0.0030 - val_loss: 6.7408e-06 - val_mae: 0.0021\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4521e-05 - mae: 0.0025 - val_loss: 4.4241e-06 - val_mae: 0.0016\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.2362e-05 - mae: 0.0024 - val_loss: 2.8222e-06 - val_mae: 0.0014\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0422e-05 - mae: 0.0021 - val_loss: 3.0096e-06 - val_mae: 0.0013\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.6645e-06 - mae: 0.0018 - val_loss: 1.2333e-06 - val_mae: 8.5924e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.5292e-06 - mae: 0.0018 - val_loss: 1.0528e-06 - val_mae: 8.0794e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.1115e-06 - mae: 0.0018 - val_loss: 9.0587e-07 - val_mae: 6.6519e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.5660e-06 - mae: 0.0017 - val_loss: 7.4019e-07 - val_mae: 5.4424e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.4505e-06 - mae: 0.0017 - val_loss: 7.9951e-07 - val_mae: 7.6242e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.8176e-06 - mae: 0.0015 - val_loss: 2.3019e-06 - val_mae: 0.0015\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.2875e-06 - mae: 0.0016 - val_loss: 9.6654e-07 - val_mae: 6.0708e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2456e-05 - mae: 0.0020 - val_loss: 3.2353e-06 - val_mae: 0.0017\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.5220e-06 - mae: 0.0016 - val_loss: 6.5148e-07 - val_mae: 5.2488e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.1305e-06 - mae: 0.0013 - val_loss: 8.0559e-07 - val_mae: 4.3538e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8107e-06 - mae: 0.0013 - val_loss: 7.6024e-07 - val_mae: 7.3802e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.4354e-06 - mae: 0.0013 - val_loss: 7.3496e-07 - val_mae: 6.8630e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.3844e-06 - mae: 0.0017 - val_loss: 1.8784e-06 - val_mae: 0.0013\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.8425e-06 - mae: 0.0013 - val_loss: 1.8904e-06 - val_mae: 0.0013\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.5759e-06 - mae: 0.0014 - val_loss: 9.0543e-07 - val_mae: 4.6682e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.3816e-06 - mae: 0.0014 - val_loss: 1.0378e-06 - val_mae: 5.7755e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8704e-06 - mae: 0.0012 - val_loss: 2.7805e-06 - val_mae: 0.0016\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9675e-06 - mae: 0.0015 - val_loss: 2.2528e-06 - val_mae: 0.0015\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3816e-06 - mae: 0.0013 - val_loss: 7.0734e-07 - val_mae: 5.9570e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2465e-06 - mae: 0.0013 - val_loss: 9.9304e-07 - val_mae: 5.4439e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6090e-06 - mae: 0.0014 - val_loss: 1.2020e-06 - val_mae: 0.0010\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.0511e-06 - mae: 0.0014 - val_loss: 9.8238e-07 - val_mae: 8.9749e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6941e-06 - mae: 0.0012 - val_loss: 1.0225e-06 - val_mae: 5.7078e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.6317e-06 - mae: 0.0015 - val_loss: 7.1894e-07 - val_mae: 6.2472e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.1921e-06 - mae: 0.0014 - val_loss: 1.5327e-06 - val_mae: 0.0012\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5749e-06 - mae: 0.0015 - val_loss: 1.0224e-06 - val_mae: 9.2268e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.2160e-06 - mae: 0.0011 - val_loss: 2.1211e-06 - val_mae: 0.0014\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.2615e-06 - mae: 0.0015 - val_loss: 6.9890e-07 - val_mae: 5.5231e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.4807e-06 - mae: 0.0012 - val_loss: 6.9826e-07 - val_mae: 5.3774e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.1649e-06 - mae: 0.0011 - val_loss: 1.9186e-06 - val_mae: 0.0013\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1880e-06 - mae: 0.0014 - val_loss: 1.0464e-06 - val_mae: 5.9003e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.2430e-06 - mae: 0.0015 - val_loss: 7.0696e-07 - val_mae: 4.7404e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.8634e-06 - mae: 0.0013 - val_loss: 3.6088e-06 - val_mae: 0.0018\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7883e-06 - mae: 0.0015 - val_loss: 7.0198e-07 - val_mae: 5.4132e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3804e-06 - mae: 0.0013 - val_loss: 8.7053e-07 - val_mae: 8.1056e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9967e-06 - mae: 0.0012 - val_loss: 1.2539e-06 - val_mae: 7.4010e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8327e-06 - mae: 9.1363e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: barra do piraí, Test Loss: 1.2538928331196075e-06, Test MAE: 0.0007401028997264802\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 109ms/step\n",
      "Completed processing for city: barra do piraí\n",
      "\n",
      "Processing city: barra mansa\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - loss: 0.0018 - mae: 0.0311 - val_loss: 9.0603e-05 - val_mae: 0.0070\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.9522e-04 - mae: 0.0125 - val_loss: 1.2285e-04 - val_mae: 0.0096\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2369e-04 - mae: 0.0083 - val_loss: 1.5861e-05 - val_mae: 0.0031\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7810e-05 - mae: 0.0060 - val_loss: 1.4657e-05 - val_mae: 0.0031\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8728e-05 - mae: 0.0051 - val_loss: 1.1428e-05 - val_mae: 0.0025\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7687e-05 - mae: 0.0039 - val_loss: 3.0495e-05 - val_mae: 0.0041\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0143e-05 - mae: 0.0032 - val_loss: 1.3869e-05 - val_mae: 0.0024\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3214e-05 - mae: 0.0026 - val_loss: 1.1352e-05 - val_mae: 0.0022\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2997e-05 - mae: 0.0025 - val_loss: 6.7687e-06 - val_mae: 0.0016\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5952e-06 - mae: 0.0019 - val_loss: 3.6119e-06 - val_mae: 0.0014\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.9711e-06 - mae: 0.0021 - val_loss: 7.9829e-06 - val_mae: 0.0022\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0512e-05 - mae: 0.0021 - val_loss: 3.1861e-06 - val_mae: 9.0941e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.4681e-06 - mae: 0.0017 - val_loss: 2.7775e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1753e-05 - mae: 0.0021 - val_loss: 2.2689e-06 - val_mae: 7.5116e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6907e-06 - mae: 0.0016 - val_loss: 1.7791e-06 - val_mae: 9.6049e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.5200e-06 - mae: 0.0016 - val_loss: 1.9701e-06 - val_mae: 0.0011\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.8182e-06 - mae: 0.0015 - val_loss: 1.8155e-06 - val_mae: 0.0010\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.9687e-06 - mae: 0.0017 - val_loss: 1.7123e-06 - val_mae: 9.0385e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.6687e-06 - mae: 0.0013 - val_loss: 2.6350e-06 - val_mae: 0.0015\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.0828e-06 - mae: 0.0015 - val_loss: 1.6832e-06 - val_mae: 6.5715e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.6635e-06 - mae: 0.0013 - val_loss: 1.6957e-06 - val_mae: 6.2856e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.3020e-06 - mae: 0.0016 - val_loss: 2.0399e-06 - val_mae: 6.1064e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.7339e-06 - mae: 0.0014 - val_loss: 1.8842e-06 - val_mae: 0.0011\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.1222e-06 - mae: 0.0014 - val_loss: 1.8817e-06 - val_mae: 5.3233e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.6783e-06 - mae: 0.0014 - val_loss: 1.9152e-06 - val_mae: 5.3999e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.4279e-06 - mae: 0.0013 - val_loss: 1.9369e-06 - val_mae: 5.4756e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.1123e-06 - mae: 0.0011 - val_loss: 3.0881e-06 - val_mae: 0.0016\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.4734e-06 - mae: 0.0016 - val_loss: 1.6696e-06 - val_mae: 7.1017e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.1006e-06 - mae: 0.0012 - val_loss: 1.8986e-06 - val_mae: 0.0011\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.2535e-06 - mae: 0.0013 - val_loss: 2.1950e-06 - val_mae: 0.0013\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0187e-06 - mae: 0.0012 - val_loss: 2.0753e-06 - val_mae: 6.3900e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.1072e-06 - mae: 0.0012 - val_loss: 2.4982e-06 - val_mae: 9.1171e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8755e-06 - mae: 0.0013 - val_loss: 1.6846e-06 - val_mae: 6.5364e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9877e-06 - mae: 0.0013 - val_loss: 2.1709e-06 - val_mae: 0.0013\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6369e-06 - mae: 0.0012 - val_loss: 2.0798e-06 - val_mae: 0.0012\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.0984e-06 - mae: 0.0012 - val_loss: 4.0601e-06 - val_mae: 0.0019\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.5866e-06 - mae: 0.0013 - val_loss: 1.7049e-06 - val_mae: 6.1290e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.9858e-06 - mae: 0.0012 - val_loss: 1.7312e-06 - val_mae: 5.7738e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.1923e-06 - mae: 0.0011 - val_loss: 2.0330e-06 - val_mae: 6.0501e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.2172e-06 - mae: 8.8733e-04 - val_loss: 2.1802e-06 - val_mae: 7.1641e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.8178e-06 - mae: 0.0013 - val_loss: 2.1309e-06 - val_mae: 0.0012\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5945e-06 - mae: 0.0012 - val_loss: 1.9970e-06 - val_mae: 0.0012\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3467e-06 - mae: 0.0014 - val_loss: 1.8997e-06 - val_mae: 0.0011\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3354e-06 - mae: 0.0013 - val_loss: 2.0016e-06 - val_mae: 5.7850e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8695e-06 - mae: 0.0012 - val_loss: 2.0016e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0867e-06 - mae: 0.0012 - val_loss: 1.6684e-06 - val_mae: 7.7258e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.4277e-06 - mae: 0.0012 - val_loss: 2.1975e-06 - val_mae: 0.0013\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5148e-06 - mae: 0.0012 - val_loss: 2.5105e-06 - val_mae: 9.1845e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.6492e-06 - mae: 0.0012 - val_loss: 1.7136e-06 - val_mae: 5.9979e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.0295e-06 - mae: 0.0010 - val_loss: 1.7724e-06 - val_mae: 5.4164e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7215e-06 - mae: 7.5072e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: barra mansa, Test Loss: 1.7723821201798273e-06, Test MAE: 0.0005416430649347603\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 98ms/step\n",
      "Completed processing for city: barra mansa\n",
      "\n",
      "Processing city: belford roxo\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 39ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 1.2578e-04 - val_mae: 0.0081\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2671e-04 - mae: 0.0144 - val_loss: 7.3147e-05 - val_mae: 0.0064\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2855e-04 - mae: 0.0119 - val_loss: 2.3521e-05 - val_mae: 0.0039\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4171e-04 - mae: 0.0095 - val_loss: 3.4047e-05 - val_mae: 0.0049\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1059e-04 - mae: 0.0080 - val_loss: 7.9571e-06 - val_mae: 0.0024\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.5537e-05 - mae: 0.0064 - val_loss: 6.3074e-06 - val_mae: 0.0022\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1776e-05 - mae: 0.0050 - val_loss: 7.1573e-06 - val_mae: 0.0023\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.0307e-05 - mae: 0.0041 - val_loss: 5.0081e-06 - val_mae: 0.0018\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3460e-05 - mae: 0.0035 - val_loss: 2.8060e-06 - val_mae: 0.0014\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6616e-05 - mae: 0.0029 - val_loss: 1.1279e-05 - val_mae: 0.0029\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4299e-05 - mae: 0.0027 - val_loss: 3.0438e-06 - val_mae: 0.0014\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0538e-05 - mae: 0.0022 - val_loss: 6.0145e-06 - val_mae: 0.0020\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.5691e-06 - mae: 0.0020 - val_loss: 2.7550e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.5984e-06 - mae: 0.0017 - val_loss: 2.3468e-06 - val_mae: 0.0011\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.7354e-06 - mae: 0.0015 - val_loss: 2.1357e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.4301e-06 - mae: 0.0014 - val_loss: 2.6405e-06 - val_mae: 0.0013\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.5903e-06 - mae: 0.0014 - val_loss: 3.1853e-06 - val_mae: 0.0016\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6665e-06 - mae: 0.0014 - val_loss: 1.1979e-06 - val_mae: 8.3374e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5960e-06 - mae: 0.0012 - val_loss: 1.0139e-06 - val_mae: 7.1480e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 4.2024e-06 - mae: 0.0012 - val_loss: 1.9810e-06 - val_mae: 0.0011\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.6127e-06 - mae: 0.0014 - val_loss: 8.4330e-07 - val_mae: 6.0991e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8484e-06 - mae: 0.0012 - val_loss: 8.4341e-07 - val_mae: 6.6550e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0909e-06 - mae: 0.0011 - val_loss: 9.4662e-07 - val_mae: 7.9383e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4950e-06 - mae: 9.7830e-04 - val_loss: 6.9362e-07 - val_mae: 5.2732e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.9988e-06 - mae: 0.0012 - val_loss: 6.7530e-07 - val_mae: 5.3572e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7878e-06 - mae: 0.0010 - val_loss: 2.5547e-06 - val_mae: 0.0015\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.1886e-06 - mae: 0.0011 - val_loss: 2.0208e-06 - val_mae: 0.0013\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.8254e-06 - mae: 0.0011 - val_loss: 6.1611e-07 - val_mae: 5.4057e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3253e-06 - mae: 9.4539e-04 - val_loss: 1.4733e-06 - val_mae: 0.0011\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7221e-06 - mae: 0.0010 - val_loss: 6.0060e-07 - val_mae: 4.0922e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.0926e-06 - mae: 9.8089e-04 - val_loss: 7.1058e-07 - val_mae: 7.0380e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2246e-06 - mae: 9.4401e-04 - val_loss: 5.3721e-07 - val_mae: 4.5828e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3227e-06 - mae: 9.1453e-04 - val_loss: 6.7868e-07 - val_mae: 4.5687e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3604e-06 - mae: 9.7332e-04 - val_loss: 9.3390e-07 - val_mae: 8.6606e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6940e-06 - mae: 9.7046e-04 - val_loss: 8.0951e-07 - val_mae: 5.6558e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5764e-06 - mae: 8.2468e-04 - val_loss: 2.1216e-06 - val_mae: 0.0014\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.9898e-06 - mae: 0.0012 - val_loss: 5.3550e-07 - val_mae: 3.8999e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8701e-06 - mae: 8.4873e-04 - val_loss: 5.6041e-07 - val_mae: 5.8932e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9560e-06 - mae: 8.6763e-04 - val_loss: 6.1283e-07 - val_mae: 6.4545e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.2020e-06 - mae: 8.8174e-04 - val_loss: 2.0009e-06 - val_mae: 0.0013\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.2971e-06 - mae: 0.0010 - val_loss: 6.4535e-07 - val_mae: 6.7517e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7074e-06 - mae: 9.5745e-04 - val_loss: 9.7621e-07 - val_mae: 8.9956e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.4347e-06 - mae: 0.0010 - val_loss: 5.6749e-07 - val_mae: 3.7933e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9130e-06 - mae: 8.2958e-04 - val_loss: 5.3313e-07 - val_mae: 5.6614e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0600e-06 - mae: 8.3694e-04 - val_loss: 5.8643e-07 - val_mae: 3.8501e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.4294e-06 - mae: 8.9110e-04 - val_loss: 7.2350e-07 - val_mae: 7.3831e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.1100e-06 - mae: 9.5475e-04 - val_loss: 6.7884e-07 - val_mae: 7.0358e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4654e-06 - mae: 9.6345e-04 - val_loss: 7.9116e-07 - val_mae: 7.8591e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.8626e-06 - mae: 8.7848e-04 - val_loss: 5.1500e-07 - val_mae: 3.8085e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9687e-06 - mae: 8.2498e-04 - val_loss: 4.8804e-07 - val_mae: 4.9778e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8045e-07 - mae: 4.7709e-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: belford roxo, Test Loss: 4.88038665480417e-07, Test MAE: 0.0004977795761078596\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 104ms/step\n",
      "Completed processing for city: belford roxo\n",
      "\n",
      "Processing city: bom jardim\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 43ms/step - loss: 0.0024 - mae: 0.0330 - val_loss: 1.9411e-04 - val_mae: 0.0133\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7183e-04 - mae: 0.0156 - val_loss: 8.4906e-05 - val_mae: 0.0075\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4097e-04 - mae: 0.0124 - val_loss: 1.3911e-04 - val_mae: 0.0109\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4075e-04 - mae: 0.0092 - val_loss: 1.8785e-04 - val_mae: 0.0131\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.7588e-05 - mae: 0.0078 - val_loss: 9.5342e-06 - val_mae: 0.0029\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.3531e-05 - mae: 0.0054 - val_loss: 9.9984e-06 - val_mae: 0.0031\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4681e-05 - mae: 0.0037 - val_loss: 5.5114e-06 - val_mae: 0.0023\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6417e-05 - mae: 0.0030 - val_loss: 3.8239e-06 - val_mae: 0.0020\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0997e-05 - mae: 0.0022 - val_loss: 5.4629e-06 - val_mae: 0.0023\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.1887e-06 - mae: 0.0017 - val_loss: 1.7514e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.9478e-06 - mae: 0.0017 - val_loss: 3.4646e-06 - val_mae: 0.0019\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.3854e-06 - mae: 0.0014 - val_loss: 1.5558e-08 - val_mae: 8.4681e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.6172e-06 - mae: 0.0010 - val_loss: 1.4952e-07 - val_mae: 3.7515e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4656e-06 - mae: 0.0010 - val_loss: 9.2337e-09 - val_mae: 7.7421e-05\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4508e-06 - mae: 7.8491e-04 - val_loss: 6.9030e-07 - val_mae: 8.2573e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5473e-06 - mae: 8.6918e-04 - val_loss: 2.4876e-07 - val_mae: 4.9066e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3316e-06 - mae: 8.1200e-04 - val_loss: 2.4506e-08 - val_mae: 1.2909e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6801e-07 - mae: 4.8815e-04 - val_loss: 3.8438e-06 - val_mae: 0.0020\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5820e-06 - mae: 8.3578e-04 - val_loss: 5.1189e-08 - val_mae: 2.0920e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0097e-06 - mae: 5.7387e-04 - val_loss: 4.0035e-07 - val_mae: 6.2659e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5537e-06 - mae: 8.2768e-04 - val_loss: 2.2805e-07 - val_mae: 4.6991e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0036e-06 - mae: 6.1525e-04 - val_loss: 1.0107e-06 - val_mae: 0.0010\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.1559e-06 - mae: 8.3383e-04 - val_loss: 4.7714e-07 - val_mae: 6.8568e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.6488e-07 - mae: 6.4409e-04 - val_loss: 3.1953e-07 - val_mae: 5.5912e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9047e-06 - mae: 8.2161e-04 - val_loss: 1.1409e-08 - val_mae: 9.9956e-05\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.4260e-07 - mae: 3.9992e-04 - val_loss: 7.0372e-07 - val_mae: 8.3491e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.4572e-07 - mae: 5.5976e-04 - val_loss: 4.6805e-07 - val_mae: 6.7931e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.9354e-07 - mae: 5.2244e-04 - val_loss: 3.0255e-07 - val_mae: 5.4425e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.0560e-07 - mae: 5.5387e-04 - val_loss: 5.6433e-08 - val_mae: 2.2382e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 5.2272e-07 - mae: 4.0257e-04 - val_loss: 1.5872e-07 - val_mae: 3.8998e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5146e-06 - mae: 6.4796e-04 - val_loss: 8.4495e-08 - val_mae: 2.7931e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.5552e-07 - mae: 5.8337e-04 - val_loss: 1.6375e-07 - val_mae: 3.9688e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4.7622e-07 - mae: 4.8578e-04 - val_loss: 8.3304e-07 - val_mae: 9.0927e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.3338e-06 - mae: 7.7738e-04 - val_loss: 1.5781e-08 - val_mae: 1.1263e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4.5818e-07 - mae: 4.4515e-04 - val_loss: 1.7474e-07 - val_mae: 4.1060e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1347e-06 - mae: 5.4864e-04 - val_loss: 1.4147e-07 - val_mae: 3.6804e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.6770e-07 - mae: 5.9618e-04 - val_loss: 5.6955e-09 - val_mae: 6.9276e-05\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.9036e-07 - mae: 4.9498e-04 - val_loss: 6.4620e-09 - val_mae: 7.6780e-05\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.9775e-07 - mae: 4.6624e-04 - val_loss: 2.2321e-07 - val_mae: 4.6695e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6007e-07 - mae: 3.3927e-04 - val_loss: 7.2856e-07 - val_mae: 8.5056e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.1634e-07 - mae: 6.6644e-04 - val_loss: 6.5464e-07 - val_mae: 8.0614e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.7669e-07 - mae: 5.6117e-04 - val_loss: 8.0353e-08 - val_mae: 2.7505e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.7583e-07 - mae: 4.9396e-04 - val_loss: 3.4853e-07 - val_mae: 5.8649e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.1581e-07 - mae: 5.8140e-04 - val_loss: 2.5344e-07 - val_mae: 4.9904e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.8027e-07 - mae: 4.9412e-04 - val_loss: 2.7953e-08 - val_mae: 1.5395e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.4130e-07 - mae: 3.6510e-04 - val_loss: 8.8303e-08 - val_mae: 2.9005e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.1490e-07 - mae: 3.4165e-04 - val_loss: 4.4137e-07 - val_mae: 6.6124e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.5903e-07 - mae: 6.3304e-04 - val_loss: 1.3368e-07 - val_mae: 3.6020e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7441e-07 - mae: 4.5149e-04 - val_loss: 3.2811e-07 - val_mae: 5.6942e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4.8156e-07 - mae: 5.2982e-04 - val_loss: 1.8696e-07 - val_mae: 4.2810e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.9374e-07 - mae: 4.3551e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: bom jardim, Test Loss: 1.8695534720336582e-07, Test MAE: 0.0004280994471628219\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 125ms/step\n",
      "Completed processing for city: bom jardim\n",
      "\n",
      "Processing city: bom jesus do itabapoana\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - loss: 0.0026 - mae: 0.0354 - val_loss: 9.0401e-05 - val_mae: 0.0082\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0025e-04 - mae: 0.0108 - val_loss: 4.8050e-05 - val_mae: 0.0061\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.1317e-04 - mae: 0.0084 - val_loss: 3.1604e-05 - val_mae: 0.0050\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.7481e-05 - mae: 0.0067 - val_loss: 1.1407e-05 - val_mae: 0.0028\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5285e-05 - mae: 0.0049 - val_loss: 9.6643e-06 - val_mae: 0.0027\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8060e-05 - mae: 0.0044 - val_loss: 7.7626e-06 - val_mae: 0.0024\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8986e-05 - mae: 0.0030 - val_loss: 2.3591e-06 - val_mae: 0.0013\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7372e-05 - mae: 0.0027 - val_loss: 1.4596e-06 - val_mae: 8.4455e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9932e-05 - mae: 0.0025 - val_loss: 1.3059e-06 - val_mae: 9.0996e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6042e-05 - mae: 0.0024 - val_loss: 7.4077e-07 - val_mae: 6.7655e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.9918e-06 - mae: 0.0018 - val_loss: 1.4682e-06 - val_mae: 0.0011\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2682e-06 - mae: 0.0017 - val_loss: 3.7836e-07 - val_mae: 4.8974e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0884e-05 - mae: 0.0017 - val_loss: 1.6196e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.4757e-06 - mae: 0.0017 - val_loss: 4.8720e-07 - val_mae: 6.6689e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0531e-05 - mae: 0.0016 - val_loss: 1.8744e-07 - val_mae: 3.2058e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.2863e-06 - mae: 0.0014 - val_loss: 1.6980e-06 - val_mae: 0.0012\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8748e-06 - mae: 0.0015 - val_loss: 2.5905e-07 - val_mae: 4.9319e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.1026e-06 - mae: 0.0012 - val_loss: 1.6574e-07 - val_mae: 3.8215e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2741e-06 - mae: 0.0013 - val_loss: 4.7670e-07 - val_mae: 5.8455e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.4224e-06 - mae: 0.0015 - val_loss: 3.8532e-07 - val_mae: 5.8531e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.1551e-06 - mae: 0.0011 - val_loss: 7.0460e-07 - val_mae: 7.9035e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.1358e-06 - mae: 0.0013 - val_loss: 1.3364e-07 - val_mae: 3.5040e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.9531e-06 - mae: 0.0012 - val_loss: 2.3611e-06 - val_mae: 0.0015\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.5877e-06 - mae: 0.0015 - val_loss: 6.8874e-08 - val_mae: 2.3942e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9995e-06 - mae: 0.0011 - val_loss: 1.7309e-07 - val_mae: 3.9728e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0302e-05 - mae: 0.0014 - val_loss: 1.0516e-07 - val_mae: 3.1013e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.6712e-06 - mae: 0.0014 - val_loss: 4.4167e-06 - val_mae: 0.0021\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.2250e-06 - mae: 0.0016 - val_loss: 3.4928e-06 - val_mae: 0.0019\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.5042e-06 - mae: 0.0014 - val_loss: 2.8082e-07 - val_mae: 4.9926e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.1940e-06 - mae: 0.0011 - val_loss: 2.7140e-06 - val_mae: 0.0016\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.0558e-06 - mae: 0.0013 - val_loss: 4.6883e-08 - val_mae: 2.0387e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3501e-06 - mae: 0.0011 - val_loss: 4.3586e-06 - val_mae: 0.0021\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7160e-06 - mae: 0.0013 - val_loss: 5.0698e-07 - val_mae: 6.9586e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5322e-06 - mae: 0.0014 - val_loss: 2.4005e-08 - val_mae: 1.3207e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3760e-06 - mae: 0.0011 - val_loss: 1.2112e-07 - val_mae: 3.3456e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2194e-06 - mae: 0.0011 - val_loss: 6.4953e-07 - val_mae: 7.9664e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.2265e-06 - mae: 0.0011 - val_loss: 1.2828e-07 - val_mae: 3.4443e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2245e-06 - mae: 0.0012 - val_loss: 9.4605e-08 - val_mae: 2.9581e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9533e-06 - mae: 0.0014 - val_loss: 5.4921e-08 - val_mae: 2.2529e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7512e-06 - mae: 0.0012 - val_loss: 4.1707e-07 - val_mae: 6.3739e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5788e-06 - mae: 0.0011 - val_loss: 2.3142e-08 - val_mae: 1.1837e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.7928e-06 - mae: 0.0013 - val_loss: 3.3698e-07 - val_mae: 5.7418e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9201e-06 - mae: 0.0013 - val_loss: 1.1076e-07 - val_mae: 3.2261e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4638e-06 - mae: 0.0012 - val_loss: 6.7879e-07 - val_mae: 8.2010e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3007e-06 - mae: 0.0011 - val_loss: 1.3592e-07 - val_mae: 3.6161e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9458e-06 - mae: 0.0015 - val_loss: 7.3086e-08 - val_mae: 2.5952e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.1408e-06 - mae: 0.0012 - val_loss: 1.3600e-06 - val_mae: 0.0012\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4312e-06 - mae: 0.0012 - val_loss: 1.7392e-06 - val_mae: 0.0013\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6214e-06 - mae: 0.0014 - val_loss: 1.3236e-06 - val_mae: 0.0011\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.0732e-06 - mae: 0.0013 - val_loss: 4.8826e-08 - val_mae: 2.1101e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9082e-08 - mae: 2.1086e-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: bom jesus do itabapoana, Test Loss: 4.882623372282069e-08, Test MAE: 0.00021100661251693964\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 97ms/step\n",
      "Completed processing for city: bom jesus do itabapoana\n",
      "\n",
      "Processing city: cabo frio\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 1.0539e-04 - val_mae: 0.0081\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4894e-04 - mae: 0.0124 - val_loss: 6.7566e-05 - val_mae: 0.0068\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9196e-04 - mae: 0.0103 - val_loss: 6.6606e-05 - val_mae: 0.0070\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1959e-04 - mae: 0.0084 - val_loss: 6.1930e-05 - val_mae: 0.0068\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.8456e-05 - mae: 0.0072 - val_loss: 6.4438e-05 - val_mae: 0.0068\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.3489e-05 - mae: 0.0067 - val_loss: 3.3198e-05 - val_mae: 0.0047\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0065e-05 - mae: 0.0057 - val_loss: 2.8431e-05 - val_mae: 0.0042\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9273e-05 - mae: 0.0052 - val_loss: 1.3002e-05 - val_mae: 0.0028\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0238e-05 - mae: 0.0050 - val_loss: 1.3518e-05 - val_mae: 0.0029\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.4034e-05 - mae: 0.0043 - val_loss: 1.1036e-05 - val_mae: 0.0028\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.8030e-05 - mae: 0.0041 - val_loss: 7.8848e-06 - val_mae: 0.0019\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.4949e-05 - mae: 0.0032 - val_loss: 1.3625e-05 - val_mae: 0.0031\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2122e-05 - mae: 0.0035 - val_loss: 7.4314e-06 - val_mae: 0.0021\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4079e-05 - mae: 0.0031 - val_loss: 1.3128e-05 - val_mae: 0.0032\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.2684e-05 - mae: 0.0036 - val_loss: 2.4932e-06 - val_mae: 9.4824e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1481e-05 - mae: 0.0032 - val_loss: 6.8394e-06 - val_mae: 0.0017\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.0686e-05 - mae: 0.0037 - val_loss: 1.5112e-05 - val_mae: 0.0031\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6086e-05 - mae: 0.0031 - val_loss: 6.0943e-06 - val_mae: 0.0015\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.9668e-05 - mae: 0.0026 - val_loss: 1.4692e-05 - val_mae: 0.0032\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1213e-05 - mae: 0.0033 - val_loss: 1.3328e-05 - val_mae: 0.0031\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8714e-05 - mae: 0.0029 - val_loss: 6.4909e-06 - val_mae: 0.0017\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.3327e-05 - mae: 0.0034 - val_loss: 1.8435e-05 - val_mae: 0.0039\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0830e-05 - mae: 0.0033 - val_loss: 7.4633e-06 - val_mae: 0.0022\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2858e-05 - mae: 0.0025 - val_loss: 6.3954e-06 - val_mae: 0.0019\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.6295e-05 - mae: 0.0032 - val_loss: 3.6583e-06 - val_mae: 0.0011\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.7645e-05 - mae: 0.0031 - val_loss: 4.9048e-06 - val_mae: 0.0013\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9151e-05 - mae: 0.0029 - val_loss: 4.5834e-06 - val_mae: 0.0012\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1204e-05 - mae: 0.0029 - val_loss: 6.1060e-06 - val_mae: 0.0018\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5881e-05 - mae: 0.0027 - val_loss: 3.7811e-06 - val_mae: 0.0011\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5064e-05 - mae: 0.0030 - val_loss: 5.6813e-06 - val_mae: 0.0017\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.3528e-05 - mae: 0.0027 - val_loss: 2.2491e-06 - val_mae: 0.0012\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2483e-05 - mae: 0.0029 - val_loss: 8.3027e-06 - val_mae: 0.0024\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0114e-05 - mae: 0.0034 - val_loss: 4.9407e-06 - val_mae: 0.0016\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.3964e-05 - mae: 0.0029 - val_loss: 3.3299e-06 - val_mae: 0.0010\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6080e-05 - mae: 0.0029 - val_loss: 5.2983e-06 - val_mae: 0.0016\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5705e-05 - mae: 0.0027 - val_loss: 1.5403e-05 - val_mae: 0.0034\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0675e-05 - mae: 0.0028 - val_loss: 3.7502e-06 - val_mae: 0.0012\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1572e-05 - mae: 0.0027 - val_loss: 3.1565e-06 - val_mae: 0.0012\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.2055e-05 - mae: 0.0028 - val_loss: 4.7355e-06 - val_mae: 0.0013\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9889e-05 - mae: 0.0023 - val_loss: 7.0551e-06 - val_mae: 0.0020\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3954e-05 - mae: 0.0022 - val_loss: 4.1484e-06 - val_mae: 0.0011\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.6352e-05 - mae: 0.0025 - val_loss: 5.4376e-06 - val_mae: 0.0015\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1226e-05 - mae: 0.0025 - val_loss: 4.9327e-06 - val_mae: 0.0014\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.7953e-05 - mae: 0.0028 - val_loss: 7.8567e-06 - val_mae: 0.0020\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8755e-05 - mae: 0.0030 - val_loss: 8.1721e-06 - val_mae: 0.0020\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2628e-05 - mae: 0.0033 - val_loss: 3.2133e-06 - val_mae: 0.0015\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1528e-05 - mae: 0.0030 - val_loss: 4.3396e-06 - val_mae: 0.0013\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0966e-05 - mae: 0.0026 - val_loss: 5.4614e-06 - val_mae: 0.0014\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9856e-05 - mae: 0.0029 - val_loss: 8.5075e-06 - val_mae: 0.0023\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1001e-05 - mae: 0.0025 - val_loss: 4.5694e-06 - val_mae: 0.0012\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8942e-06 - mae: 0.0013 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cabo frio, Test Loss: 4.5693614083575085e-06, Test MAE: 0.0011660284362733364\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 98ms/step\n",
      "Completed processing for city: cabo frio\n",
      "\n",
      "Processing city: cachoeiras de macacu\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - loss: 4.8821e-04 - mae: 0.0175 - val_loss: 1.1769e-04 - val_mae: 0.0096\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.8025e-04 - mae: 0.0103 - val_loss: 4.1435e-05 - val_mae: 0.0055\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4660e-04 - mae: 0.0089 - val_loss: 1.3375e-05 - val_mae: 0.0030\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7218e-05 - mae: 0.0060 - val_loss: 6.5242e-06 - val_mae: 0.0022\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4331e-05 - mae: 0.0047 - val_loss: 2.2816e-06 - val_mae: 0.0014\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3973e-05 - mae: 0.0034 - val_loss: 3.0907e-07 - val_mae: 5.3252e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0605e-05 - mae: 0.0029 - val_loss: 4.7801e-07 - val_mae: 6.8855e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1723e-05 - mae: 0.0026 - val_loss: 1.0353e-06 - val_mae: 0.0010\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1288e-05 - mae: 0.0018 - val_loss: 3.9608e-09 - val_mae: 4.7274e-05\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1654e-05 - mae: 0.0017 - val_loss: 2.7065e-08 - val_mae: 1.5218e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3156e-05 - mae: 0.0018 - val_loss: 4.4475e-07 - val_mae: 6.6396e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.6812e-06 - mae: 0.0014 - val_loss: 6.9712e-09 - val_mae: 5.5379e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9682e-06 - mae: 0.0010 - val_loss: 3.0884e-06 - val_mae: 0.0018\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5194e-06 - mae: 0.0012 - val_loss: 1.6451e-07 - val_mae: 4.0075e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1091e-06 - mae: 0.0012 - val_loss: 6.3410e-07 - val_mae: 7.9385e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.8849e-06 - mae: 0.0014 - val_loss: 5.0424e-09 - val_mae: 6.0634e-05\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.9151e-06 - mae: 0.0012 - val_loss: 2.9676e-07 - val_mae: 5.4116e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9065e-06 - mae: 0.0012 - val_loss: 7.3654e-08 - val_mae: 2.6503e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2536e-05 - mae: 0.0014 - val_loss: 9.7724e-08 - val_mae: 3.0630e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3831e-06 - mae: 9.6786e-04 - val_loss: 4.8772e-08 - val_mae: 2.1181e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.3781e-06 - mae: 0.0011 - val_loss: 7.8113e-08 - val_mae: 2.7318e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7357e-06 - mae: 9.6374e-04 - val_loss: 1.5058e-07 - val_mae: 3.8298e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.7700e-06 - mae: 0.0013 - val_loss: 3.7189e-08 - val_mae: 1.8243e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5492e-06 - mae: 0.0010 - val_loss: 7.3662e-09 - val_mae: 5.8810e-05\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.3937e-06 - mae: 0.0012 - val_loss: 3.1203e-07 - val_mae: 5.5508e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.4704e-06 - mae: 0.0011 - val_loss: 1.2876e-08 - val_mae: 9.4695e-05\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4380e-06 - mae: 9.8908e-04 - val_loss: 3.0111e-08 - val_mae: 1.6723e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.1893e-06 - mae: 0.0011 - val_loss: 2.5264e-08 - val_mae: 1.4613e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.1345e-06 - mae: 0.0010 - val_loss: 3.4475e-06 - val_mae: 0.0019\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8249e-06 - mae: 0.0012 - val_loss: 1.3777e-07 - val_mae: 3.6587e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3544e-06 - mae: 9.4591e-04 - val_loss: 2.8085e-06 - val_mae: 0.0017\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5347e-06 - mae: 0.0011 - val_loss: 3.7248e-07 - val_mae: 6.0710e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9108e-06 - mae: 0.0010 - val_loss: 3.2938e-07 - val_mae: 5.7049e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.0301e-06 - mae: 0.0012 - val_loss: 2.8810e-08 - val_mae: 1.5779e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0296e-05 - mae: 0.0013 - val_loss: 3.1446e-07 - val_mae: 5.5727e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1378e-06 - mae: 7.6525e-04 - val_loss: 5.7403e-07 - val_mae: 7.5506e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.8378e-06 - mae: 0.0011 - val_loss: 2.5323e-06 - val_mae: 0.0016\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6396e-06 - mae: 0.0012 - val_loss: 2.5202e-08 - val_mae: 1.5285e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9479e-06 - mae: 0.0010 - val_loss: 3.1454e-08 - val_mae: 1.6595e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.2288e-06 - mae: 8.7881e-04 - val_loss: 3.1405e-06 - val_mae: 0.0018\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3053e-06 - mae: 0.0010 - val_loss: 2.2041e-06 - val_mae: 0.0015\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.4042e-06 - mae: 9.9653e-04 - val_loss: 3.9699e-09 - val_mae: 4.7737e-05\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2435e-06 - mae: 9.4154e-04 - val_loss: 1.2872e-08 - val_mae: 1.0788e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5217e-06 - mae: 8.6031e-04 - val_loss: 3.0205e-08 - val_mae: 1.6214e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.9170e-06 - mae: 6.9213e-04 - val_loss: 4.9792e-07 - val_mae: 7.0285e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.1357e-06 - mae: 0.0010 - val_loss: 8.3105e-07 - val_mae: 9.0947e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.3553e-06 - mae: 0.0011 - val_loss: 2.0928e-07 - val_mae: 4.5317e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5668e-06 - mae: 8.4900e-04 - val_loss: 1.8354e-07 - val_mae: 4.2382e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3149e-06 - mae: 8.3073e-04 - val_loss: 3.7952e-07 - val_mae: 6.1286e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9030e-06 - mae: 8.4850e-04 - val_loss: 6.2748e-08 - val_mae: 2.4390e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.6571e-08 - mae: 2.5342e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cachoeiras de macacu, Test Loss: 6.274810715467538e-08, Test MAE: 0.00024389875761698931\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 93ms/step\n",
      "Completed processing for city: cachoeiras de macacu\n",
      "\n",
      "Processing city: cambuci\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - loss: 8.5233e-04 - mae: 0.0211 - val_loss: 1.0318e-04 - val_mae: 0.0087\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1717e-04 - mae: 0.0119 - val_loss: 7.1373e-05 - val_mae: 0.0072\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2110e-04 - mae: 0.0082 - val_loss: 4.1497e-05 - val_mae: 0.0057\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5367e-05 - mae: 0.0062 - val_loss: 2.3917e-05 - val_mae: 0.0043\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1296e-05 - mae: 0.0054 - val_loss: 2.0393e-05 - val_mae: 0.0037\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6214e-05 - mae: 0.0046 - val_loss: 1.0919e-05 - val_mae: 0.0026\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4869e-05 - mae: 0.0044 - val_loss: 6.4214e-06 - val_mae: 0.0020\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6715e-05 - mae: 0.0039 - val_loss: 4.2590e-06 - val_mae: 0.0017\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5395e-05 - mae: 0.0030 - val_loss: 6.3628e-06 - val_mae: 0.0020\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4232e-05 - mae: 0.0029 - val_loss: 3.4083e-06 - val_mae: 0.0016\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3487e-05 - mae: 0.0027 - val_loss: 2.3732e-06 - val_mae: 0.0014\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.0477e-06 - mae: 0.0022 - val_loss: 2.1411e-06 - val_mae: 0.0012\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4422e-06 - mae: 0.0020 - val_loss: 3.0163e-06 - val_mae: 0.0014\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.2389e-06 - mae: 0.0020 - val_loss: 2.8958e-06 - val_mae: 0.0014\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3337e-06 - mae: 0.0018 - val_loss: 2.0738e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5498e-06 - mae: 0.0016 - val_loss: 1.4150e-06 - val_mae: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9247e-06 - mae: 0.0014 - val_loss: 1.3736e-06 - val_mae: 9.8586e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9057e-06 - mae: 0.0014 - val_loss: 1.1029e-06 - val_mae: 9.0795e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8495e-06 - mae: 0.0012 - val_loss: 1.5520e-06 - val_mae: 0.0011\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1328e-06 - mae: 0.0013 - val_loss: 1.0368e-06 - val_mae: 8.8754e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8049e-06 - mae: 0.0012 - val_loss: 9.2522e-07 - val_mae: 8.2785e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1477e-06 - mae: 0.0012 - val_loss: 8.9734e-07 - val_mae: 7.9003e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9345e-06 - mae: 0.0012 - val_loss: 9.3281e-07 - val_mae: 7.7311e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8928e-06 - mae: 9.6907e-04 - val_loss: 9.8990e-07 - val_mae: 8.5971e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9904e-06 - mae: 0.0010 - val_loss: 7.1036e-07 - val_mae: 6.9699e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1112e-06 - mae: 0.0010 - val_loss: 1.4621e-06 - val_mae: 9.2522e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8595e-06 - mae: 9.0850e-04 - val_loss: 7.7120e-07 - val_mae: 7.5773e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3936e-06 - mae: 8.3544e-04 - val_loss: 6.1208e-07 - val_mae: 6.2566e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2335e-06 - mae: 7.7775e-04 - val_loss: 1.7524e-06 - val_mae: 0.0011\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6699e-06 - mae: 9.4329e-04 - val_loss: 6.7503e-07 - val_mae: 6.0658e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2165e-06 - mae: 8.0373e-04 - val_loss: 5.1714e-07 - val_mae: 6.1606e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0599e-06 - mae: 7.3283e-04 - val_loss: 6.3194e-07 - val_mae: 6.8660e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2559e-06 - mae: 7.6792e-04 - val_loss: 4.0064e-07 - val_mae: 5.2908e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0298e-06 - mae: 7.2929e-04 - val_loss: 6.5962e-07 - val_mae: 5.6035e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8087e-06 - mae: 7.8641e-04 - val_loss: 3.9082e-07 - val_mae: 4.9918e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0267e-06 - mae: 6.9253e-04 - val_loss: 1.1219e-06 - val_mae: 9.6407e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3519e-06 - mae: 8.7376e-04 - val_loss: 6.2911e-07 - val_mae: 6.9262e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3001e-06 - mae: 7.8039e-04 - val_loss: 3.4708e-07 - val_mae: 4.6008e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2119e-06 - mae: 8.3330e-04 - val_loss: 3.5227e-07 - val_mae: 5.0651e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5449e-07 - mae: 5.9342e-04 - val_loss: 4.1961e-07 - val_mae: 5.5876e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.2074e-07 - mae: 5.9152e-04 - val_loss: 8.0136e-07 - val_mae: 7.2500e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.2790e-07 - mae: 6.5101e-04 - val_loss: 5.6464e-07 - val_mae: 6.7003e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.6518e-07 - mae: 7.6598e-04 - val_loss: 4.6982e-07 - val_mae: 6.0187e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.5301e-07 - mae: 6.5215e-04 - val_loss: 5.9552e-07 - val_mae: 6.9913e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 8.3176e-07 - mae: 7.3162e-04 - val_loss: 6.1465e-07 - val_mae: 6.1669e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.8154e-07 - mae: 7.0471e-04 - val_loss: 2.4562e-07 - val_mae: 3.7779e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.9127e-07 - mae: 6.2703e-04 - val_loss: 1.4896e-06 - val_mae: 0.0011\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3603e-06 - mae: 8.2970e-04 - val_loss: 2.0973e-07 - val_mae: 3.6837e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.7469e-07 - mae: 4.9260e-04 - val_loss: 5.1114e-07 - val_mae: 5.5571e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.3234e-07 - mae: 5.2537e-04 - val_loss: 7.5911e-07 - val_mae: 7.5026e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7323e-07 - mae: 7.7547e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cambuci, Test Loss: 7.59114868742472e-07, Test MAE: 0.0007502599037252367\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 147ms/step\n",
      "Completed processing for city: cambuci\n",
      "\n",
      "Processing city: campos dos goytacazes\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 41ms/step - loss: 9.1550e-04 - mae: 0.0203 - val_loss: 1.2383e-04 - val_mae: 0.0086\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8013e-04 - mae: 0.0125 - val_loss: 6.0272e-05 - val_mae: 0.0070\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0380e-04 - mae: 0.0109 - val_loss: 1.2989e-04 - val_mae: 0.0087\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4948e-04 - mae: 0.0112 - val_loss: 7.1673e-05 - val_mae: 0.0075\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8331e-04 - mae: 0.0098 - val_loss: 3.9890e-05 - val_mae: 0.0052\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.2095e-04 - mae: 0.0091 - val_loss: 5.0628e-05 - val_mae: 0.0055\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7529e-04 - mae: 0.0104 - val_loss: 3.9219e-05 - val_mae: 0.0047\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1770e-04 - mae: 0.0104 - val_loss: 2.9085e-05 - val_mae: 0.0041\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2822e-04 - mae: 0.0092 - val_loss: 4.2995e-05 - val_mae: 0.0047\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0228e-04 - mae: 0.0083 - val_loss: 7.3165e-05 - val_mae: 0.0066\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1667e-04 - mae: 0.0080 - val_loss: 6.3044e-05 - val_mae: 0.0059\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9267e-04 - mae: 0.0085 - val_loss: 4.5206e-05 - val_mae: 0.0046\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2201e-04 - mae: 0.0080 - val_loss: 5.9083e-05 - val_mae: 0.0054\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.2979e-04 - mae: 0.0076 - val_loss: 6.2347e-05 - val_mae: 0.0053\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.0035e-04 - mae: 0.0079 - val_loss: 9.8262e-05 - val_mae: 0.0069\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2650e-04 - mae: 0.0075 - val_loss: 7.4190e-05 - val_mae: 0.0058\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7928e-04 - mae: 0.0081 - val_loss: 4.0975e-05 - val_mae: 0.0043\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0621e-04 - mae: 0.0082 - val_loss: 4.7385e-05 - val_mae: 0.0045\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4514e-04 - mae: 0.0076 - val_loss: 1.2163e-04 - val_mae: 0.0085\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1689e-04 - mae: 0.0085 - val_loss: 8.2016e-05 - val_mae: 0.0066\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2866e-04 - mae: 0.0072 - val_loss: 9.7025e-05 - val_mae: 0.0073\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0109e-04 - mae: 0.0072 - val_loss: 6.4591e-05 - val_mae: 0.0053\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4622e-04 - mae: 0.0080 - val_loss: 7.0978e-05 - val_mae: 0.0059\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8280e-04 - mae: 0.0078 - val_loss: 4.9274e-05 - val_mae: 0.0046\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7880e-04 - mae: 0.0067 - val_loss: 9.2733e-05 - val_mae: 0.0068\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.8171e-04 - mae: 0.0090 - val_loss: 4.9910e-05 - val_mae: 0.0045\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3831e-04 - mae: 0.0070 - val_loss: 3.9275e-05 - val_mae: 0.0040\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7712e-04 - mae: 0.0064 - val_loss: 1.0604e-04 - val_mae: 0.0074\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1629e-04 - mae: 0.0070 - val_loss: 6.4814e-05 - val_mae: 0.0050\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3340e-04 - mae: 0.0069 - val_loss: 8.1742e-05 - val_mae: 0.0058\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0589e-04 - mae: 0.0070 - val_loss: 7.7321e-05 - val_mae: 0.0057\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6531e-04 - mae: 0.0072 - val_loss: 1.5683e-04 - val_mae: 0.0095\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7861e-04 - mae: 0.0083 - val_loss: 4.1732e-05 - val_mae: 0.0040\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3597e-04 - mae: 0.0079 - val_loss: 1.3411e-04 - val_mae: 0.0086\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2975e-04 - mae: 0.0083 - val_loss: 1.1181e-04 - val_mae: 0.0076\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2343e-04 - mae: 0.0073 - val_loss: 1.0140e-04 - val_mae: 0.0064\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0270e-04 - mae: 0.0079 - val_loss: 6.2456e-05 - val_mae: 0.0049\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3811e-04 - mae: 0.0060 - val_loss: 2.1348e-04 - val_mae: 0.0114\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2864e-04 - mae: 0.0074 - val_loss: 1.2234e-04 - val_mae: 0.0072\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8400e-04 - mae: 0.0081 - val_loss: 8.8958e-05 - val_mae: 0.0057\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6798e-04 - mae: 0.0076 - val_loss: 1.2566e-04 - val_mae: 0.0081\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9068e-04 - mae: 0.0069 - val_loss: 1.7509e-04 - val_mae: 0.0104\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7309e-04 - mae: 0.0069 - val_loss: 7.3777e-05 - val_mae: 0.0055\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 2.2205e-04 - mae: 0.0070 - val_loss: 9.6965e-05 - val_mae: 0.0066\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.1825e-04 - mae: 0.0070 - val_loss: 6.2738e-05 - val_mae: 0.0049\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.5993e-04 - mae: 0.0074 - val_loss: 7.3723e-05 - val_mae: 0.0054\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9146e-04 - mae: 0.0065 - val_loss: 4.4200e-05 - val_mae: 0.0041\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5038e-04 - mae: 0.0066 - val_loss: 8.3708e-05 - val_mae: 0.0059\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6483e-04 - mae: 0.0059 - val_loss: 4.7291e-05 - val_mae: 0.0044\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.7034e-04 - mae: 0.0069 - val_loss: 4.3288e-05 - val_mae: 0.0042\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0096e-05 - mae: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: campos dos goytacazes, Test Loss: 4.328843715484254e-05, Test MAE: 0.004194051492959261\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 141ms/step\n",
      "Completed processing for city: campos dos goytacazes\n",
      "\n",
      "Processing city: cantagalo\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 48ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 1.1267e-04 - val_mae: 0.0091\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5463e-04 - mae: 0.0149 - val_loss: 9.0210e-05 - val_mae: 0.0082\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1088e-04 - mae: 0.0115 - val_loss: 9.1568e-05 - val_mae: 0.0080\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8850e-04 - mae: 0.0109 - val_loss: 1.2585e-04 - val_mae: 0.0104\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5037e-04 - mae: 0.0095 - val_loss: 9.0619e-05 - val_mae: 0.0082\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1936e-04 - mae: 0.0085 - val_loss: 4.7709e-05 - val_mae: 0.0059\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.5834e-05 - mae: 0.0074 - val_loss: 3.0734e-05 - val_mae: 0.0046\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.6622e-05 - mae: 0.0065 - val_loss: 2.1322e-05 - val_mae: 0.0037\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9458e-05 - mae: 0.0055 - val_loss: 1.0795e-05 - val_mae: 0.0024\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6737e-05 - mae: 0.0052 - val_loss: 1.3395e-05 - val_mae: 0.0034\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3485e-05 - mae: 0.0042 - val_loss: 1.1379e-06 - val_mae: 7.5253e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0250e-05 - mae: 0.0032 - val_loss: 1.0944e-06 - val_mae: 9.5625e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2975e-05 - mae: 0.0034 - val_loss: 7.7633e-07 - val_mae: 8.2964e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5738e-05 - mae: 0.0024 - val_loss: 6.4698e-07 - val_mae: 7.6946e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.9942e-06 - mae: 0.0019 - val_loss: 5.3570e-07 - val_mae: 7.0125e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.1521e-06 - mae: 0.0017 - val_loss: 1.6080e-07 - val_mae: 3.7674e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0801e-06 - mae: 0.0014 - val_loss: 6.2215e-07 - val_mae: 7.6797e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8201e-06 - mae: 0.0013 - val_loss: 2.6211e-07 - val_mae: 4.9012e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.8563e-06 - mae: 0.0014 - val_loss: 9.1582e-08 - val_mae: 2.8584e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7552e-06 - mae: 0.0012 - val_loss: 2.6688e-08 - val_mae: 7.8788e-05\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.3472e-06 - mae: 0.0013 - val_loss: 1.7257e-06 - val_mae: 0.0013\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7913e-06 - mae: 0.0013 - val_loss: 2.2198e-08 - val_mae: 7.2822e-05\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2506e-06 - mae: 9.2853e-04 - val_loss: 4.0362e-07 - val_mae: 6.2361e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.6634e-06 - mae: 0.0011 - val_loss: 4.5965e-07 - val_mae: 6.6859e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.5047e-06 - mae: 9.2731e-04 - val_loss: 1.4609e-07 - val_mae: 3.6559e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5597e-06 - mae: 0.0010 - val_loss: 2.4059e-06 - val_mae: 0.0015\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0339e-06 - mae: 0.0012 - val_loss: 1.0543e-08 - val_mae: 7.8809e-05\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7543e-06 - mae: 9.5648e-04 - val_loss: 3.2306e-08 - val_mae: 1.5283e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.4425e-06 - mae: 7.8881e-04 - val_loss: 3.9651e-08 - val_mae: 1.9491e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9211e-06 - mae: 0.0010 - val_loss: 4.6137e-08 - val_mae: 1.9620e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6326e-06 - mae: 7.8549e-04 - val_loss: 2.1540e-06 - val_mae: 0.0015\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2389e-06 - mae: 0.0011 - val_loss: 8.6217e-08 - val_mae: 2.8779e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.5389e-06 - mae: 8.4616e-04 - val_loss: 1.6380e-08 - val_mae: 9.8890e-05\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.0946e-06 - mae: 8.6357e-04 - val_loss: 7.6997e-09 - val_mae: 3.9733e-05\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3262e-06 - mae: 9.0485e-04 - val_loss: 8.3284e-08 - val_mae: 2.7788e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6853e-06 - mae: 9.2495e-04 - val_loss: 9.1671e-08 - val_mae: 2.9662e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0520e-06 - mae: 7.8555e-04 - val_loss: 5.8972e-09 - val_mae: 4.6284e-05\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7263e-06 - mae: 7.4056e-04 - val_loss: 1.2637e-06 - val_mae: 0.0011\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2489e-06 - mae: 9.3956e-04 - val_loss: 1.9461e-07 - val_mae: 4.3503e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6007e-06 - mae: 0.0011 - val_loss: 3.8384e-07 - val_mae: 6.1538e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.2900e-06 - mae: 9.0020e-04 - val_loss: 5.0076e-07 - val_mae: 7.0402e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.4839e-06 - mae: 9.8340e-04 - val_loss: 5.1715e-07 - val_mae: 7.1569e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1782e-06 - mae: 8.0323e-04 - val_loss: 1.2767e-08 - val_mae: 1.0904e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4709e-06 - mae: 7.3867e-04 - val_loss: 2.6725e-08 - val_mae: 1.6094e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7089e-06 - mae: 7.2868e-04 - val_loss: 4.4048e-07 - val_mae: 6.6026e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6023e-06 - mae: 9.4502e-04 - val_loss: 3.0126e-07 - val_mae: 5.4487e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2825e-06 - mae: 9.1876e-04 - val_loss: 5.3674e-07 - val_mae: 7.2964e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.7096e-06 - mae: 9.0229e-04 - val_loss: 4.4907e-07 - val_mae: 6.6696e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1077e-06 - mae: 9.1999e-04 - val_loss: 4.0835e-06 - val_mae: 0.0020\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3587e-06 - mae: 0.0011 - val_loss: 3.1878e-08 - val_mae: 1.7595e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.2503e-08 - mae: 1.7825e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cantagalo, Test Loss: 3.187762231959823e-08, Test MAE: 0.00017594837117940187\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 150ms/step\n",
      "Completed processing for city: cantagalo\n",
      "\n",
      "Processing city: carapebus\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 59ms/step - loss: 7.5344e-04 - mae: 0.0208 - val_loss: 1.4343e-04 - val_mae: 0.0093\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9218e-04 - mae: 0.0131 - val_loss: 5.0619e-05 - val_mae: 0.0060\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6623e-04 - mae: 0.0092 - val_loss: 6.1409e-05 - val_mae: 0.0059\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.4815e-05 - mae: 0.0056 - val_loss: 1.9983e-05 - val_mae: 0.0036\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3432e-05 - mae: 0.0042 - val_loss: 8.2275e-06 - val_mae: 0.0023\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9527e-05 - mae: 0.0036 - val_loss: 5.9665e-06 - val_mae: 0.0021\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9113e-05 - mae: 0.0029 - val_loss: 6.0877e-06 - val_mae: 0.0021\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3546e-05 - mae: 0.0026 - val_loss: 3.9135e-06 - val_mae: 0.0016\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1024e-05 - mae: 0.0025 - val_loss: 5.7274e-06 - val_mae: 0.0020\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5075e-06 - mae: 0.0021 - val_loss: 2.6946e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4828e-06 - mae: 0.0020 - val_loss: 3.4867e-06 - val_mae: 0.0016\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.7232e-06 - mae: 0.0019 - val_loss: 1.5388e-06 - val_mae: 9.7962e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.8592e-06 - mae: 0.0018 - val_loss: 3.2651e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5172e-06 - mae: 0.0014 - val_loss: 1.1945e-06 - val_mae: 8.7022e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9661e-06 - mae: 0.0015 - val_loss: 9.4972e-07 - val_mae: 7.6724e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3903e-06 - mae: 0.0014 - val_loss: 1.6624e-06 - val_mae: 0.0011\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1709e-06 - mae: 0.0013 - val_loss: 1.9244e-06 - val_mae: 0.0012\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4432e-06 - mae: 0.0012 - val_loss: 6.0074e-07 - val_mae: 6.1192e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5968e-06 - mae: 0.0013 - val_loss: 5.0384e-07 - val_mae: 5.6377e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.7475e-06 - mae: 0.0013 - val_loss: 7.1342e-07 - val_mae: 7.0318e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.1105e-06 - mae: 0.0012 - val_loss: 5.8263e-07 - val_mae: 6.2446e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1330e-06 - mae: 0.0010 - val_loss: 3.3901e-07 - val_mae: 4.6716e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8480e-06 - mae: 9.8330e-04 - val_loss: 1.1954e-06 - val_mae: 9.5933e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.0507e-06 - mae: 0.0011 - val_loss: 1.4641e-06 - val_mae: 0.0011\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.8452e-06 - mae: 9.7054e-04 - val_loss: 1.9461e-06 - val_mae: 0.0013\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2314e-06 - mae: 8.4145e-04 - val_loss: 3.7192e-07 - val_mae: 5.0292e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.7924e-06 - mae: 9.0970e-04 - val_loss: 8.6396e-07 - val_mae: 8.1488e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9573e-06 - mae: 9.6538e-04 - val_loss: 1.5364e-06 - val_mae: 0.0012\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6757e-06 - mae: 9.0999e-04 - val_loss: 5.6617e-07 - val_mae: 6.5528e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2805e-06 - mae: 7.4587e-04 - val_loss: 1.9510e-06 - val_mae: 0.0013\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1129e-06 - mae: 7.0263e-04 - val_loss: 1.5022e-07 - val_mae: 3.1693e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1158e-06 - mae: 8.1920e-04 - val_loss: 1.6845e-06 - val_mae: 0.0013\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4721e-06 - mae: 8.5783e-04 - val_loss: 1.1076e-06 - val_mae: 9.9996e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7097e-06 - mae: 8.4274e-04 - val_loss: 1.8402e-07 - val_mae: 3.4873e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4943e-06 - mae: 7.8540e-04 - val_loss: 1.1699e-07 - val_mae: 2.7938e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4647e-06 - mae: 8.7604e-04 - val_loss: 2.4833e-07 - val_mae: 4.3062e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0904e-06 - mae: 7.0163e-04 - val_loss: 2.3206e-06 - val_mae: 0.0015\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3147e-06 - mae: 7.9682e-04 - val_loss: 2.1644e-07 - val_mae: 4.0660e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.9589e-07 - mae: 6.3962e-04 - val_loss: 2.7549e-07 - val_mae: 4.5574e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1079e-06 - mae: 6.6828e-04 - val_loss: 1.8046e-07 - val_mae: 3.7226e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.2944e-07 - mae: 6.2936e-04 - val_loss: 1.1833e-06 - val_mae: 0.0011\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1308e-06 - mae: 7.7830e-04 - val_loss: 1.4858e-06 - val_mae: 0.0012\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.1727e-06 - mae: 7.8259e-04 - val_loss: 6.3918e-08 - val_mae: 2.0312e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2882e-07 - mae: 5.9641e-04 - val_loss: 1.6330e-07 - val_mae: 3.5943e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.6975e-07 - mae: 6.3947e-04 - val_loss: 1.4248e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2756e-06 - mae: 7.9789e-04 - val_loss: 6.4405e-07 - val_mae: 7.6691e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0719e-06 - mae: 7.1603e-04 - val_loss: 5.1536e-07 - val_mae: 6.7849e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3112e-06 - mae: 7.3234e-04 - val_loss: 1.0393e-07 - val_mae: 2.8727e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.8570e-07 - mae: 6.5429e-04 - val_loss: 4.1253e-07 - val_mae: 6.0188e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3846e-06 - mae: 6.7158e-04 - val_loss: 9.8063e-07 - val_mae: 9.6289e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0202e-06 - mae: 9.8632e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: carapebus, Test Loss: 9.806318530536373e-07, Test MAE: 0.0009628877160139382\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 137ms/step\n",
      "Completed processing for city: carapebus\n",
      "\n",
      "Processing city: cardoso moreira\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 51ms/step - loss: 8.3107e-04 - mae: 0.0207 - val_loss: 2.0438e-05 - val_mae: 0.0036\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2398e-04 - mae: 0.0086 - val_loss: 7.1246e-06 - val_mae: 0.0021\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4211e-05 - mae: 0.0051 - val_loss: 5.2327e-06 - val_mae: 0.0018\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3275e-05 - mae: 0.0043 - val_loss: 6.2448e-06 - val_mae: 0.0020\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2090e-05 - mae: 0.0034 - val_loss: 5.0310e-06 - val_mae: 0.0019\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5364e-05 - mae: 0.0030 - val_loss: 7.6676e-06 - val_mae: 0.0025\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4780e-05 - mae: 0.0028 - val_loss: 6.7331e-06 - val_mae: 0.0023\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2042e-05 - mae: 0.0027 - val_loss: 3.4789e-06 - val_mae: 0.0017\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.0280e-05 - mae: 0.0024 - val_loss: 1.7186e-06 - val_mae: 0.0012\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.8992e-06 - mae: 0.0019 - val_loss: 1.3737e-06 - val_mae: 0.0010\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1673e-06 - mae: 0.0022 - val_loss: 9.8459e-07 - val_mae: 8.8092e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.7182e-06 - mae: 0.0020 - val_loss: 7.1513e-07 - val_mae: 7.2767e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6984e-06 - mae: 0.0018 - val_loss: 2.8774e-07 - val_mae: 4.5493e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.1940e-06 - mae: 0.0017 - val_loss: 3.1339e-07 - val_mae: 4.8343e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.7853e-06 - mae: 0.0017 - val_loss: 6.6540e-06 - val_mae: 0.0025\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.0953e-06 - mae: 0.0016 - val_loss: 2.0840e-06 - val_mae: 0.0013\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 3.9351e-06 - mae: 0.0014 - val_loss: 7.8049e-07 - val_mae: 7.6580e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4.0277e-06 - mae: 0.0015 - val_loss: 5.5745e-07 - val_mae: 5.7352e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2564e-06 - mae: 0.0014 - val_loss: 1.5764e-06 - val_mae: 0.0011\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3321e-06 - mae: 0.0011 - val_loss: 2.3634e-06 - val_mae: 0.0014\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.9413e-06 - mae: 0.0011 - val_loss: 6.9181e-07 - val_mae: 7.1058e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7453e-06 - mae: 0.0013 - val_loss: 1.7150e-06 - val_mae: 0.0012\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0791e-06 - mae: 0.0010 - val_loss: 1.9011e-06 - val_mae: 0.0013\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7420e-06 - mae: 9.7866e-04 - val_loss: 2.7832e-07 - val_mae: 4.2476e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8515e-06 - mae: 9.9520e-04 - val_loss: 2.4359e-07 - val_mae: 4.1460e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.8847e-06 - mae: 9.7975e-04 - val_loss: 6.9685e-07 - val_mae: 6.9105e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8336e-06 - mae: 9.5005e-04 - val_loss: 6.2942e-07 - val_mae: 6.4904e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4397e-06 - mae: 8.3540e-04 - val_loss: 2.6315e-07 - val_mae: 3.9051e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6712e-06 - mae: 9.0085e-04 - val_loss: 2.1291e-07 - val_mae: 3.9242e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4144e-06 - mae: 9.1902e-04 - val_loss: 1.8997e-07 - val_mae: 3.4303e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3624e-06 - mae: 8.3771e-04 - val_loss: 2.2319e-07 - val_mae: 4.0415e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.4861e-06 - mae: 8.8210e-04 - val_loss: 2.2203e-07 - val_mae: 3.4542e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7002e-06 - mae: 8.9822e-04 - val_loss: 2.8935e-07 - val_mae: 3.8720e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.5153e-07 - mae: 6.5895e-04 - val_loss: 3.5566e-07 - val_mae: 4.4654e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.3010e-07 - mae: 6.5015e-04 - val_loss: 8.7687e-07 - val_mae: 8.5066e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.3274e-07 - mae: 6.9164e-04 - val_loss: 1.5642e-07 - val_mae: 3.2457e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.3387e-07 - mae: 6.5098e-04 - val_loss: 4.2682e-07 - val_mae: 5.2765e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.5889e-07 - mae: 5.8307e-04 - val_loss: 5.6782e-07 - val_mae: 6.5461e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3391e-06 - mae: 7.1728e-04 - val_loss: 4.1558e-07 - val_mae: 5.3355e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.1468e-06 - mae: 7.0798e-04 - val_loss: 1.3498e-07 - val_mae: 3.0737e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.9310e-07 - mae: 6.7195e-04 - val_loss: 3.3360e-07 - val_mae: 4.6029e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1464e-06 - mae: 7.6414e-04 - val_loss: 1.6995e-07 - val_mae: 2.8148e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.8181e-07 - mae: 6.1459e-04 - val_loss: 1.4557e-06 - val_mae: 0.0012\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.3103e-07 - mae: 6.5121e-04 - val_loss: 2.9604e-07 - val_mae: 4.9466e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.6004e-07 - mae: 7.3411e-04 - val_loss: 7.4274e-07 - val_mae: 7.9720e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.3469e-07 - mae: 5.8869e-04 - val_loss: 7.4748e-07 - val_mae: 8.0260e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0355e-06 - mae: 8.1274e-04 - val_loss: 2.6153e-07 - val_mae: 4.0109e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.7881e-07 - mae: 6.0994e-04 - val_loss: 2.8032e-07 - val_mae: 4.8722e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.4482e-07 - mae: 6.9675e-04 - val_loss: 2.0062e-07 - val_mae: 3.2508e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.4609e-06 - mae: 6.7559e-04 - val_loss: 2.1902e-07 - val_mae: 4.2442e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.9718e-07 - mae: 3.9673e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cardoso moreira, Test Loss: 2.1901988134231942e-07, Test MAE: 0.00042442246922291815\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 152ms/step\n",
      "Completed processing for city: cardoso moreira\n",
      "\n",
      "Processing city: carmo\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.6855e-05 - val_mae: 0.0072\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7912e-04 - mae: 0.0102 - val_loss: 7.0557e-05 - val_mae: 0.0075\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1541e-04 - mae: 0.0084 - val_loss: 4.9047e-05 - val_mae: 0.0054\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.1556e-05 - mae: 0.0062 - val_loss: 2.1485e-05 - val_mae: 0.0039\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1931e-05 - mae: 0.0051 - val_loss: 1.7596e-05 - val_mae: 0.0036\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2456e-05 - mae: 0.0048 - val_loss: 1.4428e-05 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.0578e-05 - mae: 0.0042 - val_loss: 6.8051e-06 - val_mae: 0.0021\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6031e-05 - mae: 0.0039 - val_loss: 5.1733e-06 - val_mae: 0.0018\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6542e-05 - mae: 0.0031 - val_loss: 1.1048e-05 - val_mae: 0.0026\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1.4626e-05 - mae: 0.0030 - val_loss: 5.9665e-06 - val_mae: 0.0021\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.3384e-05 - mae: 0.0027 - val_loss: 6.8351e-06 - val_mae: 0.0022\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2592e-05 - mae: 0.0026 - val_loss: 7.8647e-06 - val_mae: 0.0022\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.9069e-06 - mae: 0.0023 - val_loss: 5.9336e-06 - val_mae: 0.0020\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.1725e-06 - mae: 0.0021 - val_loss: 4.5117e-06 - val_mae: 0.0019\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7633e-06 - mae: 0.0019 - val_loss: 7.6828e-06 - val_mae: 0.0022\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6468e-06 - mae: 0.0018 - val_loss: 4.0928e-06 - val_mae: 0.0017\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6663e-06 - mae: 0.0016 - val_loss: 3.2840e-06 - val_mae: 0.0016\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6288e-06 - mae: 0.0016 - val_loss: 4.2369e-06 - val_mae: 0.0017\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0483e-06 - mae: 0.0017 - val_loss: 2.5277e-06 - val_mae: 0.0014\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.1192e-06 - mae: 0.0016 - val_loss: 2.9973e-06 - val_mae: 0.0014\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9570e-06 - mae: 0.0013 - val_loss: 6.6049e-06 - val_mae: 0.0021\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.6576e-06 - mae: 0.0017 - val_loss: 2.6261e-06 - val_mae: 0.0014\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5578e-06 - mae: 0.0013 - val_loss: 2.4753e-06 - val_mae: 0.0013\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5066e-06 - mae: 0.0014 - val_loss: 1.9354e-06 - val_mae: 0.0012\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3357e-06 - mae: 0.0012 - val_loss: 1.7729e-06 - val_mae: 0.0012\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9576e-06 - mae: 0.0012 - val_loss: 1.7195e-06 - val_mae: 0.0011\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0258e-06 - mae: 0.0013 - val_loss: 1.4251e-06 - val_mae: 0.0010\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6954e-06 - mae: 0.0013 - val_loss: 1.9881e-06 - val_mae: 0.0012\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0895e-06 - mae: 0.0012 - val_loss: 1.3466e-06 - val_mae: 9.6139e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0983e-06 - mae: 9.6439e-04 - val_loss: 1.8877e-06 - val_mae: 0.0012\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8092e-06 - mae: 0.0011 - val_loss: 1.3821e-06 - val_mae: 0.0010\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1975e-06 - mae: 0.0010 - val_loss: 1.1151e-06 - val_mae: 8.4447e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8571e-06 - mae: 0.0011 - val_loss: 9.7978e-07 - val_mae: 7.9197e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0501e-06 - mae: 9.2670e-04 - val_loss: 9.1052e-07 - val_mae: 7.5959e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6393e-06 - mae: 0.0010 - val_loss: 7.4175e-07 - val_mae: 7.1170e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.4161e-06 - mae: 8.3089e-04 - val_loss: 7.7473e-07 - val_mae: 6.9604e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5184e-06 - mae: 8.2721e-04 - val_loss: 1.0681e-06 - val_mae: 8.0317e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1651e-06 - mae: 9.8001e-04 - val_loss: 6.5938e-07 - val_mae: 7.1161e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8719e-06 - mae: 8.8721e-04 - val_loss: 6.4208e-07 - val_mae: 6.9710e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3902e-06 - mae: 0.0010 - val_loss: 6.3018e-07 - val_mae: 6.1289e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9438e-06 - mae: 9.0626e-04 - val_loss: 5.1830e-07 - val_mae: 5.6690e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5963e-06 - mae: 8.4890e-04 - val_loss: 7.8804e-07 - val_mae: 6.9866e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3688e-06 - mae: 0.0010 - val_loss: 5.7293e-07 - val_mae: 5.7384e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4788e-06 - mae: 7.7570e-04 - val_loss: 8.4346e-07 - val_mae: 7.6913e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9510e-06 - mae: 9.5929e-04 - val_loss: 5.0338e-07 - val_mae: 5.3356e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0477e-06 - mae: 9.1420e-04 - val_loss: 5.9763e-07 - val_mae: 5.9868e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0852e-06 - mae: 8.3989e-04 - val_loss: 4.7681e-07 - val_mae: 5.1688e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0183e-06 - mae: 7.9532e-04 - val_loss: 4.2183e-07 - val_mae: 4.8562e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4098e-06 - mae: 7.0381e-04 - val_loss: 1.4967e-06 - val_mae: 0.0011\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9616e-06 - mae: 9.6122e-04 - val_loss: 3.3543e-07 - val_mae: 4.7114e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.1925e-07 - mae: 4.7563e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: carmo, Test Loss: 3.3542914934514556e-07, Test MAE: 0.0004711410729214549\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 150ms/step\n",
      "Completed processing for city: carmo\n",
      "\n",
      "Processing city: casimiro de abreu\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 2.4890e-05 - val_mae: 0.0043\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4577e-04 - mae: 0.0121 - val_loss: 1.5526e-05 - val_mae: 0.0032\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2321e-04 - mae: 0.0086 - val_loss: 1.7680e-05 - val_mae: 0.0034\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.6967e-05 - mae: 0.0066 - val_loss: 6.0107e-06 - val_mae: 0.0021\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5647e-05 - mae: 0.0043 - val_loss: 3.4732e-06 - val_mae: 0.0017\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4939e-05 - mae: 0.0027 - val_loss: 2.3089e-06 - val_mae: 0.0014\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5404e-05 - mae: 0.0024 - val_loss: 1.8410e-06 - val_mae: 0.0012\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5195e-06 - mae: 0.0019 - val_loss: 1.4838e-06 - val_mae: 0.0011\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2143e-06 - mae: 0.0017 - val_loss: 1.3271e-06 - val_mae: 0.0010\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3278e-06 - mae: 0.0015 - val_loss: 1.7905e-06 - val_mae: 0.0012\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6087e-06 - mae: 0.0014 - val_loss: 1.0011e-06 - val_mae: 8.9057e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2074e-06 - mae: 0.0013 - val_loss: 1.3054e-06 - val_mae: 0.0010\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.1547e-06 - mae: 0.0015 - val_loss: 3.1643e-06 - val_mae: 0.0016\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3177e-06 - mae: 0.0013 - val_loss: 7.8482e-07 - val_mae: 8.1192e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0316e-06 - mae: 0.0012 - val_loss: 1.6444e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4753e-06 - mae: 0.0011 - val_loss: 7.0087e-07 - val_mae: 6.1279e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3324e-06 - mae: 9.2692e-04 - val_loss: 5.4008e-07 - val_mae: 6.6772e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5442e-06 - mae: 7.8985e-04 - val_loss: 7.1401e-07 - val_mae: 6.4618e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3787e-06 - mae: 8.3965e-04 - val_loss: 9.9529e-07 - val_mae: 8.2557e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0339e-06 - mae: 0.0010 - val_loss: 3.4506e-07 - val_mae: 5.0104e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6607e-06 - mae: 8.0464e-04 - val_loss: 7.9783e-07 - val_mae: 7.6236e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7740e-06 - mae: 8.3925e-04 - val_loss: 6.1374e-07 - val_mae: 6.3480e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5240e-06 - mae: 9.5420e-04 - val_loss: 8.4394e-07 - val_mae: 7.7980e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0738e-06 - mae: 9.6823e-04 - val_loss: 5.3259e-07 - val_mae: 6.2443e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7151e-06 - mae: 8.3352e-04 - val_loss: 2.5532e-07 - val_mae: 3.7426e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5592e-06 - mae: 7.2525e-04 - val_loss: 1.1637e-06 - val_mae: 9.6738e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2977e-06 - mae: 7.8900e-04 - val_loss: 2.1807e-07 - val_mae: 3.7039e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4469e-06 - mae: 8.3776e-04 - val_loss: 2.4620e-07 - val_mae: 4.1585e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2299e-07 - mae: 5.7063e-04 - val_loss: 7.2928e-07 - val_mae: 7.6088e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2821e-06 - mae: 7.5304e-04 - val_loss: 1.8564e-07 - val_mae: 3.1980e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 8.6566e-07 - mae: 6.1392e-04 - val_loss: 3.6816e-07 - val_mae: 4.9862e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1160e-06 - mae: 6.4795e-04 - val_loss: 1.7033e-07 - val_mae: 3.1298e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2878e-06 - mae: 6.8161e-04 - val_loss: 1.6825e-07 - val_mae: 3.2401e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9671e-06 - mae: 6.8996e-04 - val_loss: 3.5628e-07 - val_mae: 5.2017e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4758e-06 - mae: 7.2681e-04 - val_loss: 1.4282e-06 - val_mae: 0.0011\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3615e-06 - mae: 8.1453e-04 - val_loss: 5.7516e-07 - val_mae: 6.6147e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.2289e-07 - mae: 5.9933e-04 - val_loss: 8.6118e-07 - val_mae: 8.5256e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0851e-06 - mae: 7.0069e-04 - val_loss: 1.5541e-06 - val_mae: 0.0012\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0464e-06 - mae: 7.0139e-04 - val_loss: 2.6967e-07 - val_mae: 4.5528e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5021e-06 - mae: 8.1471e-04 - val_loss: 1.2845e-07 - val_mae: 2.5416e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.3562e-07 - mae: 4.9257e-04 - val_loss: 1.2436e-06 - val_mae: 0.0011\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5030e-06 - mae: 8.2282e-04 - val_loss: 3.3330e-07 - val_mae: 4.6657e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0781e-06 - mae: 6.9947e-04 - val_loss: 1.8737e-07 - val_mae: 3.7486e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0020e-06 - mae: 5.4553e-04 - val_loss: 1.4200e-07 - val_mae: 3.1802e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.6810e-07 - mae: 5.0926e-04 - val_loss: 1.0045e-06 - val_mae: 9.5084e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.2401e-07 - mae: 6.4251e-04 - val_loss: 2.8730e-07 - val_mae: 4.8210e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0097e-06 - mae: 6.5789e-04 - val_loss: 2.5178e-07 - val_mae: 4.5053e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2279e-07 - mae: 6.3772e-04 - val_loss: 5.6687e-07 - val_mae: 6.7898e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8200e-06 - mae: 7.1691e-04 - val_loss: 1.2289e-07 - val_mae: 2.9862e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4369e-07 - mae: 5.2447e-04 - val_loss: 5.5076e-07 - val_mae: 6.9445e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.3744e-07 - mae: 7.6358e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: casimiro de abreu, Test Loss: 5.507582159225421e-07, Test MAE: 0.0006944537744857371\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 180ms/step\n",
      "Completed processing for city: casimiro de abreu\n",
      "\n",
      "Processing city: comendador levy gasparian\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 61ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 1.0001e-04 - val_mae: 0.0086\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1976e-04 - mae: 0.0119 - val_loss: 7.8627e-05 - val_mae: 0.0065\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6189e-04 - mae: 0.0097 - val_loss: 3.6106e-05 - val_mae: 0.0048\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0381e-04 - mae: 0.0080 - val_loss: 3.8599e-05 - val_mae: 0.0055\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5084e-05 - mae: 0.0068 - val_loss: 3.2501e-05 - val_mae: 0.0049\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.6434e-05 - mae: 0.0059 - val_loss: 1.5005e-05 - val_mae: 0.0033\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5575e-05 - mae: 0.0044 - val_loss: 1.8014e-05 - val_mae: 0.0036\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6756e-05 - mae: 0.0045 - val_loss: 1.6735e-05 - val_mae: 0.0028\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 2.4059e-05 - mae: 0.0035 - val_loss: 6.1738e-06 - val_mae: 0.0017\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8055e-05 - mae: 0.0030 - val_loss: 3.0320e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4234e-05 - mae: 0.0026 - val_loss: 4.1887e-06 - val_mae: 0.0017\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1313e-05 - mae: 0.0023 - val_loss: 1.0990e-06 - val_mae: 7.8798e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.1636e-06 - mae: 0.0018 - val_loss: 1.1747e-06 - val_mae: 0.0010\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.7083e-06 - mae: 0.0018 - val_loss: 6.2632e-07 - val_mae: 6.7720e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.3565e-06 - mae: 0.0015 - val_loss: 4.4951e-07 - val_mae: 5.7195e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8454e-06 - mae: 0.0015 - val_loss: 7.7437e-07 - val_mae: 6.9338e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2218e-06 - mae: 0.0012 - val_loss: 1.0078e-06 - val_mae: 8.9765e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.8453e-06 - mae: 0.0013 - val_loss: 1.6524e-07 - val_mae: 3.5138e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2423e-06 - mae: 0.0010 - val_loss: 1.5152e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1343e-06 - mae: 0.0011 - val_loss: 4.8600e-07 - val_mae: 6.4273e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8873e-06 - mae: 9.4714e-04 - val_loss: 4.4095e-07 - val_mae: 6.2202e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1916e-06 - mae: 8.8488e-04 - val_loss: 8.8804e-08 - val_mae: 2.8044e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8476e-06 - mae: 7.9570e-04 - val_loss: 2.2607e-07 - val_mae: 4.3477e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4721e-06 - mae: 8.1098e-04 - val_loss: 2.9773e-07 - val_mae: 5.0905e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0767e-06 - mae: 0.0010 - val_loss: 1.2977e-06 - val_mae: 0.0011\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3239e-06 - mae: 9.7595e-04 - val_loss: 1.4136e-07 - val_mae: 3.5038e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3409e-06 - mae: 9.6653e-04 - val_loss: 3.7049e-08 - val_mae: 9.2976e-05\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0677e-06 - mae: 6.4934e-04 - val_loss: 2.9030e-08 - val_mae: 1.4916e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0537e-06 - mae: 6.2696e-04 - val_loss: 4.8905e-08 - val_mae: 2.1396e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3570e-06 - mae: 6.6334e-04 - val_loss: 8.8045e-08 - val_mae: 2.8156e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1552e-06 - mae: 7.8927e-04 - val_loss: 2.5121e-07 - val_mae: 4.7950e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3570e-06 - mae: 7.2993e-04 - val_loss: 2.0932e-08 - val_mae: 9.4181e-05\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1496e-06 - mae: 5.7393e-04 - val_loss: 5.2882e-08 - val_mae: 1.8539e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0611e-06 - mae: 6.1013e-04 - val_loss: 1.0478e-06 - val_mae: 0.0010\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.6237e-06 - mae: 8.9277e-04 - val_loss: 1.7128e-08 - val_mae: 1.1348e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.3923e-06 - mae: 6.1033e-04 - val_loss: 2.0412e-08 - val_mae: 6.9760e-05\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2872e-06 - mae: 7.1044e-04 - val_loss: 4.7206e-07 - val_mae: 6.7651e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6557e-06 - mae: 7.1571e-04 - val_loss: 2.5785e-08 - val_mae: 1.5538e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9052e-07 - mae: 3.9219e-04 - val_loss: 5.0066e-08 - val_mae: 2.1432e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.7037e-07 - mae: 5.2652e-04 - val_loss: 2.3829e-07 - val_mae: 4.7581e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3278e-06 - mae: 5.8426e-04 - val_loss: 2.8134e-07 - val_mae: 5.1969e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3067e-06 - mae: 8.7850e-04 - val_loss: 2.1897e-08 - val_mae: 1.4329e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.7818e-07 - mae: 5.6182e-04 - val_loss: 6.1178e-08 - val_mae: 2.2286e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.0249e-07 - mae: 6.1513e-04 - val_loss: 3.3007e-07 - val_mae: 5.6523e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2914e-06 - mae: 7.6220e-04 - val_loss: 2.9966e-07 - val_mae: 5.3766e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.3651e-07 - mae: 5.2552e-04 - val_loss: 3.0705e-07 - val_mae: 5.4460e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9498e-07 - mae: 6.2112e-04 - val_loss: 9.0964e-07 - val_mae: 9.4837e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1362e-06 - mae: 6.4046e-04 - val_loss: 3.3069e-07 - val_mae: 5.6664e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.5290e-07 - mae: 5.8761e-04 - val_loss: 3.5706e-08 - val_mae: 1.6335e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2430e-06 - mae: 6.3133e-04 - val_loss: 9.0651e-09 - val_mae: 5.3661e-05\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1405e-08 - mae: 6.1818e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: comendador levy gasparian, Test Loss: 9.065119321860493e-09, Test MAE: 5.366108234738931e-05\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 158ms/step\n",
      "Completed processing for city: comendador levy gasparian\n",
      "\n",
      "Processing city: conceição de macabu\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 55ms/step - loss: 3.4140e-04 - mae: 0.0141 - val_loss: 1.9748e-05 - val_mae: 0.0035\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.7591e-05 - mae: 0.0072 - val_loss: 2.3842e-05 - val_mae: 0.0036\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.4779e-05 - mae: 0.0056 - val_loss: 6.0867e-06 - val_mae: 0.0021\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4277e-05 - mae: 0.0041 - val_loss: 7.8264e-06 - val_mae: 0.0023\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2119e-05 - mae: 0.0032 - val_loss: 7.5774e-06 - val_mae: 0.0024\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1905e-05 - mae: 0.0025 - val_loss: 2.7885e-06 - val_mae: 0.0015\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1747e-05 - mae: 0.0023 - val_loss: 2.7509e-06 - val_mae: 0.0014\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1576e-05 - mae: 0.0022 - val_loss: 5.9547e-06 - val_mae: 0.0021\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.4815e-06 - mae: 0.0020 - val_loss: 2.2855e-06 - val_mae: 0.0014\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2472e-06 - mae: 0.0017 - val_loss: 1.9271e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6357e-06 - mae: 0.0013 - val_loss: 1.6282e-06 - val_mae: 0.0010\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9212e-06 - mae: 0.0015 - val_loss: 1.3920e-06 - val_mae: 9.6178e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6746e-06 - mae: 0.0013 - val_loss: 1.1993e-06 - val_mae: 9.7851e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.9276e-06 - mae: 0.0014 - val_loss: 2.3146e-06 - val_mae: 0.0013\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7868e-06 - mae: 0.0013 - val_loss: 2.6003e-06 - val_mae: 0.0014\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2844e-06 - mae: 0.0011 - val_loss: 8.8971e-07 - val_mae: 8.5364e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1646e-06 - mae: 0.0011 - val_loss: 1.4884e-06 - val_mae: 0.0011\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8579e-06 - mae: 0.0010 - val_loss: 9.7024e-07 - val_mae: 8.7829e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5517e-06 - mae: 0.0011 - val_loss: 2.1305e-06 - val_mae: 0.0013\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1538e-06 - mae: 9.4248e-04 - val_loss: 6.6789e-07 - val_mae: 7.3385e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6750e-06 - mae: 0.0010 - val_loss: 5.4470e-07 - val_mae: 5.5427e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3093e-06 - mae: 0.0011 - val_loss: 5.4593e-07 - val_mae: 6.5871e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9714e-06 - mae: 9.9188e-04 - val_loss: 6.4379e-07 - val_mae: 7.1936e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6276e-06 - mae: 9.0021e-04 - val_loss: 4.0789e-07 - val_mae: 5.1985e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1145e-06 - mae: 7.6083e-04 - val_loss: 1.2063e-06 - val_mae: 9.5487e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.9200e-06 - mae: 9.8864e-04 - val_loss: 7.9906e-07 - val_mae: 7.8639e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6074e-06 - mae: 8.7258e-04 - val_loss: 1.3872e-06 - val_mae: 0.0010\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4104e-06 - mae: 9.0865e-04 - val_loss: 3.1441e-07 - val_mae: 4.3711e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4366e-06 - mae: 8.5016e-04 - val_loss: 7.3824e-07 - val_mae: 7.5602e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3770e-06 - mae: 8.5183e-04 - val_loss: 3.5263e-07 - val_mae: 5.3580e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5541e-06 - mae: 8.4890e-04 - val_loss: 7.0433e-07 - val_mae: 7.3697e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4580e-06 - mae: 8.1497e-04 - val_loss: 6.7029e-07 - val_mae: 6.6092e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2034e-06 - mae: 8.5032e-04 - val_loss: 3.0620e-07 - val_mae: 4.1476e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0765e-06 - mae: 7.3546e-04 - val_loss: 2.1343e-07 - val_mae: 3.7991e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.4709e-07 - mae: 6.0549e-04 - val_loss: 1.2464e-06 - val_mae: 0.0010\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.4137e-07 - mae: 7.7981e-04 - val_loss: 7.5050e-07 - val_mae: 7.7185e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0838e-06 - mae: 7.1405e-04 - val_loss: 4.1635e-07 - val_mae: 5.8008e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6735e-06 - mae: 8.7596e-04 - val_loss: 1.6840e-06 - val_mae: 0.0012\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4428e-06 - mae: 8.2149e-04 - val_loss: 4.3759e-07 - val_mae: 5.9206e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.2861e-07 - mae: 7.0420e-04 - val_loss: 1.5164e-06 - val_mae: 0.0012\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1514e-06 - mae: 7.0335e-04 - val_loss: 1.5100e-07 - val_mae: 2.8512e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.0077e-07 - mae: 5.8691e-04 - val_loss: 3.8390e-07 - val_mae: 4.9396e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.1353e-06 - mae: 7.1746e-04 - val_loss: 4.5386e-07 - val_mae: 6.0117e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 7.1450e-07 - mae: 6.2764e-04 - val_loss: 5.8345e-07 - val_mae: 6.8701e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8778e-07 - mae: 6.6111e-04 - val_loss: 1.8878e-07 - val_mae: 3.1827e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9874e-06 - mae: 8.0260e-04 - val_loss: 8.9195e-07 - val_mae: 8.8315e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1.6702e-06 - mae: 7.8182e-04 - val_loss: 5.0517e-07 - val_mae: 6.2969e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.1335e-06 - mae: 7.1620e-04 - val_loss: 1.2595e-07 - val_mae: 2.5960e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.2555e-07 - mae: 5.7909e-04 - val_loss: 1.3698e-07 - val_mae: 3.3842e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.4784e-07 - mae: 5.1023e-04 - val_loss: 2.2338e-07 - val_mae: 4.2885e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.4959e-07 - mae: 4.5958e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: conceição de macabu, Test Loss: 2.2338272742672416e-07, Test MAE: 0.00042884552385658026\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 109ms/step\n",
      "Completed processing for city: conceição de macabu\n",
      "\n",
      "Processing city: cordeiro\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - loss: 4.6248e-04 - mae: 0.0174 - val_loss: 1.4745e-04 - val_mae: 0.0103\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3480e-04 - mae: 0.0094 - val_loss: 2.8028e-05 - val_mae: 0.0042\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.8146e-05 - mae: 0.0074 - val_loss: 7.8391e-06 - val_mae: 0.0023\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.3605e-05 - mae: 0.0059 - val_loss: 1.3296e-05 - val_mae: 0.0031\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.5122e-05 - mae: 0.0052 - val_loss: 1.5674e-05 - val_mae: 0.0032\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2846e-05 - mae: 0.0045 - val_loss: 2.3644e-05 - val_mae: 0.0040\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5559e-05 - mae: 0.0040 - val_loss: 1.2382e-05 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2920e-05 - mae: 0.0037 - val_loss: 1.0154e-05 - val_mae: 0.0027\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7132e-05 - mae: 0.0030 - val_loss: 1.3496e-05 - val_mae: 0.0032\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8052e-05 - mae: 0.0031 - val_loss: 4.5045e-06 - val_mae: 0.0018\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6861e-05 - mae: 0.0030 - val_loss: 3.2486e-06 - val_mae: 0.0015\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.3012e-05 - mae: 0.0026 - val_loss: 4.6216e-06 - val_mae: 0.0019\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1288e-05 - mae: 0.0024 - val_loss: 3.4871e-06 - val_mae: 0.0016\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1092e-05 - mae: 0.0023 - val_loss: 1.9769e-06 - val_mae: 0.0012\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0784e-05 - mae: 0.0023 - val_loss: 2.0341e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.9907e-06 - mae: 0.0019 - val_loss: 3.4036e-06 - val_mae: 0.0016\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.7775e-06 - mae: 0.0020 - val_loss: 1.0679e-06 - val_mae: 8.5316e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.8233e-06 - mae: 0.0019 - val_loss: 8.2703e-07 - val_mae: 7.6691e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.3882e-06 - mae: 0.0016 - val_loss: 9.1379e-07 - val_mae: 7.6310e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.8646e-06 - mae: 0.0018 - val_loss: 1.9394e-06 - val_mae: 0.0012\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.3116e-06 - mae: 0.0019 - val_loss: 6.7983e-07 - val_mae: 6.4160e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.4401e-06 - mae: 0.0016 - val_loss: 1.6272e-06 - val_mae: 0.0011\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 7.5823e-06 - mae: 0.0017 - val_loss: 3.8895e-06 - val_mae: 0.0019\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7355e-06 - mae: 0.0019 - val_loss: 4.1081e-07 - val_mae: 4.9413e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.5256e-06 - mae: 0.0016 - val_loss: 3.2633e-07 - val_mae: 4.3981e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5315e-06 - mae: 0.0015 - val_loss: 2.8481e-07 - val_mae: 4.1669e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9025e-06 - mae: 0.0015 - val_loss: 2.9406e-07 - val_mae: 3.9888e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 6.6820e-06 - mae: 0.0014 - val_loss: 3.0653e-07 - val_mae: 3.6022e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.9133e-06 - mae: 0.0013 - val_loss: 2.0469e-07 - val_mae: 3.6255e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 4.1836e-06 - mae: 0.0012 - val_loss: 5.5322e-07 - val_mae: 6.9113e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 8.4579e-06 - mae: 0.0016 - val_loss: 2.0678e-06 - val_mae: 0.0014\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 7.9216e-06 - mae: 0.0016 - val_loss: 1.3445e-06 - val_mae: 0.0011\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.4226e-06 - mae: 0.0014 - val_loss: 1.7820e-07 - val_mae: 3.4039e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.8267e-06 - mae: 0.0014 - val_loss: 1.6199e-07 - val_mae: 3.1129e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2733e-06 - mae: 0.0014 - val_loss: 2.1152e-07 - val_mae: 2.8739e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 4.3655e-06 - mae: 0.0012 - val_loss: 4.6940e-07 - val_mae: 5.7895e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4789e-06 - mae: 0.0014 - val_loss: 1.6300e-07 - val_mae: 2.2362e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.2694e-06 - mae: 0.0015 - val_loss: 1.0279e-06 - val_mae: 9.5642e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 6.9557e-06 - mae: 0.0015 - val_loss: 1.6854e-07 - val_mae: 3.5936e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.2006e-06 - mae: 0.0012 - val_loss: 2.5727e-06 - val_mae: 0.0016\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7665e-06 - mae: 0.0014 - val_loss: 1.1659e-07 - val_mae: 2.5317e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5856e-06 - mae: 0.0013 - val_loss: 1.8713e-06 - val_mae: 0.0013\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.6178e-06 - mae: 0.0014 - val_loss: 6.8903e-07 - val_mae: 7.7827e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8618e-06 - mae: 0.0013 - val_loss: 5.8907e-07 - val_mae: 7.1966e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5296e-06 - mae: 0.0012 - val_loss: 7.4849e-07 - val_mae: 8.1022e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5090e-06 - mae: 0.0013 - val_loss: 1.6292e-07 - val_mae: 3.5084e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3071e-06 - mae: 0.0011 - val_loss: 2.0837e-07 - val_mae: 3.6487e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9733e-06 - mae: 0.0013 - val_loss: 2.8875e-07 - val_mae: 4.9643e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9977e-06 - mae: 0.0011 - val_loss: 1.3756e-06 - val_mae: 0.0011\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4894e-06 - mae: 0.0011 - val_loss: 2.1817e-07 - val_mae: 4.2250e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.9336e-07 - mae: 4.0032e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: cordeiro, Test Loss: 2.1817285755787452e-07, Test MAE: 0.00042249856051057577\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 166ms/step\n",
      "Completed processing for city: cordeiro\n",
      "\n",
      "Processing city: duas barras\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 54ms/step - loss: 7.8033e-04 - mae: 0.0202 - val_loss: 8.3797e-05 - val_mae: 0.0070\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0540e-04 - mae: 0.0078 - val_loss: 3.8211e-05 - val_mae: 0.0050\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.6884e-05 - mae: 0.0055 - val_loss: 1.3854e-05 - val_mae: 0.0031\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0608e-05 - mae: 0.0039 - val_loss: 8.1739e-06 - val_mae: 0.0024\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0223e-05 - mae: 0.0031 - val_loss: 3.0952e-06 - val_mae: 0.0014\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0724e-05 - mae: 0.0024 - val_loss: 1.1644e-06 - val_mae: 9.2451e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1820e-06 - mae: 0.0019 - val_loss: 8.4515e-07 - val_mae: 7.7152e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.2334e-06 - mae: 0.0015 - val_loss: 7.4218e-07 - val_mae: 6.9108e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1646e-06 - mae: 0.0013 - val_loss: 5.5853e-07 - val_mae: 6.1627e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9084e-06 - mae: 0.0013 - val_loss: 4.1593e-07 - val_mae: 5.0420e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3744e-06 - mae: 0.0011 - val_loss: 6.5437e-07 - val_mae: 6.9287e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6615e-06 - mae: 0.0011 - val_loss: 3.0886e-07 - val_mae: 4.3183e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9592e-06 - mae: 9.6489e-04 - val_loss: 1.4861e-06 - val_mae: 0.0011\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6591e-06 - mae: 0.0012 - val_loss: 5.3832e-07 - val_mae: 6.4836e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.4131e-06 - mae: 8.7937e-04 - val_loss: 8.3902e-07 - val_mae: 8.3270e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0323e-06 - mae: 0.0010 - val_loss: 1.9043e-07 - val_mae: 3.5629e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.1963e-06 - mae: 7.9414e-04 - val_loss: 1.7635e-07 - val_mae: 3.4602e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.3470e-06 - mae: 9.6958e-04 - val_loss: 1.7212e-07 - val_mae: 3.0390e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.4679e-06 - mae: 8.1162e-04 - val_loss: 2.3449e-07 - val_mae: 4.2768e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.2534e-06 - mae: 8.1295e-04 - val_loss: 8.3958e-07 - val_mae: 8.5314e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0691e-06 - mae: 7.8573e-04 - val_loss: 1.1793e-07 - val_mae: 2.6939e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 6.7316e-07 - mae: 6.3380e-04 - val_loss: 1.4660e-07 - val_mae: 3.2981e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2254e-06 - mae: 7.6182e-04 - val_loss: 5.9353e-07 - val_mae: 6.9990e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.3304e-07 - mae: 7.1810e-04 - val_loss: 2.9511e-07 - val_mae: 4.4330e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 7.9963e-07 - mae: 6.7093e-04 - val_loss: 9.4000e-08 - val_mae: 2.4373e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0096e-06 - mae: 6.3010e-04 - val_loss: 8.8865e-08 - val_mae: 2.3809e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9367e-07 - mae: 5.2148e-04 - val_loss: 9.0957e-08 - val_mae: 2.4525e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.1912e-07 - mae: 6.8193e-04 - val_loss: 1.7655e-07 - val_mae: 3.2782e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 6.5996e-07 - mae: 6.0861e-04 - val_loss: 1.5520e-06 - val_mae: 0.0012\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1556e-06 - mae: 8.2896e-04 - val_loss: 5.8639e-07 - val_mae: 7.1617e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2632e-07 - mae: 6.4312e-04 - val_loss: 2.0847e-07 - val_mae: 4.0944e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2801e-07 - mae: 6.0630e-04 - val_loss: 1.7661e-07 - val_mae: 3.4357e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2566e-07 - mae: 6.4132e-04 - val_loss: 2.7476e-07 - val_mae: 4.7602e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2348e-06 - mae: 7.2559e-04 - val_loss: 6.6741e-08 - val_mae: 2.0422e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.7432e-07 - mae: 5.0018e-04 - val_loss: 1.1533e-07 - val_mae: 2.7265e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.5678e-07 - mae: 5.0216e-04 - val_loss: 2.0018e-07 - val_mae: 3.8084e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9099e-07 - mae: 5.3414e-04 - val_loss: 5.0403e-07 - val_mae: 6.6834e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.9699e-07 - mae: 6.9622e-04 - val_loss: 2.2131e-07 - val_mae: 4.2396e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2417e-07 - mae: 5.1209e-04 - val_loss: 7.5325e-07 - val_mae: 8.3695e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 8.5338e-07 - mae: 7.5923e-04 - val_loss: 5.0933e-08 - val_mae: 1.7591e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.6946e-07 - mae: 4.5794e-04 - val_loss: 2.0477e-07 - val_mae: 4.0723e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2583e-07 - mae: 5.8457e-04 - val_loss: 1.8627e-07 - val_mae: 3.8617e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1589e-06 - mae: 5.7647e-04 - val_loss: 1.8847e-07 - val_mae: 3.8105e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7125e-07 - mae: 5.7329e-04 - val_loss: 4.0708e-07 - val_mae: 6.0331e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.1285e-07 - mae: 6.5456e-04 - val_loss: 6.8481e-07 - val_mae: 8.0208e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2831e-07 - mae: 6.5626e-04 - val_loss: 2.6116e-07 - val_mae: 4.7014e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6888e-07 - mae: 5.6768e-04 - val_loss: 1.1537e-07 - val_mae: 2.9714e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.0082e-07 - mae: 4.5710e-04 - val_loss: 5.5570e-07 - val_mae: 7.2005e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.9029e-07 - mae: 5.8009e-04 - val_loss: 4.9039e-07 - val_mae: 6.7377e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 6.5073e-07 - mae: 5.4284e-04 - val_loss: 7.9818e-08 - val_mae: 2.4066e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 8.8645e-08 - mae: 2.5827e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: duas barras, Test Loss: 7.981803662460152e-08, Test MAE: 0.00024065976322162896\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 123ms/step\n",
      "Completed processing for city: duas barras\n",
      "\n",
      "Processing city: duque de caxias\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 49ms/step - loss: 4.2699e-04 - mae: 0.0160 - val_loss: 3.6173e-05 - val_mae: 0.0049\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4924e-04 - mae: 0.0095 - val_loss: 1.2906e-05 - val_mae: 0.0028\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.4114e-05 - mae: 0.0072 - val_loss: 1.3707e-05 - val_mae: 0.0030\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4391e-05 - mae: 0.0060 - val_loss: 1.3733e-05 - val_mae: 0.0033\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9626e-05 - mae: 0.0055 - val_loss: 5.2615e-06 - val_mae: 0.0019\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0630e-05 - mae: 0.0050 - val_loss: 5.6061e-06 - val_mae: 0.0021\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6469e-05 - mae: 0.0040 - val_loss: 9.2816e-06 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.9262e-05 - mae: 0.0047 - val_loss: 2.8237e-06 - val_mae: 0.0013\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4156e-05 - mae: 0.0038 - val_loss: 5.1657e-06 - val_mae: 0.0020\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4776e-05 - mae: 0.0039 - val_loss: 4.0001e-06 - val_mae: 0.0017\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5418e-05 - mae: 0.0037 - val_loss: 1.0473e-06 - val_mae: 8.0103e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.5374e-05 - mae: 0.0036 - val_loss: 6.2999e-07 - val_mae: 6.5622e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5351e-05 - mae: 0.0031 - val_loss: 7.3550e-06 - val_mae: 0.0026\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2709e-05 - mae: 0.0036 - val_loss: 3.7350e-06 - val_mae: 0.0018\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.3222e-05 - mae: 0.0031 - val_loss: 1.8266e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.3760e-05 - mae: 0.0030 - val_loss: 3.4971e-06 - val_mae: 0.0018\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5518e-05 - mae: 0.0031 - val_loss: 1.2636e-06 - val_mae: 0.0010\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6863e-05 - mae: 0.0028 - val_loss: 1.6300e-06 - val_mae: 0.0012\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3904e-05 - mae: 0.0030 - val_loss: 3.0063e-06 - val_mae: 0.0016\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5638e-05 - mae: 0.0029 - val_loss: 8.3251e-07 - val_mae: 8.3025e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1783e-05 - mae: 0.0025 - val_loss: 5.1972e-06 - val_mae: 0.0022\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1881e-05 - mae: 0.0028 - val_loss: 4.3153e-07 - val_mae: 5.5726e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7609e-05 - mae: 0.0023 - val_loss: 4.0327e-06 - val_mae: 0.0019\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5058e-05 - mae: 0.0029 - val_loss: 4.3108e-07 - val_mae: 4.3327e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6742e-05 - mae: 0.0027 - val_loss: 4.2847e-06 - val_mae: 0.0020\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8705e-05 - mae: 0.0024 - val_loss: 3.5573e-06 - val_mae: 0.0018\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5453e-05 - mae: 0.0022 - val_loss: 9.1257e-06 - val_mae: 0.0030\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9699e-05 - mae: 0.0027 - val_loss: 7.8108e-07 - val_mae: 8.0511e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8844e-05 - mae: 0.0028 - val_loss: 3.6597e-06 - val_mae: 0.0018\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3897e-05 - mae: 0.0026 - val_loss: 1.0619e-05 - val_mae: 0.0032\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1794e-05 - mae: 0.0030 - val_loss: 7.4110e-07 - val_mae: 7.7980e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1347e-05 - mae: 0.0026 - val_loss: 2.0781e-06 - val_mae: 0.0014\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3837e-05 - mae: 0.0027 - val_loss: 9.9295e-07 - val_mae: 9.1658e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9629e-05 - mae: 0.0024 - val_loss: 4.4212e-07 - val_mae: 5.6714e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6038e-05 - mae: 0.0025 - val_loss: 2.7281e-06 - val_mae: 0.0016\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7540e-05 - mae: 0.0029 - val_loss: 7.3477e-07 - val_mae: 7.7360e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3844e-05 - mae: 0.0025 - val_loss: 4.5442e-07 - val_mae: 4.4259e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2884e-05 - mae: 0.0024 - val_loss: 4.7403e-07 - val_mae: 4.4926e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8404e-05 - mae: 0.0022 - val_loss: 2.1790e-06 - val_mae: 0.0014\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5214e-05 - mae: 0.0021 - val_loss: 5.2768e-06 - val_mae: 0.0022\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8143e-05 - mae: 0.0024 - val_loss: 1.7430e-05 - val_mae: 0.0041\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4697e-05 - mae: 0.0031 - val_loss: 8.1339e-07 - val_mae: 6.6680e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4728e-05 - mae: 0.0025 - val_loss: 8.4154e-06 - val_mae: 0.0028\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9721e-05 - mae: 0.0026 - val_loss: 6.6213e-06 - val_mae: 0.0025\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2931e-05 - mae: 0.0028 - val_loss: 4.2863e-07 - val_mae: 5.0703e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9393e-05 - mae: 0.0022 - val_loss: 5.4620e-06 - val_mae: 0.0023\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9172e-05 - mae: 0.0031 - val_loss: 3.7263e-07 - val_mae: 4.5138e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3288e-05 - mae: 0.0024 - val_loss: 1.7549e-06 - val_mae: 0.0012\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.7996e-05 - mae: 0.0021 - val_loss: 2.2521e-06 - val_mae: 0.0014\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6995e-05 - mae: 0.0024 - val_loss: 5.7290e-07 - val_mae: 6.6553e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.6642e-07 - mae: 7.4835e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: duque de caxias, Test Loss: 5.729003760279738e-07, Test MAE: 0.0006655284087173641\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 187ms/step\n",
      "Completed processing for city: duque de caxias\n",
      "\n",
      "Processing city: engenheiro paulo de frontin\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 51ms/step - loss: 8.6159e-04 - mae: 0.0219 - val_loss: 3.0214e-04 - val_mae: 0.0132\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3274e-04 - mae: 0.0110 - val_loss: 6.2507e-05 - val_mae: 0.0067\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6693e-05 - mae: 0.0062 - val_loss: 3.6063e-05 - val_mae: 0.0053\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5225e-05 - mae: 0.0050 - val_loss: 2.5367e-05 - val_mae: 0.0044\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0519e-05 - mae: 0.0040 - val_loss: 1.7420e-05 - val_mae: 0.0036\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8900e-05 - mae: 0.0032 - val_loss: 1.2721e-05 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2747e-05 - mae: 0.0026 - val_loss: 9.8805e-06 - val_mae: 0.0025\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1271e-05 - mae: 0.0025 - val_loss: 8.5791e-06 - val_mae: 0.0025\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1422e-05 - mae: 0.0022 - val_loss: 6.8461e-06 - val_mae: 0.0020\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.8888e-06 - mae: 0.0021 - val_loss: 7.0117e-06 - val_mae: 0.0018\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.9547e-06 - mae: 0.0018 - val_loss: 6.1605e-06 - val_mae: 0.0022\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.8230e-06 - mae: 0.0018 - val_loss: 4.1399e-06 - val_mae: 0.0017\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7659e-06 - mae: 0.0016 - val_loss: 3.6729e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1018e-06 - mae: 0.0012 - val_loss: 3.4365e-06 - val_mae: 0.0016\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3524e-06 - mae: 0.0013 - val_loss: 3.1870e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1763e-06 - mae: 0.0013 - val_loss: 2.7010e-06 - val_mae: 0.0013\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9456e-06 - mae: 0.0011 - val_loss: 2.4625e-06 - val_mae: 0.0014\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5788e-06 - mae: 0.0011 - val_loss: 2.6296e-06 - val_mae: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0514e-06 - mae: 9.4605e-04 - val_loss: 2.1423e-06 - val_mae: 0.0010\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9789e-06 - mae: 0.0011 - val_loss: 1.9519e-06 - val_mae: 0.0013\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7050e-06 - mae: 0.0011 - val_loss: 1.7430e-06 - val_mae: 9.0767e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0284e-06 - mae: 9.1365e-04 - val_loss: 2.6784e-06 - val_mae: 0.0011\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.8816e-06 - mae: 9.0830e-04 - val_loss: 1.4134e-06 - val_mae: 0.0011\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9056e-06 - mae: 9.5285e-04 - val_loss: 3.6794e-06 - val_mae: 0.0016\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.4307e-06 - mae: 8.1526e-04 - val_loss: 1.1885e-06 - val_mae: 6.9056e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4143e-06 - mae: 6.5763e-04 - val_loss: 1.0616e-06 - val_mae: 6.7937e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1500e-06 - mae: 6.9442e-04 - val_loss: 9.3274e-07 - val_mae: 7.8294e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6725e-06 - mae: 9.1374e-04 - val_loss: 1.1047e-06 - val_mae: 9.9027e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2977e-06 - mae: 8.1426e-04 - val_loss: 1.2766e-06 - val_mae: 7.5708e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1030e-06 - mae: 6.4624e-04 - val_loss: 9.0107e-07 - val_mae: 5.2745e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1933e-06 - mae: 6.1881e-04 - val_loss: 1.5268e-06 - val_mae: 9.4089e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2643e-06 - mae: 7.7818e-04 - val_loss: 1.4949e-06 - val_mae: 9.5521e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3473e-06 - mae: 7.4438e-04 - val_loss: 2.6027e-06 - val_mae: 0.0014\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0378e-06 - mae: 7.6307e-04 - val_loss: 8.4692e-07 - val_mae: 6.1827e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.7401e-07 - mae: 5.1466e-04 - val_loss: 8.5555e-07 - val_mae: 6.4559e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.9663e-07 - mae: 5.8987e-04 - val_loss: 5.6838e-07 - val_mae: 4.1847e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.4709e-07 - mae: 5.1523e-04 - val_loss: 4.0210e-07 - val_mae: 5.1305e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.3790e-07 - mae: 6.1819e-04 - val_loss: 5.2881e-07 - val_mae: 4.1868e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9348e-06 - mae: 7.0963e-04 - val_loss: 4.1331e-07 - val_mae: 3.4367e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.3834e-07 - mae: 5.0976e-04 - val_loss: 1.1987e-06 - val_mae: 9.3943e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.0878e-07 - mae: 6.1588e-04 - val_loss: 3.4194e-07 - val_mae: 5.4704e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4194e-06 - mae: 6.3409e-04 - val_loss: 6.8489e-07 - val_mae: 6.3708e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 7.7912e-07 - mae: 6.6629e-04 - val_loss: 2.9733e-07 - val_mae: 3.4064e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.8598e-07 - mae: 5.3104e-04 - val_loss: 7.9806e-07 - val_mae: 7.3369e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1.0793e-06 - mae: 7.0371e-04 - val_loss: 1.9920e-06 - val_mae: 0.0013\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.3935e-07 - mae: 6.2011e-04 - val_loss: 6.5845e-07 - val_mae: 6.6038e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2509e-06 - mae: 7.6809e-04 - val_loss: 1.5810e-06 - val_mae: 0.0012\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4694e-07 - mae: 6.0173e-04 - val_loss: 6.1469e-07 - val_mae: 7.3389e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3870e-06 - mae: 8.1251e-04 - val_loss: 3.0358e-07 - val_mae: 5.3415e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8854e-07 - mae: 6.4104e-04 - val_loss: 4.1876e-07 - val_mae: 5.1466e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3713e-07 - mae: 4.6271e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: engenheiro paulo de frontin, Test Loss: 4.1875716760841897e-07, Test MAE: 0.000514661893248558\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 135ms/step\n",
      "Completed processing for city: engenheiro paulo de frontin\n",
      "\n",
      "Processing city: guapimirim\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 4.4724e-04 - mae: 0.0170 - val_loss: 2.9569e-05 - val_mae: 0.0044\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2548e-04 - mae: 0.0116 - val_loss: 2.6491e-05 - val_mae: 0.0042\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6102e-04 - mae: 0.0097 - val_loss: 5.0112e-05 - val_mae: 0.0059\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1096e-04 - mae: 0.0081 - val_loss: 1.2190e-05 - val_mae: 0.0027\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.7665e-05 - mae: 0.0065 - val_loss: 8.1782e-06 - val_mae: 0.0021\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.3432e-05 - mae: 0.0059 - val_loss: 1.9622e-06 - val_mae: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1635e-05 - mae: 0.0046 - val_loss: 1.2291e-06 - val_mae: 8.5504e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4918e-05 - mae: 0.0035 - val_loss: 1.4388e-06 - val_mae: 9.4989e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9849e-05 - mae: 0.0031 - val_loss: 2.2972e-06 - val_mae: 0.0013\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3981e-05 - mae: 0.0026 - val_loss: 1.4114e-06 - val_mae: 9.8678e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7125e-06 - mae: 0.0022 - val_loss: 8.5635e-07 - val_mae: 7.6880e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 6.4361e-06 - mae: 0.0017 - val_loss: 2.4553e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9571e-06 - mae: 0.0016 - val_loss: 2.0976e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.6442e-06 - mae: 0.0019 - val_loss: 1.9338e-06 - val_mae: 0.0012\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9243e-06 - mae: 0.0015 - val_loss: 1.6852e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1367e-06 - mae: 0.0012 - val_loss: 6.6139e-07 - val_mae: 7.1017e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7660e-06 - mae: 0.0011 - val_loss: 1.0312e-06 - val_mae: 8.6214e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9388e-06 - mae: 0.0011 - val_loss: 9.8659e-07 - val_mae: 8.4146e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1965e-06 - mae: 0.0011 - val_loss: 8.2555e-07 - val_mae: 7.0846e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3346e-06 - mae: 0.0011 - val_loss: 4.2719e-07 - val_mae: 5.7478e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9412e-06 - mae: 0.0010 - val_loss: 6.7402e-07 - val_mae: 6.4183e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1433e-06 - mae: 9.9868e-04 - val_loss: 3.4401e-07 - val_mae: 5.1283e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0734e-06 - mae: 9.6938e-04 - val_loss: 2.7008e-07 - val_mae: 4.3974e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.0319e-06 - mae: 8.0465e-04 - val_loss: 7.7498e-07 - val_mae: 7.3220e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2484e-06 - mae: 7.6150e-04 - val_loss: 2.9380e-07 - val_mae: 4.3443e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.8334e-06 - mae: 8.0487e-04 - val_loss: 2.5635e-07 - val_mae: 4.3984e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.0706e-07 - mae: 6.3716e-04 - val_loss: 4.8622e-07 - val_mae: 5.9033e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.8870e-06 - mae: 7.7885e-04 - val_loss: 1.5868e-07 - val_mae: 3.3812e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 7.4234e-07 - mae: 5.6399e-04 - val_loss: 5.3048e-07 - val_mae: 6.3236e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9164e-06 - mae: 8.7494e-04 - val_loss: 3.8650e-07 - val_mae: 5.2163e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4125e-06 - mae: 7.1316e-04 - val_loss: 1.2619e-07 - val_mae: 2.8859e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0625e-06 - mae: 8.9447e-04 - val_loss: 1.1175e-07 - val_mae: 2.7446e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 6.4880e-07 - mae: 5.5980e-04 - val_loss: 1.0177e-07 - val_mae: 2.5996e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5296e-06 - mae: 7.9409e-04 - val_loss: 1.7562e-07 - val_mae: 3.3183e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.7897e-07 - mae: 5.5659e-04 - val_loss: 7.1466e-08 - val_mae: 2.3087e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2983e-07 - mae: 5.3253e-04 - val_loss: 6.5002e-08 - val_mae: 2.1275e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1191e-06 - mae: 4.8040e-04 - val_loss: 1.7293e-07 - val_mae: 3.4554e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.1866e-07 - mae: 5.4914e-04 - val_loss: 1.1612e-07 - val_mae: 2.6907e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5947e-07 - mae: 6.1539e-04 - val_loss: 8.5169e-07 - val_mae: 9.0176e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.5494e-07 - mae: 6.7916e-04 - val_loss: 4.4491e-07 - val_mae: 6.3973e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.2381e-07 - mae: 6.4077e-04 - val_loss: 2.5252e-07 - val_mae: 4.6978e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3827e-06 - mae: 5.8632e-04 - val_loss: 2.2727e-07 - val_mae: 4.4338e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9571e-07 - mae: 5.3280e-04 - val_loss: 1.3933e-07 - val_mae: 3.3356e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 8.1276e-07 - mae: 5.8526e-04 - val_loss: 2.5453e-07 - val_mae: 4.7904e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.2737e-07 - mae: 6.1400e-04 - val_loss: 7.9834e-08 - val_mae: 2.4020e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8383e-07 - mae: 4.6529e-04 - val_loss: 2.5490e-08 - val_mae: 1.4030e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.2039e-07 - mae: 5.3811e-04 - val_loss: 3.5992e-07 - val_mae: 5.8491e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8546e-07 - mae: 5.3747e-04 - val_loss: 8.6570e-08 - val_mae: 2.6574e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2476e-06 - mae: 6.5829e-04 - val_loss: 1.2126e-07 - val_mae: 3.2498e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.9048e-07 - mae: 6.2494e-04 - val_loss: 9.7636e-08 - val_mae: 2.8678e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.7410e-08 - mae: 2.6706e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: guapimirim, Test Loss: 9.763633812553962e-08, Test MAE: 0.0002867810253519565\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 141ms/step\n",
      "Completed processing for city: guapimirim\n",
      "\n",
      "Processing city: iguaba grande\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 50ms/step - loss: 7.8702e-04 - mae: 0.0215 - val_loss: 5.6589e-05 - val_mae: 0.0057\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4433e-04 - mae: 0.0096 - val_loss: 4.5002e-05 - val_mae: 0.0056\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2965e-05 - mae: 0.0074 - val_loss: 3.1901e-05 - val_mae: 0.0048\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2691e-05 - mae: 0.0054 - val_loss: 1.3208e-05 - val_mae: 0.0032\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7861e-05 - mae: 0.0044 - val_loss: 2.5454e-06 - val_mae: 0.0013\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0659e-05 - mae: 0.0032 - val_loss: 8.2691e-07 - val_mae: 7.2977e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5354e-05 - mae: 0.0025 - val_loss: 1.0709e-06 - val_mae: 8.1035e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 9.0686e-06 - mae: 0.0020 - val_loss: 4.1382e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0045e-06 - mae: 0.0017 - val_loss: 1.6387e-06 - val_mae: 0.0011\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8554e-06 - mae: 0.0017 - val_loss: 6.8481e-07 - val_mae: 6.1671e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8389e-06 - mae: 0.0016 - val_loss: 4.1718e-07 - val_mae: 5.8028e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.8870e-06 - mae: 0.0013 - val_loss: 5.5732e-07 - val_mae: 5.4517e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0356e-06 - mae: 0.0012 - val_loss: 3.2815e-07 - val_mae: 4.7326e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6340e-06 - mae: 0.0010 - val_loss: 4.3662e-07 - val_mae: 4.8075e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.9445e-06 - mae: 0.0010 - val_loss: 1.0209e-06 - val_mae: 9.0044e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.3149e-06 - mae: 0.0011 - val_loss: 5.4351e-07 - val_mae: 5.2595e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.9715e-06 - mae: 9.8608e-04 - val_loss: 1.8516e-06 - val_mae: 0.0013\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9417e-06 - mae: 0.0011 - val_loss: 1.1356e-06 - val_mae: 9.7037e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.4966e-06 - mae: 0.0011 - val_loss: 1.5871e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9428e-06 - mae: 0.0011 - val_loss: 7.8555e-07 - val_mae: 7.4580e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8775e-06 - mae: 8.0502e-04 - val_loss: 5.7886e-07 - val_mae: 5.9300e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5961e-06 - mae: 8.5535e-04 - val_loss: 4.7041e-07 - val_mae: 6.0822e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5801e-06 - mae: 0.0010 - val_loss: 2.6467e-07 - val_mae: 3.7691e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4856e-06 - mae: 8.2904e-04 - val_loss: 2.3022e-06 - val_mae: 0.0014\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.1561e-06 - mae: 8.4153e-04 - val_loss: 2.8828e-07 - val_mae: 4.7243e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3716e-06 - mae: 0.0010 - val_loss: 2.3086e-07 - val_mae: 3.9851e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.2039e-06 - mae: 7.4939e-04 - val_loss: 4.6911e-07 - val_mae: 5.0452e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.1716e-06 - mae: 0.0010 - val_loss: 4.4714e-07 - val_mae: 4.8949e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.6875e-06 - mae: 7.7894e-04 - val_loss: 2.4806e-07 - val_mae: 4.2822e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5592e-06 - mae: 7.2528e-04 - val_loss: 3.6269e-07 - val_mae: 5.2945e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4795e-06 - mae: 7.6906e-04 - val_loss: 4.8837e-07 - val_mae: 6.1932e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1171e-06 - mae: 8.3081e-04 - val_loss: 5.6337e-07 - val_mae: 6.7070e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6072e-06 - mae: 8.1916e-04 - val_loss: 5.1178e-07 - val_mae: 6.3398e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5911e-06 - mae: 8.8999e-04 - val_loss: 1.6267e-06 - val_mae: 0.0012\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2124e-06 - mae: 9.1407e-04 - val_loss: 6.7075e-07 - val_mae: 6.7007e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7146e-06 - mae: 6.1966e-04 - val_loss: 3.2424e-07 - val_mae: 3.9967e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.0841e-06 - mae: 9.1688e-04 - val_loss: 7.7614e-07 - val_mae: 8.0294e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5069e-06 - mae: 8.5921e-04 - val_loss: 3.0308e-07 - val_mae: 3.8952e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5033e-06 - mae: 7.5268e-04 - val_loss: 6.8652e-07 - val_mae: 7.4733e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.5202e-06 - mae: 7.9825e-04 - val_loss: 2.5318e-07 - val_mae: 4.3057e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3816e-06 - mae: 9.4307e-04 - val_loss: 2.9519e-07 - val_mae: 3.8371e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7662e-06 - mae: 6.4595e-04 - val_loss: 5.4090e-07 - val_mae: 6.5256e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4124e-06 - mae: 8.4449e-04 - val_loss: 2.7919e-07 - val_mae: 3.6949e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7144e-07 - mae: 5.6422e-04 - val_loss: 2.6015e-06 - val_mae: 0.0015\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9198e-06 - mae: 8.2647e-04 - val_loss: 8.2106e-07 - val_mae: 8.2725e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8105e-06 - mae: 7.2036e-04 - val_loss: 2.0784e-06 - val_mae: 0.0014\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7254e-06 - mae: 8.3407e-04 - val_loss: 2.4759e-07 - val_mae: 3.4779e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3738e-06 - mae: 6.0724e-04 - val_loss: 2.3180e-07 - val_mae: 3.8922e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6403e-06 - mae: 7.1261e-04 - val_loss: 3.8941e-07 - val_mae: 5.4567e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3242e-06 - mae: 7.0050e-04 - val_loss: 2.4707e-07 - val_mae: 3.4242e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6598e-07 - mae: 2.6579e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: iguaba grande, Test Loss: 2.470745812388486e-07, Test MAE: 0.0003424239403102547\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 139ms/step\n",
      "Completed processing for city: iguaba grande\n",
      "\n",
      "Processing city: itaboraí\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 53ms/step - loss: 7.6474e-04 - mae: 0.0217 - val_loss: 1.2162e-04 - val_mae: 0.0094\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7731e-04 - mae: 0.0129 - val_loss: 9.9053e-05 - val_mae: 0.0090\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4702e-04 - mae: 0.0092 - val_loss: 1.9952e-05 - val_mae: 0.0040\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.3121e-05 - mae: 0.0070 - val_loss: 3.7978e-05 - val_mae: 0.0060\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.0386e-05 - mae: 0.0057 - val_loss: 1.9523e-05 - val_mae: 0.0043\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.6147e-05 - mae: 0.0055 - val_loss: 1.9909e-05 - val_mae: 0.0044\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.6312e-05 - mae: 0.0046 - val_loss: 2.3989e-05 - val_mae: 0.0048\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.8275e-05 - mae: 0.0043 - val_loss: 3.5580e-05 - val_mae: 0.0059\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9116e-05 - mae: 0.0044 - val_loss: 1.8350e-05 - val_mae: 0.0042\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6009e-05 - mae: 0.0038 - val_loss: 1.4994e-05 - val_mae: 0.0038\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8484e-05 - mae: 0.0036 - val_loss: 1.6380e-05 - val_mae: 0.0040\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9978e-05 - mae: 0.0036 - val_loss: 2.0340e-05 - val_mae: 0.0045\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.1684e-05 - mae: 0.0037 - val_loss: 1.1665e-05 - val_mae: 0.0034\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6339e-05 - mae: 0.0035 - val_loss: 1.1303e-05 - val_mae: 0.0033\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1079e-05 - mae: 0.0035 - val_loss: 1.5679e-05 - val_mae: 0.0039\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1934e-05 - mae: 0.0040 - val_loss: 1.5066e-05 - val_mae: 0.0038\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9700e-05 - mae: 0.0035 - val_loss: 1.0310e-05 - val_mae: 0.0032\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.6431e-05 - mae: 0.0037 - val_loss: 1.1639e-05 - val_mae: 0.0034\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6389e-05 - mae: 0.0036 - val_loss: 5.8699e-06 - val_mae: 0.0024\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9629e-05 - mae: 0.0035 - val_loss: 1.2081e-05 - val_mae: 0.0034\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.4542e-05 - mae: 0.0036 - val_loss: 3.4589e-06 - val_mae: 0.0018\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3307e-05 - mae: 0.0034 - val_loss: 7.0602e-06 - val_mae: 0.0026\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4735e-05 - mae: 0.0030 - val_loss: 1.6801e-05 - val_mae: 0.0041\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1881e-05 - mae: 0.0036 - val_loss: 9.2435e-06 - val_mae: 0.0030\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3035e-05 - mae: 0.0034 - val_loss: 9.4865e-06 - val_mae: 0.0030\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7563e-05 - mae: 0.0032 - val_loss: 2.2251e-05 - val_mae: 0.0047\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9077e-05 - mae: 0.0034 - val_loss: 7.3924e-06 - val_mae: 0.0027\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1877e-05 - mae: 0.0034 - val_loss: 7.9737e-06 - val_mae: 0.0028\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8858e-05 - mae: 0.0031 - val_loss: 2.0312e-05 - val_mae: 0.0045\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3722e-05 - mae: 0.0032 - val_loss: 1.0255e-05 - val_mae: 0.0031\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1670e-05 - mae: 0.0030 - val_loss: 1.9911e-05 - val_mae: 0.0044\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.8799e-05 - mae: 0.0033 - val_loss: 8.0927e-06 - val_mae: 0.0028\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4941e-05 - mae: 0.0029 - val_loss: 2.0021e-05 - val_mae: 0.0044\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.6527e-05 - mae: 0.0032 - val_loss: 1.5147e-05 - val_mae: 0.0038\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7478e-05 - mae: 0.0032 - val_loss: 1.9768e-05 - val_mae: 0.0044\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.0312e-05 - mae: 0.0029 - val_loss: 1.4452e-05 - val_mae: 0.0037\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7242e-05 - mae: 0.0032 - val_loss: 4.1697e-06 - val_mae: 0.0019\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1259e-05 - mae: 0.0032 - val_loss: 2.0722e-06 - val_mae: 0.0012\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8443e-05 - mae: 0.0032 - val_loss: 7.5263e-06 - val_mae: 0.0026\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8744e-05 - mae: 0.0031 - val_loss: 1.2472e-05 - val_mae: 0.0034\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9703e-05 - mae: 0.0033 - val_loss: 1.2628e-05 - val_mae: 0.0035\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0298e-05 - mae: 0.0028 - val_loss: 2.1340e-05 - val_mae: 0.0045\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7745e-05 - mae: 0.0033 - val_loss: 5.1918e-06 - val_mae: 0.0021\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4266e-05 - mae: 0.0028 - val_loss: 6.7325e-06 - val_mae: 0.0024\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9577e-05 - mae: 0.0026 - val_loss: 2.2349e-05 - val_mae: 0.0046\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0872e-05 - mae: 0.0030 - val_loss: 1.8731e-05 - val_mae: 0.0042\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6545e-05 - mae: 0.0031 - val_loss: 6.4381e-06 - val_mae: 0.0023\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6178e-05 - mae: 0.0034 - val_loss: 1.1951e-05 - val_mae: 0.0033\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4032e-05 - mae: 0.0030 - val_loss: 9.1501e-06 - val_mae: 0.0028\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2722e-05 - mae: 0.0030 - val_loss: 7.2356e-06 - val_mae: 0.0024\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.8494e-06 - mae: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: itaboraí, Test Loss: 7.235641078295885e-06, Test MAE: 0.002416723407804966\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 176ms/step\n",
      "Completed processing for city: itaboraí\n",
      "\n",
      "Processing city: itaguaí\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 54ms/step - loss: 6.4659e-04 - mae: 0.0193 - val_loss: 2.7121e-05 - val_mae: 0.0039\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8405e-04 - mae: 0.0107 - val_loss: 2.1631e-05 - val_mae: 0.0039\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.3413e-04 - mae: 0.0093 - val_loss: 4.7623e-05 - val_mae: 0.0055\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.3808e-05 - mae: 0.0076 - val_loss: 1.6036e-05 - val_mae: 0.0031\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.2785e-05 - mae: 0.0072 - val_loss: 1.5659e-05 - val_mae: 0.0031\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2467e-05 - mae: 0.0062 - val_loss: 1.7856e-05 - val_mae: 0.0035\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 5.8366e-05 - mae: 0.0060 - val_loss: 2.2494e-05 - val_mae: 0.0037\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.5948e-05 - mae: 0.0052 - val_loss: 1.3472e-05 - val_mae: 0.0030\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.5482e-05 - mae: 0.0048 - val_loss: 2.0373e-05 - val_mae: 0.0037\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6075e-05 - mae: 0.0045 - val_loss: 1.9839e-05 - val_mae: 0.0037\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8634e-05 - mae: 0.0042 - val_loss: 9.2564e-06 - val_mae: 0.0025\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.7645e-05 - mae: 0.0040 - val_loss: 6.5843e-06 - val_mae: 0.0022\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1504e-05 - mae: 0.0034 - val_loss: 5.3304e-06 - val_mae: 0.0020\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1310e-05 - mae: 0.0032 - val_loss: 1.2615e-05 - val_mae: 0.0032\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5614e-05 - mae: 0.0029 - val_loss: 2.5714e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1492e-05 - mae: 0.0024 - val_loss: 3.4516e-06 - val_mae: 0.0016\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0506e-05 - mae: 0.0023 - val_loss: 3.3282e-06 - val_mae: 0.0017\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.0418e-06 - mae: 0.0020 - val_loss: 2.3452e-06 - val_mae: 0.0014\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.8450e-06 - mae: 0.0020 - val_loss: 1.9326e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9956e-06 - mae: 0.0018 - val_loss: 1.9917e-06 - val_mae: 8.7224e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8755e-06 - mae: 0.0015 - val_loss: 1.3997e-06 - val_mae: 7.2372e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.7283e-06 - mae: 0.0013 - val_loss: 1.5474e-06 - val_mae: 7.3171e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6466e-06 - mae: 0.0015 - val_loss: 2.0374e-06 - val_mae: 0.0013\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7764e-06 - mae: 0.0013 - val_loss: 1.2932e-06 - val_mae: 6.8313e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.8379e-06 - mae: 0.0013 - val_loss: 1.9286e-06 - val_mae: 0.0013\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4454e-06 - mae: 0.0013 - val_loss: 1.3323e-06 - val_mae: 9.5267e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.6361e-06 - mae: 0.0011 - val_loss: 1.3390e-06 - val_mae: 6.7163e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2774e-06 - mae: 0.0012 - val_loss: 1.2692e-06 - val_mae: 9.4625e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4212e-06 - mae: 0.0010 - val_loss: 1.2665e-06 - val_mae: 6.5427e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.5129e-06 - mae: 0.0012 - val_loss: 1.5869e-06 - val_mae: 7.6278e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8466e-06 - mae: 9.0119e-04 - val_loss: 1.0741e-06 - val_mae: 6.2717e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5419e-06 - mae: 0.0010 - val_loss: 1.0090e-06 - val_mae: 6.9554e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8871e-06 - mae: 8.8949e-04 - val_loss: 1.5107e-06 - val_mae: 0.0011\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.4228e-06 - mae: 0.0011 - val_loss: 1.0831e-06 - val_mae: 5.9063e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6646e-06 - mae: 8.0249e-04 - val_loss: 1.8552e-06 - val_mae: 9.4973e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9890e-06 - mae: 0.0011 - val_loss: 9.6334e-07 - val_mae: 7.6224e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7836e-06 - mae: 8.8986e-04 - val_loss: 2.3717e-06 - val_mae: 0.0015\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4740e-06 - mae: 9.7567e-04 - val_loss: 1.0479e-06 - val_mae: 5.6838e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3085e-06 - mae: 9.2646e-04 - val_loss: 9.5628e-07 - val_mae: 5.7213e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.9965e-06 - mae: 9.0522e-04 - val_loss: 9.3736e-07 - val_mae: 5.7444e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9496e-06 - mae: 8.6540e-04 - val_loss: 9.8637e-07 - val_mae: 8.2788e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.9668e-06 - mae: 8.7954e-04 - val_loss: 1.2088e-06 - val_mae: 6.2061e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.9361e-06 - mae: 8.5003e-04 - val_loss: 8.6159e-07 - val_mae: 6.2333e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6918e-06 - mae: 7.9778e-04 - val_loss: 9.8275e-07 - val_mae: 5.3408e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0378e-06 - mae: 9.0867e-04 - val_loss: 1.0517e-06 - val_mae: 5.5096e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9384e-06 - mae: 7.4443e-04 - val_loss: 1.2322e-06 - val_mae: 6.3624e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9363e-06 - mae: 9.9540e-04 - val_loss: 8.5765e-07 - val_mae: 5.6658e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0986e-06 - mae: 8.4285e-04 - val_loss: 1.1128e-06 - val_mae: 5.7482e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6369e-06 - mae: 7.8233e-04 - val_loss: 1.2333e-06 - val_mae: 6.3947e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3248e-06 - mae: 6.3315e-04 - val_loss: 9.7372e-07 - val_mae: 8.5148e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.8836e-07 - mae: 8.5243e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: itaguaí, Test Loss: 9.737158279676805e-07, Test MAE: 0.0008514775545336306\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 196ms/step\n",
      "Completed processing for city: itaguaí\n",
      "\n",
      "Processing city: italva\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - loss: 5.7944e-04 - mae: 0.0183 - val_loss: 4.1857e-05 - val_mae: 0.0052\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6193e-04 - mae: 0.0092 - val_loss: 4.2069e-05 - val_mae: 0.0055\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4833e-05 - mae: 0.0066 - val_loss: 3.5496e-05 - val_mae: 0.0052\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8224e-05 - mae: 0.0054 - val_loss: 3.3645e-05 - val_mae: 0.0047\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9673e-05 - mae: 0.0042 - val_loss: 1.3500e-05 - val_mae: 0.0031\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9825e-05 - mae: 0.0031 - val_loss: 2.4128e-06 - val_mae: 0.0013\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3962e-05 - mae: 0.0027 - val_loss: 1.8808e-06 - val_mae: 0.0011\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.1367e-06 - mae: 0.0021 - val_loss: 1.2601e-06 - val_mae: 9.9742e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2784e-06 - mae: 0.0018 - val_loss: 1.0727e-06 - val_mae: 9.4116e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7712e-06 - mae: 0.0018 - val_loss: 4.2475e-06 - val_mae: 0.0018\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0593e-06 - mae: 0.0015 - val_loss: 7.6325e-07 - val_mae: 7.1534e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7788e-06 - mae: 0.0014 - val_loss: 6.3291e-07 - val_mae: 6.8874e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3820e-06 - mae: 0.0014 - val_loss: 5.6518e-07 - val_mae: 6.1869e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2221e-06 - mae: 0.0011 - val_loss: 8.6964e-07 - val_mae: 7.7134e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6924e-06 - mae: 0.0012 - val_loss: 1.7234e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3498e-06 - mae: 0.0011 - val_loss: 3.9916e-07 - val_mae: 5.3772e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1806e-06 - mae: 9.9280e-04 - val_loss: 8.8727e-07 - val_mae: 7.8679e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9042e-06 - mae: 9.4106e-04 - val_loss: 3.5055e-07 - val_mae: 4.9083e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3165e-06 - mae: 9.5313e-04 - val_loss: 9.5057e-07 - val_mae: 8.2989e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1856e-06 - mae: 9.9765e-04 - val_loss: 4.3882e-07 - val_mae: 5.4631e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0726e-06 - mae: 9.5623e-04 - val_loss: 3.2299e-07 - val_mae: 4.7097e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1766e-06 - mae: 7.8502e-04 - val_loss: 5.0528e-07 - val_mae: 5.7829e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5308e-06 - mae: 8.9265e-04 - val_loss: 4.3604e-07 - val_mae: 5.3174e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4652e-06 - mae: 8.7708e-04 - val_loss: 2.4704e-07 - val_mae: 3.8513e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4110e-06 - mae: 7.8028e-04 - val_loss: 5.0311e-07 - val_mae: 6.0178e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2678e-06 - mae: 7.3786e-04 - val_loss: 7.8256e-07 - val_mae: 7.8823e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4725e-06 - mae: 0.0010 - val_loss: 2.0307e-07 - val_mae: 3.4188e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.7173e-07 - mae: 5.9334e-04 - val_loss: 2.2391e-07 - val_mae: 3.9169e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.2971e-07 - mae: 5.8949e-04 - val_loss: 1.1134e-06 - val_mae: 9.8895e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0562e-06 - mae: 8.1255e-04 - val_loss: 1.1724e-06 - val_mae: 0.0010\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2918e-06 - mae: 7.8270e-04 - val_loss: 2.2111e-07 - val_mae: 3.9000e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.3791e-07 - mae: 6.1336e-04 - val_loss: 2.3366e-07 - val_mae: 4.0302e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0807e-06 - mae: 7.0053e-04 - val_loss: 4.8681e-07 - val_mae: 6.1994e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.3437e-07 - mae: 5.4236e-04 - val_loss: 1.3519e-07 - val_mae: 2.9052e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1254e-06 - mae: 6.8415e-04 - val_loss: 9.7618e-08 - val_mae: 2.3654e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.6777e-07 - mae: 5.3205e-04 - val_loss: 3.3907e-07 - val_mae: 5.0802e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5902e-07 - mae: 5.7914e-04 - val_loss: 1.1764e-06 - val_mae: 0.0010\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2395e-07 - mae: 7.2377e-04 - val_loss: 1.2510e-06 - val_mae: 0.0011\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3354e-06 - mae: 7.7747e-04 - val_loss: 3.6586e-07 - val_mae: 5.5284e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.4661e-07 - mae: 6.2595e-04 - val_loss: 1.1066e-07 - val_mae: 2.7505e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.1708e-07 - mae: 5.5878e-04 - val_loss: 1.0677e-07 - val_mae: 2.4697e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4856e-07 - mae: 5.0714e-04 - val_loss: 3.1559e-07 - val_mae: 5.1353e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1994e-07 - mae: 5.2874e-04 - val_loss: 2.3591e-07 - val_mae: 4.1795e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0436e-06 - mae: 6.4992e-04 - val_loss: 3.6608e-07 - val_mae: 5.4608e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2723e-07 - mae: 6.8227e-04 - val_loss: 1.1004e-07 - val_mae: 2.8662e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6499e-07 - mae: 5.2103e-04 - val_loss: 3.6370e-07 - val_mae: 5.4780e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3006e-06 - mae: 7.3991e-04 - val_loss: 2.3633e-07 - val_mae: 4.4486e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.5064e-07 - mae: 6.8657e-04 - val_loss: 3.1932e-07 - val_mae: 5.0884e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1694e-06 - mae: 7.5885e-04 - val_loss: 2.7423e-07 - val_mae: 4.6465e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.0034e-07 - mae: 6.7225e-04 - val_loss: 1.8454e-07 - val_mae: 3.9218e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.8287e-07 - mae: 3.9857e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: italva, Test Loss: 1.8453779659921565e-07, Test MAE: 0.00039218380698002875\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 175ms/step\n",
      "Completed processing for city: italva\n",
      "\n",
      "Processing city: itaocara\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 1.3731e-04 - val_mae: 0.0089\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7235e-04 - mae: 0.0131 - val_loss: 5.9645e-05 - val_mae: 0.0064\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0768e-04 - mae: 0.0114 - val_loss: 2.2167e-05 - val_mae: 0.0039\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6251e-04 - mae: 0.0100 - val_loss: 1.9932e-05 - val_mae: 0.0038\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1396e-04 - mae: 0.0080 - val_loss: 1.8229e-05 - val_mae: 0.0037\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.9994e-05 - mae: 0.0069 - val_loss: 1.1061e-05 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.1620e-05 - mae: 0.0051 - val_loss: 1.2884e-05 - val_mae: 0.0030\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7575e-05 - mae: 0.0043 - val_loss: 9.8012e-06 - val_mae: 0.0030\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3739e-05 - mae: 0.0036 - val_loss: 5.0354e-06 - val_mae: 0.0022\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2129e-05 - mae: 0.0025 - val_loss: 3.6839e-06 - val_mae: 0.0019\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0710e-05 - mae: 0.0020 - val_loss: 5.5357e-07 - val_mae: 7.1712e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.1780e-06 - mae: 0.0018 - val_loss: 2.4817e-07 - val_mae: 3.5186e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.7294e-06 - mae: 0.0012 - val_loss: 2.6233e-06 - val_mae: 0.0016\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0485e-06 - mae: 0.0015 - val_loss: 2.9678e-07 - val_mae: 2.4498e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0334e-06 - mae: 8.9759e-04 - val_loss: 1.3328e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.8571e-06 - mae: 0.0010 - val_loss: 7.0209e-07 - val_mae: 6.8215e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0029e-06 - mae: 9.6340e-04 - val_loss: 2.5388e-07 - val_mae: 2.1560e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6854e-06 - mae: 8.0820e-04 - val_loss: 2.5834e-07 - val_mae: 3.8021e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7433e-06 - mae: 6.7441e-04 - val_loss: 6.9927e-07 - val_mae: 6.8008e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6279e-06 - mae: 6.6866e-04 - val_loss: 3.6953e-07 - val_mae: 5.5122e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2194e-06 - mae: 7.6510e-04 - val_loss: 1.5033e-06 - val_mae: 0.0011\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3221e-06 - mae: 9.1519e-04 - val_loss: 2.5618e-07 - val_mae: 2.1208e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.5913e-07 - mae: 4.5016e-04 - val_loss: 5.0091e-07 - val_mae: 5.1395e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5798e-06 - mae: 7.1787e-04 - val_loss: 2.4253e-07 - val_mae: 2.3974e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5270e-06 - mae: 5.4481e-04 - val_loss: 3.9996e-07 - val_mae: 5.8369e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2592e-06 - mae: 5.7278e-04 - val_loss: 3.5470e-07 - val_mae: 3.4342e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5651e-07 - mae: 4.4328e-04 - val_loss: 3.1041e-07 - val_mae: 2.7137e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.5137e-07 - mae: 4.8424e-04 - val_loss: 2.7078e-07 - val_mae: 2.0847e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2259e-06 - mae: 4.5902e-04 - val_loss: 2.3767e-07 - val_mae: 3.0107e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0470e-06 - mae: 6.0781e-04 - val_loss: 8.0431e-07 - val_mae: 7.5336e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4886e-06 - mae: 7.0483e-04 - val_loss: 1.4185e-06 - val_mae: 0.0011\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1407e-06 - mae: 6.5721e-04 - val_loss: 2.3692e-07 - val_mae: 2.7476e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 7.4952e-07 - mae: 5.0771e-04 - val_loss: 4.4042e-07 - val_mae: 6.2341e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.3815e-06 - mae: 7.2080e-04 - val_loss: 5.5677e-07 - val_mae: 7.1951e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.8641e-07 - mae: 4.9982e-04 - val_loss: 5.7506e-07 - val_mae: 7.3290e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7259e-07 - mae: 4.6352e-04 - val_loss: 2.9363e-07 - val_mae: 4.5056e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.6951e-07 - mae: 4.1881e-04 - val_loss: 7.8986e-07 - val_mae: 8.6904e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 7.6931e-07 - mae: 5.1036e-04 - val_loss: 4.1946e-07 - val_mae: 4.2743e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.1608e-07 - mae: 5.5009e-04 - val_loss: 2.4634e-07 - val_mae: 2.3010e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.3892e-07 - mae: 6.3649e-04 - val_loss: 3.6843e-07 - val_mae: 3.6286e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 6.7427e-07 - mae: 5.1113e-04 - val_loss: 4.4451e-07 - val_mae: 4.5579e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3103e-06 - mae: 7.2630e-04 - val_loss: 5.8995e-07 - val_mae: 5.9429e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.6387e-07 - mae: 5.3869e-04 - val_loss: 2.3819e-07 - val_mae: 2.6051e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3403e-06 - mae: 6.0532e-04 - val_loss: 6.8213e-07 - val_mae: 8.0491e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0608e-06 - mae: 7.5902e-04 - val_loss: 7.4141e-07 - val_mae: 7.1039e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.0937e-07 - mae: 6.1238e-04 - val_loss: 2.6080e-07 - val_mae: 3.8640e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6827e-07 - mae: 5.2219e-04 - val_loss: 3.5302e-07 - val_mae: 3.4096e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.1266e-07 - mae: 4.5636e-04 - val_loss: 2.8291e-07 - val_mae: 4.3212e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9502e-07 - mae: 3.7191e-04 - val_loss: 6.1380e-07 - val_mae: 7.6012e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2302e-06 - mae: 6.1108e-04 - val_loss: 5.2401e-07 - val_mae: 5.3595e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8210e-07 - mae: 5.0932e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: itaocara, Test Loss: 5.240058840172424e-07, Test MAE: 0.0005359479691833258\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 146ms/step\n",
      "Completed processing for city: itaocara\n",
      "\n",
      "Processing city: itaperuna\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - loss: 8.9059e-04 - mae: 0.0225 - val_loss: 5.4731e-05 - val_mae: 0.0064\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1852e-04 - mae: 0.0136 - val_loss: 3.2601e-05 - val_mae: 0.0049\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5840e-04 - mae: 0.0093 - val_loss: 1.6270e-05 - val_mae: 0.0034\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.9214e-05 - mae: 0.0075 - val_loss: 1.3908e-05 - val_mae: 0.0030\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.0558e-05 - mae: 0.0066 - val_loss: 1.5196e-05 - val_mae: 0.0033\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6265e-05 - mae: 0.0057 - val_loss: 1.2407e-05 - val_mae: 0.0029\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.8744e-05 - mae: 0.0058 - val_loss: 1.0538e-05 - val_mae: 0.0026\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.0394e-05 - mae: 0.0055 - val_loss: 2.3139e-05 - val_mae: 0.0043\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8530e-05 - mae: 0.0059 - val_loss: 9.2936e-06 - val_mae: 0.0025\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.1991e-05 - mae: 0.0047 - val_loss: 1.2302e-05 - val_mae: 0.0030\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8268e-05 - mae: 0.0047 - val_loss: 1.2445e-05 - val_mae: 0.0029\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8428e-05 - mae: 0.0045 - val_loss: 8.7815e-06 - val_mae: 0.0023\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0431e-05 - mae: 0.0045 - val_loss: 1.0899e-05 - val_mae: 0.0027\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8155e-05 - mae: 0.0045 - val_loss: 2.0183e-05 - val_mae: 0.0040\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.8526e-05 - mae: 0.0042 - val_loss: 7.5288e-06 - val_mae: 0.0022\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8120e-05 - mae: 0.0043 - val_loss: 1.2796e-05 - val_mae: 0.0031\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9782e-05 - mae: 0.0044 - val_loss: 1.0919e-05 - val_mae: 0.0028\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3032e-05 - mae: 0.0041 - val_loss: 1.1999e-05 - val_mae: 0.0030\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8746e-05 - mae: 0.0044 - val_loss: 7.5479e-06 - val_mae: 0.0023\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4404e-05 - mae: 0.0038 - val_loss: 9.3545e-06 - val_mae: 0.0026\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9713e-05 - mae: 0.0039 - val_loss: 6.0149e-06 - val_mae: 0.0020\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.2938e-05 - mae: 0.0041 - val_loss: 5.0602e-06 - val_mae: 0.0018\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3467e-05 - mae: 0.0035 - val_loss: 9.6364e-06 - val_mae: 0.0026\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.6103e-05 - mae: 0.0040 - val_loss: 9.4065e-06 - val_mae: 0.0026\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0508e-05 - mae: 0.0033 - val_loss: 1.6858e-05 - val_mae: 0.0036\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.3677e-05 - mae: 0.0035 - val_loss: 1.3480e-05 - val_mae: 0.0031\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6087e-05 - mae: 0.0040 - val_loss: 6.0120e-06 - val_mae: 0.0020\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6452e-05 - mae: 0.0035 - val_loss: 8.2266e-06 - val_mae: 0.0024\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0453e-05 - mae: 0.0039 - val_loss: 8.7313e-06 - val_mae: 0.0025\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.4101e-05 - mae: 0.0037 - val_loss: 4.2479e-06 - val_mae: 0.0017\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.1369e-05 - mae: 0.0038 - val_loss: 7.3319e-06 - val_mae: 0.0022\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.3219e-05 - mae: 0.0041 - val_loss: 4.1009e-06 - val_mae: 0.0017\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.3235e-05 - mae: 0.0032 - val_loss: 7.7068e-06 - val_mae: 0.0023\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2471e-05 - mae: 0.0037 - val_loss: 5.1000e-06 - val_mae: 0.0019\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0181e-05 - mae: 0.0036 - val_loss: 6.1703e-06 - val_mae: 0.0021\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4883e-05 - mae: 0.0034 - val_loss: 4.8620e-06 - val_mae: 0.0018\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8157e-05 - mae: 0.0034 - val_loss: 5.8851e-06 - val_mae: 0.0020\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4482e-05 - mae: 0.0027 - val_loss: 2.0583e-05 - val_mae: 0.0041\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9942e-05 - mae: 0.0038 - val_loss: 5.8792e-06 - val_mae: 0.0020\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9311e-05 - mae: 0.0030 - val_loss: 6.1493e-06 - val_mae: 0.0021\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9011e-05 - mae: 0.0036 - val_loss: 5.7144e-06 - val_mae: 0.0020\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.3760e-05 - mae: 0.0037 - val_loss: 3.7426e-06 - val_mae: 0.0016\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4.5762e-05 - mae: 0.0035 - val_loss: 5.3999e-06 - val_mae: 0.0019\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5613e-05 - mae: 0.0033 - val_loss: 4.2722e-06 - val_mae: 0.0017\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7133e-05 - mae: 0.0032 - val_loss: 1.0800e-05 - val_mae: 0.0028\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4125e-05 - mae: 0.0038 - val_loss: 3.6974e-06 - val_mae: 0.0016\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5551e-05 - mae: 0.0032 - val_loss: 8.7579e-06 - val_mae: 0.0025\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0984e-05 - mae: 0.0037 - val_loss: 7.4889e-06 - val_mae: 0.0023\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6236e-05 - mae: 0.0034 - val_loss: 1.3991e-05 - val_mae: 0.0033\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.6974e-05 - mae: 0.0035 - val_loss: 3.7937e-06 - val_mae: 0.0016\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.5793e-06 - mae: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: itaperuna, Test Loss: 3.7936563330731587e-06, Test MAE: 0.001622035983018577\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 141ms/step\n",
      "Completed processing for city: itaperuna\n",
      "\n",
      "Processing city: itatiaia\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - loss: 6.8576e-04 - mae: 0.0202 - val_loss: 9.1275e-05 - val_mae: 0.0076\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3060e-04 - mae: 0.0120 - val_loss: 4.0024e-05 - val_mae: 0.0053\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6220e-04 - mae: 0.0099 - val_loss: 6.3697e-05 - val_mae: 0.0058\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2910e-04 - mae: 0.0087 - val_loss: 1.3367e-05 - val_mae: 0.0030\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0332e-04 - mae: 0.0081 - val_loss: 8.0435e-06 - val_mae: 0.0024\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.8109e-05 - mae: 0.0065 - val_loss: 1.1245e-05 - val_mae: 0.0029\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3330e-05 - mae: 0.0057 - val_loss: 5.8705e-06 - val_mae: 0.0020\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6573e-05 - mae: 0.0051 - val_loss: 1.3512e-05 - val_mae: 0.0031\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7408e-05 - mae: 0.0039 - val_loss: 8.9926e-06 - val_mae: 0.0025\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1436e-05 - mae: 0.0034 - val_loss: 1.0398e-05 - val_mae: 0.0030\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7045e-05 - mae: 0.0028 - val_loss: 8.8903e-07 - val_mae: 8.3597e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3423e-05 - mae: 0.0024 - val_loss: 2.1356e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.7969e-06 - mae: 0.0021 - val_loss: 4.4513e-07 - val_mae: 5.9088e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.9910e-06 - mae: 0.0019 - val_loss: 7.4327e-07 - val_mae: 7.5941e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6531e-06 - mae: 0.0018 - val_loss: 2.2518e-07 - val_mae: 3.2835e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.1286e-06 - mae: 0.0017 - val_loss: 1.8784e-06 - val_mae: 0.0013\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.0378e-06 - mae: 0.0013 - val_loss: 4.3451e-06 - val_mae: 0.0021\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.5819e-06 - mae: 0.0015 - val_loss: 2.7685e-07 - val_mae: 4.7236e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3983e-06 - mae: 0.0012 - val_loss: 2.2170e-07 - val_mae: 4.2702e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.8184e-06 - mae: 0.0012 - val_loss: 2.8635e-07 - val_mae: 4.7459e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.3168e-06 - mae: 0.0011 - val_loss: 1.9253e-06 - val_mae: 0.0014\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0527e-06 - mae: 0.0012 - val_loss: 1.6892e-06 - val_mae: 0.0013\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8278e-06 - mae: 0.0011 - val_loss: 3.6788e-07 - val_mae: 5.3606e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6728e-06 - mae: 0.0011 - val_loss: 5.1639e-06 - val_mae: 0.0023\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8977e-06 - mae: 0.0012 - val_loss: 2.9191e-07 - val_mae: 4.7776e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6789e-06 - mae: 7.4476e-04 - val_loss: 1.8916e-07 - val_mae: 3.8926e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7185e-06 - mae: 0.0010 - val_loss: 4.7662e-07 - val_mae: 6.3210e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4704e-06 - mae: 9.1982e-04 - val_loss: 4.7587e-07 - val_mae: 6.3451e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5932e-06 - mae: 9.3633e-04 - val_loss: 1.9458e-07 - val_mae: 3.9195e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4040e-06 - mae: 9.5704e-04 - val_loss: 1.9562e-07 - val_mae: 3.9257e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6340e-06 - mae: 9.5479e-04 - val_loss: 1.0202e-06 - val_mae: 9.7945e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.7953e-06 - mae: 9.9685e-04 - val_loss: 5.7454e-08 - val_mae: 2.0853e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5286e-06 - mae: 8.8121e-04 - val_loss: 2.9172e-07 - val_mae: 4.8787e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.1010e-06 - mae: 8.1634e-04 - val_loss: 1.6849e-07 - val_mae: 3.6384e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4570e-06 - mae: 9.8051e-04 - val_loss: 1.1228e-07 - val_mae: 3.0084e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.7943e-06 - mae: 7.1782e-04 - val_loss: 1.1631e-07 - val_mae: 3.0517e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9706e-06 - mae: 7.9059e-04 - val_loss: 7.1877e-08 - val_mae: 2.4668e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7319e-06 - mae: 6.9573e-04 - val_loss: 4.9591e-08 - val_mae: 1.6847e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7002e-06 - mae: 7.0701e-04 - val_loss: 8.9334e-08 - val_mae: 2.1551e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 2.2779e-06 - mae: 8.3833e-04 - val_loss: 2.7754e-07 - val_mae: 4.8658e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.7821e-06 - mae: 8.3784e-04 - val_loss: 1.0965e-07 - val_mae: 2.6516e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.8708e-06 - mae: 7.3875e-04 - val_loss: 1.6500e-06 - val_mae: 0.0013\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8727e-06 - mae: 9.0719e-04 - val_loss: 1.0332e-07 - val_mae: 2.8543e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0209e-06 - mae: 8.2715e-04 - val_loss: 1.7422e-07 - val_mae: 3.7260e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0914e-06 - mae: 8.5919e-04 - val_loss: 1.5888e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2244e-06 - mae: 9.3403e-04 - val_loss: 3.3995e-07 - val_mae: 5.5368e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9756e-06 - mae: 8.4277e-04 - val_loss: 4.4225e-08 - val_mae: 1.4574e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5826e-06 - mae: 8.8813e-04 - val_loss: 3.5341e-08 - val_mae: 1.7364e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.1705e-06 - mae: 8.4186e-04 - val_loss: 8.7931e-08 - val_mae: 2.6280e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 2.0308e-06 - mae: 7.4800e-04 - val_loss: 8.4552e-07 - val_mae: 9.0347e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 8.9419e-07 - mae: 9.3224e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: itatiaia, Test Loss: 8.455234024040692e-07, Test MAE: 0.0009034655522555113\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 164ms/step\n",
      "Completed processing for city: itatiaia\n",
      "\n",
      "Processing city: japeri\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 58ms/step - loss: 6.3388e-04 - mae: 0.0185 - val_loss: 1.3465e-04 - val_mae: 0.0093\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7777e-04 - mae: 0.0097 - val_loss: 6.1264e-05 - val_mae: 0.0064\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0260e-04 - mae: 0.0074 - val_loss: 7.9680e-05 - val_mae: 0.0073\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5305e-05 - mae: 0.0046 - val_loss: 3.2081e-05 - val_mae: 0.0044\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7929e-05 - mae: 0.0032 - val_loss: 5.3717e-06 - val_mae: 0.0018\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7239e-05 - mae: 0.0026 - val_loss: 6.1091e-06 - val_mae: 0.0019\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.4261e-06 - mae: 0.0019 - val_loss: 6.2813e-06 - val_mae: 0.0022\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.2997e-06 - mae: 0.0016 - val_loss: 2.8504e-06 - val_mae: 0.0014\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 8.5742e-06 - mae: 0.0017 - val_loss: 7.5507e-07 - val_mae: 6.6326e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.2810e-06 - mae: 0.0010 - val_loss: 1.5696e-06 - val_mae: 0.0010\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3493e-06 - mae: 0.0011 - val_loss: 4.6337e-07 - val_mae: 5.5982e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7544e-06 - mae: 0.0010 - val_loss: 7.9311e-07 - val_mae: 7.7491e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.2664e-06 - mae: 0.0010 - val_loss: 1.0066e-06 - val_mae: 7.7949e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.9540e-06 - mae: 0.0010 - val_loss: 4.2622e-07 - val_mae: 5.4786e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6181e-06 - mae: 8.3588e-04 - val_loss: 4.8039e-07 - val_mae: 5.8210e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4340e-06 - mae: 7.6117e-04 - val_loss: 2.5726e-06 - val_mae: 0.0015\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.2766e-06 - mae: 0.0011 - val_loss: 8.4646e-07 - val_mae: 7.4189e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.2752e-06 - mae: 7.2086e-04 - val_loss: 2.5884e-06 - val_mae: 0.0015\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7725e-06 - mae: 9.1197e-04 - val_loss: 4.3452e-07 - val_mae: 4.9882e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.8364e-06 - mae: 8.0670e-04 - val_loss: 2.5553e-06 - val_mae: 0.0015\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2603e-06 - mae: 9.1482e-04 - val_loss: 9.2955e-07 - val_mae: 8.3111e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1347e-06 - mae: 6.8998e-04 - val_loss: 4.9701e-07 - val_mae: 6.0223e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.9605e-06 - mae: 8.0667e-04 - val_loss: 4.1333e-07 - val_mae: 4.8227e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3991e-06 - mae: 6.8912e-04 - val_loss: 9.9422e-07 - val_mae: 9.1315e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8089e-06 - mae: 9.1490e-04 - val_loss: 5.2706e-07 - val_mae: 5.8527e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6900e-06 - mae: 7.6986e-04 - val_loss: 3.3735e-07 - val_mae: 4.8420e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1509e-06 - mae: 6.3161e-04 - val_loss: 3.6587e-07 - val_mae: 5.1198e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5498e-06 - mae: 7.9661e-04 - val_loss: 1.5852e-07 - val_mae: 3.3953e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1122e-06 - mae: 6.7507e-04 - val_loss: 8.6224e-07 - val_mae: 8.4321e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1107e-06 - mae: 6.5812e-04 - val_loss: 8.1397e-07 - val_mae: 8.3486e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.1968e-06 - mae: 7.9024e-04 - val_loss: 5.2226e-07 - val_mae: 6.4928e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0325e-06 - mae: 7.6739e-04 - val_loss: 3.0582e-07 - val_mae: 4.1745e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5469e-06 - mae: 6.8915e-04 - val_loss: 2.9757e-07 - val_mae: 4.6562e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.5911e-07 - mae: 6.9993e-04 - val_loss: 1.7747e-07 - val_mae: 3.1704e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3245e-06 - mae: 6.0469e-04 - val_loss: 4.5235e-06 - val_mae: 0.0021\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6707e-06 - mae: 8.2129e-04 - val_loss: 2.0506e-07 - val_mae: 3.3477e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.4846e-07 - mae: 6.7669e-04 - val_loss: 1.4053e-07 - val_mae: 2.8592e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4523e-06 - mae: 7.0409e-04 - val_loss: 1.3891e-07 - val_mae: 3.0842e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 6.8768e-07 - mae: 5.2379e-04 - val_loss: 5.9779e-07 - val_mae: 7.2106e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 8.3661e-07 - mae: 6.7770e-04 - val_loss: 1.0040e-07 - val_mae: 2.5638e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.6506e-07 - mae: 6.3342e-04 - val_loss: 9.8729e-08 - val_mae: 2.6512e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.3925e-06 - mae: 6.9919e-04 - val_loss: 5.2422e-07 - val_mae: 6.6018e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.0488e-07 - mae: 5.5410e-04 - val_loss: 5.5534e-07 - val_mae: 6.8440e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2979e-06 - mae: 6.1096e-04 - val_loss: 6.8766e-07 - val_mae: 7.7647e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.4337e-07 - mae: 5.9062e-04 - val_loss: 1.4314e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1213e-06 - mae: 7.2086e-04 - val_loss: 1.5230e-07 - val_mae: 2.8593e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0346e-07 - mae: 4.6652e-04 - val_loss: 2.0382e-07 - val_mae: 3.9386e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2065e-07 - mae: 6.1251e-04 - val_loss: 4.4382e-07 - val_mae: 6.0646e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.5231e-07 - mae: 6.3701e-04 - val_loss: 3.8808e-07 - val_mae: 5.7810e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.7606e-07 - mae: 5.9899e-04 - val_loss: 4.4791e-07 - val_mae: 6.1483e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4.1637e-07 - mae: 5.9956e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: japeri, Test Loss: 4.479096276099881e-07, Test MAE: 0.0006148297688923776\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 140ms/step\n",
      "Completed processing for city: japeri\n",
      "\n",
      "Processing city: laje do muriaé\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 55ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 2.2982e-04 - val_mae: 0.0133\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7319e-04 - mae: 0.0170 - val_loss: 2.5141e-04 - val_mae: 0.0133\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5823e-04 - mae: 0.0145 - val_loss: 1.0023e-04 - val_mae: 0.0088\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3065e-04 - mae: 0.0118 - val_loss: 6.1610e-05 - val_mae: 0.0067\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4244e-04 - mae: 0.0094 - val_loss: 5.4449e-05 - val_mae: 0.0060\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1695e-04 - mae: 0.0081 - val_loss: 1.9208e-05 - val_mae: 0.0036\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7826e-05 - mae: 0.0058 - val_loss: 1.9245e-05 - val_mae: 0.0035\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9418e-05 - mae: 0.0051 - val_loss: 1.3250e-05 - val_mae: 0.0027\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3867e-05 - mae: 0.0042 - val_loss: 6.4010e-06 - val_mae: 0.0024\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7147e-05 - mae: 0.0030 - val_loss: 1.9519e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.1511e-06 - mae: 0.0020 - val_loss: 3.5022e-06 - val_mae: 0.0018\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2477e-06 - mae: 0.0017 - val_loss: 6.2799e-07 - val_mae: 7.5965e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4091e-06 - mae: 0.0015 - val_loss: 8.6896e-07 - val_mae: 8.5041e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2382e-06 - mae: 0.0014 - val_loss: 7.4363e-08 - val_mae: 2.5024e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9517e-06 - mae: 0.0013 - val_loss: 4.4654e-08 - val_mae: 1.7268e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9538e-06 - mae: 7.4065e-04 - val_loss: 1.6912e-06 - val_mae: 0.0013\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.2173e-06 - mae: 0.0011 - val_loss: 1.1277e-06 - val_mae: 0.0011\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2482e-06 - mae: 8.1329e-04 - val_loss: 4.2506e-08 - val_mae: 2.0216e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6293e-06 - mae: 6.5356e-04 - val_loss: 1.2945e-07 - val_mae: 3.5264e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.5098e-07 - mae: 6.4946e-04 - val_loss: 1.7294e-06 - val_mae: 0.0013\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4849e-06 - mae: 8.9720e-04 - val_loss: 8.1565e-09 - val_mae: 5.5021e-05\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5486e-06 - mae: 7.3663e-04 - val_loss: 2.0304e-07 - val_mae: 4.4490e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.9975e-07 - mae: 5.9984e-04 - val_loss: 1.8485e-07 - val_mae: 4.2413e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.4405e-07 - mae: 6.1835e-04 - val_loss: 1.7537e-08 - val_mae: 1.1262e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.5960e-07 - mae: 5.1558e-04 - val_loss: 7.2498e-09 - val_mae: 4.9976e-05\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0017e-06 - mae: 4.8341e-04 - val_loss: 5.6401e-08 - val_mae: 2.3233e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0638e-06 - mae: 6.5250e-04 - val_loss: 1.2492e-06 - val_mae: 0.0011\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1870e-07 - mae: 5.3893e-04 - val_loss: 1.5318e-06 - val_mae: 0.0012\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3065e-06 - mae: 7.4020e-04 - val_loss: 1.5265e-08 - val_mae: 1.0286e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.4340e-07 - mae: 3.6015e-04 - val_loss: 3.3375e-07 - val_mae: 5.7365e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1218e-07 - mae: 5.6157e-04 - val_loss: 1.0540e-08 - val_mae: 7.6427e-05\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0301e-07 - mae: 4.0393e-04 - val_loss: 7.4114e-09 - val_mae: 7.7586e-05\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5723e-07 - mae: 2.9798e-04 - val_loss: 4.6552e-08 - val_mae: 2.0470e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.3486e-07 - mae: 3.8231e-04 - val_loss: 3.6280e-08 - val_mae: 1.8677e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7710e-07 - mae: 5.5526e-04 - val_loss: 5.0452e-09 - val_mae: 2.5221e-05\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7039e-07 - mae: 2.3571e-04 - val_loss: 4.9809e-08 - val_mae: 2.1242e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5702e-07 - mae: 4.0144e-04 - val_loss: 7.4692e-09 - val_mae: 5.3187e-05\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8230e-07 - mae: 4.2147e-04 - val_loss: 8.1354e-09 - val_mae: 5.9340e-05\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.9610e-07 - mae: 5.3992e-04 - val_loss: 1.6811e-07 - val_mae: 4.0439e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9511e-07 - mae: 4.1452e-04 - val_loss: 7.4259e-09 - val_mae: 7.8106e-05\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0378e-06 - mae: 4.9945e-04 - val_loss: 1.7271e-08 - val_mae: 1.1254e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3808e-07 - mae: 3.1317e-04 - val_loss: 1.4897e-06 - val_mae: 0.0012\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0787e-06 - mae: 7.3517e-04 - val_loss: 5.3724e-08 - val_mae: 2.2170e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.0403e-07 - mae: 5.0947e-04 - val_loss: 5.7691e-08 - val_mae: 2.3052e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0211e-06 - mae: 5.9239e-04 - val_loss: 1.7119e-07 - val_mae: 4.0827e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.0336e-07 - mae: 6.3874e-04 - val_loss: 2.9123e-07 - val_mae: 5.3550e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3115e-07 - mae: 4.6998e-04 - val_loss: 7.6063e-09 - val_mae: 5.5910e-05\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4691e-07 - mae: 3.4281e-04 - val_loss: 9.3259e-08 - val_mae: 2.9865e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.4796e-07 - mae: 4.9270e-04 - val_loss: 1.7085e-07 - val_mae: 4.0785e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.4913e-07 - mae: 5.3662e-04 - val_loss: 1.7735e-07 - val_mae: 4.1576e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8265e-07 - mae: 4.2387e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: laje do muriaé, Test Loss: 1.773479993971705e-07, Test MAE: 0.0004157610528636724\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 136ms/step\n",
      "Completed processing for city: laje do muriaé\n",
      "\n",
      "Processing city: macaé\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 52ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 4.0821e-05 - val_mae: 0.0053\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.2080e-04 - mae: 0.0117 - val_loss: 1.2161e-05 - val_mae: 0.0029\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5238e-04 - mae: 0.0096 - val_loss: 1.9782e-05 - val_mae: 0.0037\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1977e-04 - mae: 0.0082 - val_loss: 1.0121e-05 - val_mae: 0.0027\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.6290e-05 - mae: 0.0066 - val_loss: 1.0387e-05 - val_mae: 0.0028\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.0763e-05 - mae: 0.0059 - val_loss: 6.8771e-06 - val_mae: 0.0021\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9671e-05 - mae: 0.0055 - val_loss: 1.0612e-05 - val_mae: 0.0026\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1283e-05 - mae: 0.0045 - val_loss: 7.7982e-06 - val_mae: 0.0024\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9458e-05 - mae: 0.0038 - val_loss: 8.2756e-06 - val_mae: 0.0024\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1657e-05 - mae: 0.0036 - val_loss: 7.8864e-06 - val_mae: 0.0022\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0346e-05 - mae: 0.0029 - val_loss: 5.0189e-06 - val_mae: 0.0019\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0596e-05 - mae: 0.0028 - val_loss: 4.1814e-06 - val_mae: 0.0017\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8584e-05 - mae: 0.0026 - val_loss: 2.6915e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9026e-05 - mae: 0.0025 - val_loss: 2.5498e-06 - val_mae: 0.0011\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2358e-05 - mae: 0.0021 - val_loss: 4.3247e-06 - val_mae: 0.0019\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.6478e-05 - mae: 0.0024 - val_loss: 1.9567e-06 - val_mae: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6381e-05 - mae: 0.0022 - val_loss: 1.9839e-06 - val_mae: 0.0011\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8190e-05 - mae: 0.0021 - val_loss: 1.9603e-06 - val_mae: 9.1798e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 2.5667e-05 - mae: 0.0025 - val_loss: 2.4261e-06 - val_mae: 0.0014\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1701e-05 - mae: 0.0019 - val_loss: 1.9392e-06 - val_mae: 9.5472e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1680e-05 - mae: 0.0018 - val_loss: 2.8649e-06 - val_mae: 9.7714e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3577e-05 - mae: 0.0019 - val_loss: 1.9405e-06 - val_mae: 9.5254e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5525e-05 - mae: 0.0019 - val_loss: 1.9557e-06 - val_mae: 9.1879e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0336e-05 - mae: 0.0022 - val_loss: 1.9814e-06 - val_mae: 8.8446e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1451e-05 - mae: 0.0016 - val_loss: 2.7126e-06 - val_mae: 0.0015\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7790e-05 - mae: 0.0020 - val_loss: 2.3232e-06 - val_mae: 7.9890e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1979e-05 - mae: 0.0017 - val_loss: 2.8464e-06 - val_mae: 0.0016\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8058e-05 - mae: 0.0021 - val_loss: 2.0073e-06 - val_mae: 0.0010\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6132e-05 - mae: 0.0019 - val_loss: 2.0646e-06 - val_mae: 8.3429e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1695e-05 - mae: 0.0017 - val_loss: 2.3600e-06 - val_mae: 0.0013\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3700e-05 - mae: 0.0018 - val_loss: 2.1396e-06 - val_mae: 8.1400e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6476e-05 - mae: 0.0018 - val_loss: 2.9878e-06 - val_mae: 0.0016\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4010e-05 - mae: 0.0019 - val_loss: 2.3870e-06 - val_mae: 0.0013\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5676e-05 - mae: 0.0021 - val_loss: 3.0775e-06 - val_mae: 0.0016\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.2524e-05 - mae: 0.0018 - val_loss: 2.1535e-06 - val_mae: 0.0012\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.4918e-06 - mae: 0.0015 - val_loss: 2.2077e-06 - val_mae: 0.0012\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0943e-05 - mae: 0.0020 - val_loss: 2.0693e-06 - val_mae: 8.5231e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.9554e-05 - mae: 0.0020 - val_loss: 2.0022e-06 - val_mae: 9.9687e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8364e-05 - mae: 0.0020 - val_loss: 2.3443e-06 - val_mae: 0.0013\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3761e-05 - mae: 0.0018 - val_loss: 2.0009e-06 - val_mae: 9.9091e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1933e-05 - mae: 0.0016 - val_loss: 2.2687e-06 - val_mae: 7.9637e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5327e-05 - mae: 0.0018 - val_loss: 2.0330e-06 - val_mae: 8.8348e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3382e-05 - mae: 0.0017 - val_loss: 2.0056e-06 - val_mae: 9.2606e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1.8620e-05 - mae: 0.0019 - val_loss: 2.0932e-06 - val_mae: 8.3761e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 8.5934e-06 - mae: 0.0014 - val_loss: 3.4416e-06 - val_mae: 0.0018\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0607e-05 - mae: 0.0021 - val_loss: 2.6265e-06 - val_mae: 0.0015\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.7617e-06 - mae: 0.0015 - val_loss: 3.3253e-06 - val_mae: 0.0017\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.8656e-06 - mae: 0.0017 - val_loss: 9.3215e-06 - val_mae: 0.0029\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.2390e-05 - mae: 0.0020 - val_loss: 2.1191e-06 - val_mae: 8.2419e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.2648e-06 - mae: 0.0014 - val_loss: 2.7215e-06 - val_mae: 0.0015\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 2.6955e-06 - mae: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: macaé, Test Loss: 2.7215053250984056e-06, Test MAE: 0.001505051739513874\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 143ms/step\n",
      "Completed processing for city: macaé\n",
      "\n",
      "Processing city: macuco\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 47ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 2.9861e-04 - val_mae: 0.0153\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1633e-04 - mae: 0.0114 - val_loss: 1.2868e-04 - val_mae: 0.0103\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2381e-04 - mae: 0.0087 - val_loss: 1.6270e-04 - val_mae: 0.0121\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.0455e-05 - mae: 0.0070 - val_loss: 5.1045e-05 - val_mae: 0.0064\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2512e-05 - mae: 0.0061 - val_loss: 4.5183e-05 - val_mae: 0.0053\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.2069e-05 - mae: 0.0052 - val_loss: 2.1792e-05 - val_mae: 0.0038\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8600e-05 - mae: 0.0042 - val_loss: 1.2059e-05 - val_mae: 0.0029\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8402e-05 - mae: 0.0033 - val_loss: 6.5170e-06 - val_mae: 0.0023\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3696e-05 - mae: 0.0029 - val_loss: 4.1059e-06 - val_mae: 0.0018\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5572e-05 - mae: 0.0028 - val_loss: 4.5870e-06 - val_mae: 0.0016\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0111e-05 - mae: 0.0023 - val_loss: 3.8001e-06 - val_mae: 0.0017\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.6031e-06 - mae: 0.0021 - val_loss: 1.3180e-06 - val_mae: 8.5588e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.4703e-06 - mae: 0.0017 - val_loss: 1.3078e-06 - val_mae: 7.1885e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5069e-06 - mae: 0.0018 - val_loss: 1.0407e-06 - val_mae: 6.6555e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.0241e-06 - mae: 0.0015 - val_loss: 3.0259e-06 - val_mae: 0.0016\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9895e-06 - mae: 0.0016 - val_loss: 4.0566e-07 - val_mae: 5.9708e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5302e-06 - mae: 0.0012 - val_loss: 4.4663e-07 - val_mae: 6.3385e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5917e-06 - mae: 0.0012 - val_loss: 3.4200e-07 - val_mae: 5.5698e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8522e-06 - mae: 0.0010 - val_loss: 1.2573e-07 - val_mae: 2.8733e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5985e-06 - mae: 9.8850e-04 - val_loss: 1.0124e-07 - val_mae: 1.2482e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3824e-06 - mae: 9.3910e-04 - val_loss: 2.6804e-07 - val_mae: 4.4009e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1004e-06 - mae: 8.5294e-04 - val_loss: 5.5024e-07 - val_mae: 7.2146e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2205e-06 - mae: 8.3817e-04 - val_loss: 8.8023e-08 - val_mae: 2.7954e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.3573e-06 - mae: 0.0010 - val_loss: 1.3027e-07 - val_mae: 3.5386e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7719e-06 - mae: 8.7740e-04 - val_loss: 6.4253e-08 - val_mae: 2.4315e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9049e-06 - mae: 8.2929e-04 - val_loss: 2.8205e-08 - val_mae: 1.3271e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0882e-06 - mae: 8.0612e-04 - val_loss: 2.3765e-07 - val_mae: 4.6828e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0520e-06 - mae: 8.3899e-04 - val_loss: 1.7572e-07 - val_mae: 4.0331e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.7497e-06 - mae: 6.9119e-04 - val_loss: 1.2473e-06 - val_mae: 0.0011\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.7987e-06 - mae: 8.8121e-04 - val_loss: 1.9402e-07 - val_mae: 4.3282e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0564e-06 - mae: 7.8618e-04 - val_loss: 3.7905e-08 - val_mae: 1.8374e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5868e-06 - mae: 6.8204e-04 - val_loss: 4.2704e-07 - val_mae: 6.5079e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0115e-06 - mae: 7.4102e-04 - val_loss: 4.8168e-09 - val_mae: 4.4679e-05\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9911e-06 - mae: 7.7977e-04 - val_loss: 1.2352e-08 - val_mae: 1.0167e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4200e-06 - mae: 7.0910e-04 - val_loss: 6.5267e-08 - val_mae: 2.5234e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8100e-06 - mae: 8.3694e-04 - val_loss: 1.7335e-09 - val_mae: 2.8177e-05\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.4123e-06 - mae: 8.5583e-04 - val_loss: 2.0369e-07 - val_mae: 4.5021e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.9831e-06 - mae: 8.3304e-04 - val_loss: 4.0261e-08 - val_mae: 1.9981e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2655e-06 - mae: 6.9251e-04 - val_loss: 2.8227e-07 - val_mae: 5.3049e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2660e-06 - mae: 7.3055e-04 - val_loss: 9.8970e-10 - val_mae: 1.9790e-05\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.7103e-06 - mae: 6.2734e-04 - val_loss: 7.2342e-07 - val_mae: 8.5004e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0635e-06 - mae: 6.6735e-04 - val_loss: 2.0410e-07 - val_mae: 4.5082e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5497e-06 - mae: 7.4569e-04 - val_loss: 1.4524e-09 - val_mae: 3.1611e-05\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5868e-06 - mae: 6.6491e-04 - val_loss: 1.3342e-07 - val_mae: 3.6409e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8937e-06 - mae: 7.7653e-04 - val_loss: 4.9664e-07 - val_mae: 7.0412e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2478e-06 - mae: 7.6964e-04 - val_loss: 2.4297e-09 - val_mae: 3.9675e-05\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1297e-07 - mae: 4.3425e-04 - val_loss: 1.0032e-09 - val_mae: 1.2148e-05\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0011e-06 - mae: 5.5747e-04 - val_loss: 1.1531e-07 - val_mae: 3.3831e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.8685e-07 - mae: 5.4119e-04 - val_loss: 6.0352e-07 - val_mae: 7.7631e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1754e-06 - mae: 5.7280e-04 - val_loss: 2.0032e-07 - val_mae: 4.4661e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9853e-07 - mae: 4.4496e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: macuco, Test Loss: 2.0031515646223852e-07, Test MAE: 0.00044660887215286493\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 138ms/step\n",
      "Completed processing for city: macuco\n",
      "\n",
      "Processing city: magé\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 53ms/step - loss: 0.0010 - mae: 0.0249 - val_loss: 1.1609e-04 - val_mae: 0.0088\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7868e-04 - mae: 0.0128 - val_loss: 7.4697e-05 - val_mae: 0.0076\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3290e-04 - mae: 0.0088 - val_loss: 4.4010e-05 - val_mae: 0.0042\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1113e-05 - mae: 0.0068 - val_loss: 2.9894e-05 - val_mae: 0.0039\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3526e-05 - mae: 0.0054 - val_loss: 7.8249e-06 - val_mae: 0.0024\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.3257e-05 - mae: 0.0047 - val_loss: 6.0585e-06 - val_mae: 0.0022\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7152e-05 - mae: 0.0035 - val_loss: 5.8398e-06 - val_mae: 0.0021\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0787e-05 - mae: 0.0030 - val_loss: 1.2737e-05 - val_mae: 0.0032\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3265e-05 - mae: 0.0025 - val_loss: 8.5176e-06 - val_mae: 0.0026\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1275e-05 - mae: 0.0023 - val_loss: 5.3723e-06 - val_mae: 0.0021\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7318e-06 - mae: 0.0021 - val_loss: 3.7415e-06 - val_mae: 0.0017\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1373e-06 - mae: 0.0018 - val_loss: 3.1225e-06 - val_mae: 0.0016\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.8356e-06 - mae: 0.0015 - val_loss: 2.6529e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.5727e-06 - mae: 0.0016 - val_loss: 2.2615e-06 - val_mae: 0.0013\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.6329e-06 - mae: 0.0014 - val_loss: 2.5287e-06 - val_mae: 0.0014\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.8008e-06 - mae: 0.0013 - val_loss: 2.6356e-06 - val_mae: 0.0014\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.6805e-06 - mae: 0.0015 - val_loss: 1.7530e-06 - val_mae: 0.0012\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.1977e-06 - mae: 0.0013 - val_loss: 4.2990e-06 - val_mae: 0.0018\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.7696e-06 - mae: 0.0014 - val_loss: 1.9762e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.9706e-06 - mae: 0.0013 - val_loss: 1.4199e-06 - val_mae: 0.0010\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 5.1743e-06 - mae: 0.0012 - val_loss: 3.4810e-06 - val_mae: 0.0016\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.6782e-06 - mae: 0.0014 - val_loss: 9.6506e-07 - val_mae: 8.3474e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.7879e-06 - mae: 9.8330e-04 - val_loss: 1.8491e-06 - val_mae: 0.0011\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.5088e-06 - mae: 0.0012 - val_loss: 6.6587e-07 - val_mae: 6.9772e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7024e-06 - mae: 9.2867e-04 - val_loss: 7.3818e-07 - val_mae: 7.2349e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8525e-06 - mae: 0.0011 - val_loss: 5.5633e-07 - val_mae: 6.1923e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2727e-06 - mae: 0.0011 - val_loss: 9.6326e-07 - val_mae: 8.2213e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7308e-06 - mae: 8.6826e-04 - val_loss: 1.8206e-06 - val_mae: 0.0012\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0198e-06 - mae: 0.0011 - val_loss: 4.1704e-07 - val_mae: 5.2768e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.4498e-06 - mae: 9.1419e-04 - val_loss: 4.2996e-07 - val_mae: 5.4484e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.1478e-06 - mae: 0.0011 - val_loss: 5.5266e-07 - val_mae: 6.2459e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8407e-06 - mae: 9.2182e-04 - val_loss: 1.1738e-06 - val_mae: 9.4242e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.7688e-06 - mae: 0.0011 - val_loss: 9.3403e-07 - val_mae: 8.2890e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.8919e-06 - mae: 9.7901e-04 - val_loss: 5.9255e-06 - val_mae: 0.0024\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.1310e-06 - mae: 0.0012 - val_loss: 9.9446e-07 - val_mae: 8.7418e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3234e-06 - mae: 7.9782e-04 - val_loss: 1.0292e-06 - val_mae: 8.9651e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4733e-06 - mae: 0.0010 - val_loss: 7.9811e-07 - val_mae: 7.7432e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5078e-06 - mae: 9.0074e-04 - val_loss: 2.6706e-06 - val_mae: 0.0016\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5740e-06 - mae: 0.0012 - val_loss: 3.7534e-07 - val_mae: 4.8409e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 2.8386e-06 - mae: 9.5404e-04 - val_loss: 5.0269e-07 - val_mae: 6.0360e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1171e-06 - mae: 9.9565e-04 - val_loss: 2.0913e-07 - val_mae: 3.6654e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4288e-06 - mae: 9.1452e-04 - val_loss: 3.3223e-07 - val_mae: 4.5381e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6780e-06 - mae: 9.1194e-04 - val_loss: 1.3611e-06 - val_mae: 0.0011\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6301e-06 - mae: 9.3771e-04 - val_loss: 1.7969e-07 - val_mae: 3.4806e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1219e-06 - mae: 8.1108e-04 - val_loss: 1.7505e-07 - val_mae: 3.1331e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2629e-06 - mae: 8.8999e-04 - val_loss: 1.6926e-07 - val_mae: 3.1620e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3508e-06 - mae: 8.7079e-04 - val_loss: 3.1018e-07 - val_mae: 4.7527e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9398e-06 - mae: 9.8056e-04 - val_loss: 1.6212e-07 - val_mae: 3.1805e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.1383e-06 - mae: 9.6127e-04 - val_loss: 3.0831e-07 - val_mae: 4.6785e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 1.9088e-06 - mae: 7.6717e-04 - val_loss: 3.2657e-07 - val_mae: 4.6488e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 2.9255e-07 - mae: 4.4413e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: magé, Test Loss: 3.265740815550089e-07, Test MAE: 0.0004648776666726917\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 138ms/step\n",
      "Completed processing for city: magé\n",
      "\n",
      "Processing city: mangaratiba\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 60ms/step - loss: 0.0014 - mae: 0.0296 - val_loss: 3.3024e-04 - val_mae: 0.0156\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.1874e-04 - mae: 0.0178 - val_loss: 1.5186e-04 - val_mae: 0.0105\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7005e-04 - mae: 0.0130 - val_loss: 8.4357e-05 - val_mae: 0.0072\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0676e-04 - mae: 0.0112 - val_loss: 1.0433e-04 - val_mae: 0.0088\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4129e-04 - mae: 0.0094 - val_loss: 2.3988e-05 - val_mae: 0.0039\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0441e-04 - mae: 0.0083 - val_loss: 1.5282e-05 - val_mae: 0.0031\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.5847e-05 - mae: 0.0074 - val_loss: 2.5861e-05 - val_mae: 0.0045\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.4369e-05 - mae: 0.0073 - val_loss: 7.9050e-06 - val_mae: 0.0023\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.5044e-05 - mae: 0.0064 - val_loss: 6.8022e-06 - val_mae: 0.0021\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9914e-05 - mae: 0.0062 - val_loss: 5.2026e-06 - val_mae: 0.0019\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5787e-05 - mae: 0.0057 - val_loss: 4.3974e-06 - val_mae: 0.0016\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.8487e-05 - mae: 0.0051 - val_loss: 3.5757e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9397e-05 - mae: 0.0040 - val_loss: 1.3273e-06 - val_mae: 9.7698e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.9719e-05 - mae: 0.0032 - val_loss: 1.3042e-06 - val_mae: 8.2822e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3711e-05 - mae: 0.0032 - val_loss: 3.2115e-06 - val_mae: 0.0013\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1845e-05 - mae: 0.0022 - val_loss: 4.9462e-07 - val_mae: 5.5957e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2279e-05 - mae: 0.0022 - val_loss: 2.2204e-07 - val_mae: 3.7104e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.0789e-06 - mae: 0.0015 - val_loss: 3.3545e-06 - val_mae: 0.0018\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0549e-06 - mae: 0.0014 - val_loss: 1.6118e-06 - val_mae: 0.0013\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.2720e-06 - mae: 0.0012 - val_loss: 2.9856e-08 - val_mae: 1.0345e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3332e-06 - mae: 0.0012 - val_loss: 6.8204e-07 - val_mae: 8.2324e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.7208e-06 - mae: 0.0010 - val_loss: 6.6260e-08 - val_mae: 2.5082e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7680e-06 - mae: 8.9140e-04 - val_loss: 1.9103e-06 - val_mae: 0.0014\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7531e-06 - mae: 9.4801e-04 - val_loss: 1.7701e-07 - val_mae: 4.1556e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5164e-06 - mae: 7.0821e-04 - val_loss: 1.4261e-07 - val_mae: 3.7189e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7249e-06 - mae: 7.7116e-04 - val_loss: 1.5779e-06 - val_mae: 0.0013\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8667e-06 - mae: 8.7863e-04 - val_loss: 1.8516e-07 - val_mae: 4.2526e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3118e-06 - mae: 7.0777e-04 - val_loss: 3.9287e-08 - val_mae: 1.9142e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.9418e-07 - mae: 5.1419e-04 - val_loss: 7.5285e-08 - val_mae: 2.6763e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.9793e-06 - mae: 6.9833e-04 - val_loss: 1.6212e-07 - val_mae: 3.9725e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2233e-06 - mae: 6.5587e-04 - val_loss: 3.1213e-07 - val_mae: 5.5481e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6334e-06 - mae: 6.6130e-04 - val_loss: 6.3173e-08 - val_mae: 2.4261e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.0886e-06 - mae: 6.0314e-04 - val_loss: 2.6408e-07 - val_mae: 5.0967e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.3620e-06 - mae: 8.1436e-04 - val_loss: 3.0022e-07 - val_mae: 5.4397e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.4470e-07 - mae: 5.3575e-04 - val_loss: 3.8013e-07 - val_mae: 6.1304e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.6010e-07 - mae: 6.7806e-04 - val_loss: 6.5511e-07 - val_mae: 8.0672e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0675e-06 - mae: 6.1911e-04 - val_loss: 2.7304e-08 - val_mae: 1.5163e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.6580e-07 - mae: 5.8720e-04 - val_loss: 9.1596e-08 - val_mae: 2.9550e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2700e-07 - mae: 5.3175e-04 - val_loss: 7.9044e-07 - val_mae: 8.8664e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7046e-06 - mae: 7.7349e-04 - val_loss: 8.1897e-07 - val_mae: 9.0258e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1059e-06 - mae: 6.5659e-04 - val_loss: 1.6312e-07 - val_mae: 3.9851e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 8.9879e-07 - mae: 5.8798e-04 - val_loss: 1.7447e-07 - val_mae: 4.1250e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.7973e-07 - mae: 5.3834e-04 - val_loss: 5.9425e-07 - val_mae: 7.6808e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6010e-07 - mae: 6.5151e-04 - val_loss: 4.8304e-09 - val_mae: 4.6049e-05\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.9170e-07 - mae: 5.1564e-04 - val_loss: 2.4261e-07 - val_mae: 4.8816e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 9.7262e-07 - mae: 6.4766e-04 - val_loss: 1.7280e-07 - val_mae: 4.1047e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6144e-07 - mae: 5.5697e-04 - val_loss: 5.0750e-07 - val_mae: 7.0936e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5952e-07 - mae: 6.7047e-04 - val_loss: 1.1022e-06 - val_mae: 0.0010\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0194e-06 - mae: 7.4115e-04 - val_loss: 2.1173e-08 - val_mae: 1.2984e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7860e-07 - mae: 5.2517e-04 - val_loss: 1.8883e-07 - val_mae: 4.2956e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8302e-07 - mae: 4.2390e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: mangaratiba, Test Loss: 1.8883375219047593e-07, Test MAE: 0.0004295583057682961\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 129ms/step\n",
      "Completed processing for city: mangaratiba\n",
      "\n",
      "Processing city: maricá\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 48ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 1.2219e-04 - val_mae: 0.0078\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7807e-04 - mae: 0.0102 - val_loss: 5.3355e-05 - val_mae: 0.0049\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0605e-04 - mae: 0.0078 - val_loss: 1.7472e-05 - val_mae: 0.0030\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.4073e-05 - mae: 0.0055 - val_loss: 1.6495e-05 - val_mae: 0.0030\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3740e-05 - mae: 0.0048 - val_loss: 7.8078e-06 - val_mae: 0.0022\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3552e-05 - mae: 0.0036 - val_loss: 3.8038e-06 - val_mae: 0.0015\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.9807e-05 - mae: 0.0031 - val_loss: 2.8141e-06 - val_mae: 0.0013\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2753e-05 - mae: 0.0032 - val_loss: 5.0444e-06 - val_mae: 0.0021\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2286e-05 - mae: 0.0026 - val_loss: 8.8890e-07 - val_mae: 7.9920e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5969e-05 - mae: 0.0026 - val_loss: 5.8667e-06 - val_mae: 0.0023\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.0495e-06 - mae: 0.0020 - val_loss: 4.9821e-06 - val_mae: 0.0021\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.8316e-06 - mae: 0.0021 - val_loss: 4.6332e-07 - val_mae: 6.0630e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1369e-05 - mae: 0.0020 - val_loss: 3.2223e-06 - val_mae: 0.0017\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 6.9551e-06 - mae: 0.0018 - val_loss: 4.0339e-07 - val_mae: 5.7667e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4302e-06 - mae: 0.0018 - val_loss: 1.5569e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4951e-06 - mae: 0.0017 - val_loss: 4.6419e-07 - val_mae: 6.2343e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.2999e-06 - mae: 0.0016 - val_loss: 8.0025e-07 - val_mae: 8.2550e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4560e-06 - mae: 0.0016 - val_loss: 6.5657e-07 - val_mae: 7.4585e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.1386e-06 - mae: 0.0016 - val_loss: 3.3412e-06 - val_mae: 0.0018\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.3318e-06 - mae: 0.0017 - val_loss: 2.1131e-07 - val_mae: 4.2912e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6158e-06 - mae: 0.0016 - val_loss: 1.1095e-06 - val_mae: 0.0010\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.8765e-06 - mae: 0.0016 - val_loss: 3.5020e-06 - val_mae: 0.0019\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6227e-06 - mae: 0.0016 - val_loss: 6.7847e-07 - val_mae: 7.8172e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.3531e-06 - mae: 0.0015 - val_loss: 6.4443e-07 - val_mae: 7.6400e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3585e-06 - mae: 0.0014 - val_loss: 4.1212e-07 - val_mae: 6.0449e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5469e-06 - mae: 0.0016 - val_loss: 1.2131e-06 - val_mae: 0.0011\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.1747e-06 - mae: 0.0015 - val_loss: 1.7394e-06 - val_mae: 0.0013\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1189e-06 - mae: 0.0018 - val_loss: 1.0060e-07 - val_mae: 2.9417e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.3962e-06 - mae: 0.0014 - val_loss: 7.4888e-07 - val_mae: 8.4708e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.5179e-06 - mae: 0.0013 - val_loss: 2.3833e-07 - val_mae: 4.6463e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7524e-06 - mae: 0.0013 - val_loss: 4.0773e-07 - val_mae: 6.1843e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.9741e-06 - mae: 0.0015 - val_loss: 4.9484e-07 - val_mae: 6.8553e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.8100e-06 - mae: 0.0016 - val_loss: 3.1037e-07 - val_mae: 5.3670e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.6199e-06 - mae: 0.0016 - val_loss: 1.4294e-06 - val_mae: 0.0012\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.1744e-06 - mae: 0.0017 - val_loss: 1.6586e-06 - val_mae: 0.0013\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2566e-06 - mae: 0.0014 - val_loss: 1.6139e-07 - val_mae: 3.8356e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.7780e-06 - mae: 0.0015 - val_loss: 6.4587e-07 - val_mae: 7.9292e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5431e-06 - mae: 0.0015 - val_loss: 4.0873e-07 - val_mae: 6.2608e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.6366e-06 - mae: 0.0014 - val_loss: 7.6059e-08 - val_mae: 2.4449e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7219e-06 - mae: 0.0014 - val_loss: 1.7262e-08 - val_mae: 8.9291e-05\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2385e-06 - mae: 0.0014 - val_loss: 1.0325e-06 - val_mae: 0.0010\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.4296e-06 - mae: 0.0017 - val_loss: 7.9923e-07 - val_mae: 8.8592e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9358e-06 - mae: 0.0014 - val_loss: 3.9456e-06 - val_mae: 0.0020\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7895e-06 - mae: 0.0015 - val_loss: 1.7307e-06 - val_mae: 0.0013\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8839e-06 - mae: 0.0013 - val_loss: 5.1675e-07 - val_mae: 7.1045e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3794e-06 - mae: 0.0012 - val_loss: 2.4635e-06 - val_mae: 0.0016\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3134e-06 - mae: 0.0012 - val_loss: 8.0559e-07 - val_mae: 8.9138e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8355e-06 - mae: 0.0013 - val_loss: 6.9097e-07 - val_mae: 8.2549e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.0959e-06 - mae: 0.0015 - val_loss: 2.2459e-06 - val_mae: 0.0015\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9148e-06 - mae: 0.0014 - val_loss: 8.0137e-08 - val_mae: 2.7058e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.9282e-08 - mae: 2.6755e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: maricá, Test Loss: 8.013710584009459e-08, Test MAE: 0.00027057569241151214\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 159ms/step\n",
      "Completed processing for city: maricá\n",
      "\n",
      "Processing city: mendes\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 47ms/step - loss: 9.1618e-04 - mae: 0.0234 - val_loss: 2.0496e-04 - val_mae: 0.0118\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0696e-04 - mae: 0.0140 - val_loss: 7.8614e-05 - val_mae: 0.0075\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7695e-04 - mae: 0.0106 - val_loss: 1.6201e-04 - val_mae: 0.0112\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5478e-04 - mae: 0.0093 - val_loss: 2.8036e-05 - val_mae: 0.0045\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2425e-04 - mae: 0.0084 - val_loss: 2.4519e-05 - val_mae: 0.0038\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2364e-05 - mae: 0.0059 - val_loss: 2.7065e-05 - val_mae: 0.0040\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5954e-05 - mae: 0.0054 - val_loss: 3.0097e-05 - val_mae: 0.0041\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2688e-05 - mae: 0.0041 - val_loss: 2.2224e-05 - val_mae: 0.0038\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4699e-05 - mae: 0.0035 - val_loss: 9.5289e-06 - val_mae: 0.0021\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8674e-05 - mae: 0.0028 - val_loss: 1.1879e-05 - val_mae: 0.0029\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6107e-05 - mae: 0.0027 - val_loss: 3.0781e-06 - val_mae: 0.0012\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5949e-06 - mae: 0.0015 - val_loss: 3.4896e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5320e-06 - mae: 0.0017 - val_loss: 1.3396e-06 - val_mae: 0.0011\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.4409e-06 - mae: 0.0016 - val_loss: 9.1068e-07 - val_mae: 7.5788e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.8253e-06 - mae: 0.0013 - val_loss: 8.7769e-07 - val_mae: 5.9257e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.2245e-06 - mae: 0.0012 - val_loss: 4.8229e-07 - val_mae: 6.0422e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.4982e-06 - mae: 0.0010 - val_loss: 6.2463e-07 - val_mae: 4.7894e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4765e-06 - mae: 0.0010 - val_loss: 1.0290e-06 - val_mae: 8.5870e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.4685e-06 - mae: 0.0010 - val_loss: 2.5425e-07 - val_mae: 4.3624e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5552e-06 - mae: 0.0010 - val_loss: 7.6973e-07 - val_mae: 7.4746e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3722e-06 - mae: 0.0011 - val_loss: 6.6780e-07 - val_mae: 7.1116e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0001e-06 - mae: 9.9722e-04 - val_loss: 2.3594e-06 - val_mae: 0.0015\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9010e-06 - mae: 0.0011 - val_loss: 1.2906e-07 - val_mae: 3.3484e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9510e-06 - mae: 9.9415e-04 - val_loss: 5.6186e-07 - val_mae: 6.8957e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0974e-06 - mae: 8.1709e-04 - val_loss: 7.6346e-07 - val_mae: 8.2203e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6957e-06 - mae: 9.2390e-04 - val_loss: 5.2431e-07 - val_mae: 6.7136e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.6584e-06 - mae: 0.0010 - val_loss: 7.5191e-08 - val_mae: 2.5434e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4435e-06 - mae: 8.8115e-04 - val_loss: 1.7746e-07 - val_mae: 3.4167e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8596e-06 - mae: 7.0869e-04 - val_loss: 4.6574e-07 - val_mae: 6.3930e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0944e-06 - mae: 9.8357e-04 - val_loss: 8.0262e-08 - val_mae: 1.7051e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0859e-06 - mae: 8.2774e-04 - val_loss: 1.3669e-07 - val_mae: 3.5233e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.1216e-06 - mae: 8.6792e-04 - val_loss: 1.2804e-07 - val_mae: 3.4121e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8524e-06 - mae: 7.4918e-04 - val_loss: 1.2521e-07 - val_mae: 3.3795e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5298e-06 - mae: 6.9339e-04 - val_loss: 3.5938e-07 - val_mae: 5.6981e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4417e-06 - mae: 7.4756e-04 - val_loss: 3.8767e-08 - val_mae: 1.0591e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.2150e-06 - mae: 6.9719e-04 - val_loss: 9.5105e-07 - val_mae: 9.5799e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.9214e-06 - mae: 9.4532e-04 - val_loss: 7.5871e-07 - val_mae: 8.5210e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.7251e-06 - mae: 7.8662e-04 - val_loss: 4.5378e-07 - val_mae: 6.4972e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2046e-06 - mae: 6.8614e-04 - val_loss: 2.9293e-07 - val_mae: 5.1272e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2952e-06 - mae: 8.0918e-04 - val_loss: 2.4359e-07 - val_mae: 4.6308e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1269e-06 - mae: 8.1306e-04 - val_loss: 1.4647e-06 - val_mae: 0.0012\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3742e-06 - mae: 9.4312e-04 - val_loss: 5.3483e-07 - val_mae: 7.1251e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7237e-06 - mae: 6.7698e-04 - val_loss: 2.4719e-08 - val_mae: 9.7207e-05\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6526e-06 - mae: 6.8440e-04 - val_loss: 1.0602e-06 - val_mae: 0.0010\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 2.1389e-06 - mae: 8.7830e-04 - val_loss: 3.6558e-08 - val_mae: 1.8240e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8536e-06 - mae: 7.2132e-04 - val_loss: 8.9104e-08 - val_mae: 2.8527e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0410e-06 - mae: 7.0456e-04 - val_loss: 2.4654e-08 - val_mae: 1.3590e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0836e-06 - mae: 6.9519e-04 - val_loss: 2.1626e-08 - val_mae: 1.1535e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5940e-06 - mae: 6.5576e-04 - val_loss: 1.4718e-07 - val_mae: 3.6574e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6055e-06 - mae: 7.1008e-04 - val_loss: 5.9165e-08 - val_mae: 1.9473e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 6.6634e-08 - mae: 2.0731e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: mendes, Test Loss: 5.916535528172062e-08, Test MAE: 0.00019473205611575395\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 135ms/step\n",
      "Completed processing for city: mendes\n",
      "\n",
      "Processing city: miguel pereira\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 48ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 8.5982e-05 - val_mae: 0.0070\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3835e-04 - mae: 0.0114 - val_loss: 7.3915e-05 - val_mae: 0.0067\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0776e-04 - mae: 0.0077 - val_loss: 2.5322e-05 - val_mae: 0.0040\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6096e-05 - mae: 0.0057 - val_loss: 1.4215e-05 - val_mae: 0.0030\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4703e-05 - mae: 0.0049 - val_loss: 1.1153e-05 - val_mae: 0.0030\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7623e-05 - mae: 0.0040 - val_loss: 7.0411e-06 - val_mae: 0.0025\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8139e-05 - mae: 0.0031 - val_loss: 5.7662e-06 - val_mae: 0.0022\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0643e-05 - mae: 0.0024 - val_loss: 3.0650e-06 - val_mae: 0.0016\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0288e-05 - mae: 0.0020 - val_loss: 3.0562e-06 - val_mae: 0.0011\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.7672e-06 - mae: 0.0018 - val_loss: 1.4921e-06 - val_mae: 9.6556e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.3187e-06 - mae: 0.0017 - val_loss: 1.4563e-06 - val_mae: 0.0011\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0253e-06 - mae: 0.0014 - val_loss: 2.2063e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.8977e-06 - mae: 0.0014 - val_loss: 1.6759e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0081e-06 - mae: 0.0014 - val_loss: 2.1372e-07 - val_mae: 3.6239e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9979e-06 - mae: 0.0010 - val_loss: 1.8615e-07 - val_mae: 3.2087e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8381e-06 - mae: 0.0010 - val_loss: 8.3254e-07 - val_mae: 8.5733e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.9000e-06 - mae: 9.8765e-04 - val_loss: 3.5025e-07 - val_mae: 5.4049e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4851e-06 - mae: 9.6141e-04 - val_loss: 1.1072e-06 - val_mae: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6898e-06 - mae: 8.6115e-04 - val_loss: 1.3028e-06 - val_mae: 0.0011\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2043e-06 - mae: 9.2319e-04 - val_loss: 4.6807e-08 - val_mae: 1.7754e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6517e-06 - mae: 8.9922e-04 - val_loss: 4.8483e-08 - val_mae: 1.7850e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8036e-06 - mae: 7.4361e-04 - val_loss: 1.2258e-07 - val_mae: 3.1625e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3984e-06 - mae: 6.6472e-04 - val_loss: 9.5590e-08 - val_mae: 2.7766e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2566e-06 - mae: 6.1644e-04 - val_loss: 5.8520e-08 - val_mae: 1.9582e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7988e-06 - mae: 7.6651e-04 - val_loss: 1.3788e-07 - val_mae: 3.4379e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8528e-07 - mae: 5.4055e-04 - val_loss: 4.2528e-07 - val_mae: 6.3680e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5223e-06 - mae: 7.9858e-04 - val_loss: 5.8826e-07 - val_mae: 7.5567e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.8272e-07 - mae: 6.7606e-04 - val_loss: 1.3346e-07 - val_mae: 3.4573e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5722e-06 - mae: 8.1421e-04 - val_loss: 1.8190e-08 - val_mae: 1.0937e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.6386e-06 - mae: 6.8663e-04 - val_loss: 9.4276e-09 - val_mae: 7.2412e-05\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.0419e-06 - mae: 5.3969e-04 - val_loss: 5.5785e-08 - val_mae: 2.1775e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 5.9104e-07 - mae: 4.6941e-04 - val_loss: 1.8300e-07 - val_mae: 4.1857e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4109e-06 - mae: 6.6586e-04 - val_loss: 4.6160e-07 - val_mae: 6.7260e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.5086e-07 - mae: 6.8293e-04 - val_loss: 1.9179e-07 - val_mae: 4.2956e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 7.3813e-07 - mae: 5.1779e-04 - val_loss: 3.8473e-06 - val_mae: 0.0020\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4131e-06 - mae: 8.0568e-04 - val_loss: 2.4125e-07 - val_mae: 4.8570e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.2444e-07 - mae: 4.9943e-04 - val_loss: 1.1405e-06 - val_mae: 0.0011\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.2096e-07 - mae: 6.6861e-04 - val_loss: 4.0756e-07 - val_mae: 6.3423e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4843e-06 - mae: 6.2252e-04 - val_loss: 7.6694e-08 - val_mae: 2.7199e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4.9944e-07 - mae: 4.0531e-04 - val_loss: 6.3844e-08 - val_mae: 2.4758e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.1508e-06 - mae: 6.3446e-04 - val_loss: 1.9554e-07 - val_mae: 4.3752e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 5.7661e-07 - mae: 5.5220e-04 - val_loss: 4.9009e-07 - val_mae: 6.9696e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 3.9066e-07 - mae: 4.6692e-04 - val_loss: 6.9278e-07 - val_mae: 8.2973e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2254e-07 - mae: 5.7250e-04 - val_loss: 1.0733e-06 - val_mae: 0.0010\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.4679e-07 - mae: 6.4044e-04 - val_loss: 1.5856e-08 - val_mae: 1.0565e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 6.1027e-07 - mae: 4.8863e-04 - val_loss: 6.6057e-07 - val_mae: 8.0977e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.0356e-07 - mae: 6.3710e-04 - val_loss: 3.3673e-08 - val_mae: 1.7126e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9712e-07 - mae: 5.1663e-04 - val_loss: 5.7367e-07 - val_mae: 7.5448e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.5391e-07 - mae: 6.1068e-04 - val_loss: 3.9983e-07 - val_mae: 6.2925e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.1514e-07 - mae: 5.6703e-04 - val_loss: 5.1003e-07 - val_mae: 7.1139e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.1572e-07 - mae: 7.1625e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: miguel pereira, Test Loss: 5.10027120981249e-07, Test MAE: 0.0007113936590030789\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 142ms/step\n",
      "Completed processing for city: miguel pereira\n",
      "\n",
      "Processing city: miracema\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 54ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 1.4726e-04 - val_mae: 0.0107\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9185e-04 - mae: 0.0128 - val_loss: 8.1621e-05 - val_mae: 0.0070\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5407e-04 - mae: 0.0093 - val_loss: 5.1081e-05 - val_mae: 0.0062\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.3720e-05 - mae: 0.0071 - val_loss: 3.7467e-05 - val_mae: 0.0057\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5374e-05 - mae: 0.0064 - val_loss: 2.4215e-05 - val_mae: 0.0048\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3318e-05 - mae: 0.0050 - val_loss: 1.0102e-05 - val_mae: 0.0030\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7421e-05 - mae: 0.0041 - val_loss: 5.0008e-06 - val_mae: 0.0020\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8224e-05 - mae: 0.0033 - val_loss: 5.4180e-06 - val_mae: 0.0020\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5283e-05 - mae: 0.0029 - val_loss: 1.0348e-05 - val_mae: 0.0030\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0221e-05 - mae: 0.0025 - val_loss: 3.3980e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.7818e-06 - mae: 0.0018 - val_loss: 2.3616e-06 - val_mae: 0.0013\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5731e-06 - mae: 0.0018 - val_loss: 3.4572e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.4636e-06 - mae: 0.0016 - val_loss: 2.6917e-06 - val_mae: 0.0011\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.3650e-06 - mae: 0.0016 - val_loss: 2.6230e-06 - val_mae: 0.0012\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.1496e-06 - mae: 0.0015 - val_loss: 1.6358e-06 - val_mae: 0.0012\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3954e-06 - mae: 0.0014 - val_loss: 4.7536e-06 - val_mae: 0.0019\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9559e-06 - mae: 0.0015 - val_loss: 8.7857e-07 - val_mae: 8.3407e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.4735e-06 - mae: 0.0014 - val_loss: 1.7032e-06 - val_mae: 9.7848e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3958e-06 - mae: 0.0012 - val_loss: 1.0772e-06 - val_mae: 7.2558e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.9269e-06 - mae: 0.0012 - val_loss: 6.5101e-07 - val_mae: 6.0593e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0048e-06 - mae: 0.0012 - val_loss: 5.7424e-07 - val_mae: 6.9411e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1133e-06 - mae: 0.0013 - val_loss: 4.0305e-07 - val_mae: 5.5864e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9388e-06 - mae: 9.1216e-04 - val_loss: 1.3495e-06 - val_mae: 9.9231e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3612e-06 - mae: 0.0012 - val_loss: 6.4363e-07 - val_mae: 5.8036e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2963e-06 - mae: 0.0011 - val_loss: 5.2544e-07 - val_mae: 6.3885e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5881e-06 - mae: 9.8348e-04 - val_loss: 1.6372e-06 - val_mae: 0.0012\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.8513e-06 - mae: 0.0010 - val_loss: 3.8778e-06 - val_mae: 0.0019\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4137e-06 - mae: 0.0012 - val_loss: 1.6807e-06 - val_mae: 0.0012\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7218e-06 - mae: 0.0011 - val_loss: 5.7830e-07 - val_mae: 6.5667e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0155e-06 - mae: 8.5997e-04 - val_loss: 8.2375e-07 - val_mae: 7.9735e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8767e-06 - mae: 0.0010 - val_loss: 1.9888e-07 - val_mae: 4.1432e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5054e-06 - mae: 8.9244e-04 - val_loss: 9.4048e-07 - val_mae: 8.9115e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6664e-06 - mae: 0.0011 - val_loss: 8.6562e-07 - val_mae: 8.5392e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.8726e-06 - mae: 0.0010 - val_loss: 2.6702e-07 - val_mae: 4.4691e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4721e-06 - mae: 9.0578e-04 - val_loss: 2.4051e-07 - val_mae: 3.6680e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9331e-06 - mae: 7.8957e-04 - val_loss: 4.6797e-07 - val_mae: 6.0261e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0720e-06 - mae: 9.3363e-04 - val_loss: 4.1055e-07 - val_mae: 5.6213e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6172e-06 - mae: 9.4075e-04 - val_loss: 5.8281e-07 - val_mae: 7.0567e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1202e-06 - mae: 8.1382e-04 - val_loss: 3.0426e-07 - val_mae: 4.7901e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0202e-06 - mae: 8.1320e-04 - val_loss: 1.3183e-07 - val_mae: 2.7091e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4841e-06 - mae: 9.3147e-04 - val_loss: 6.3176e-08 - val_mae: 2.2293e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3584e-06 - mae: 7.6979e-04 - val_loss: 9.8552e-07 - val_mae: 9.6329e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3530e-06 - mae: 9.9333e-04 - val_loss: 7.0115e-08 - val_mae: 2.3794e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6573e-06 - mae: 7.1843e-04 - val_loss: 7.4065e-07 - val_mae: 8.2892e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0355e-06 - mae: 8.5171e-04 - val_loss: 3.0009e-07 - val_mae: 5.0158e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0063e-06 - mae: 8.7893e-04 - val_loss: 1.1659e-06 - val_mae: 0.0011\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3015e-06 - mae: 9.1924e-04 - val_loss: 3.6653e-07 - val_mae: 5.6140e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0817e-06 - mae: 9.2636e-04 - val_loss: 3.0092e-07 - val_mae: 5.0386e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4570e-06 - mae: 9.0183e-04 - val_loss: 2.9048e-07 - val_mae: 4.9748e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.7813e-06 - mae: 7.0874e-04 - val_loss: 5.8362e-07 - val_mae: 7.3370e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.5531e-07 - mae: 7.1959e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: miracema, Test Loss: 5.836225227540126e-07, Test MAE: 0.0007337036076933146\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 132ms/step\n",
      "Completed processing for city: miracema\n",
      "\n",
      "Processing city: natividade\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - loss: 6.1244e-04 - mae: 0.0187 - val_loss: 6.3838e-05 - val_mae: 0.0074\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6817e-04 - mae: 0.0099 - val_loss: 3.3561e-05 - val_mae: 0.0043\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.4594e-05 - mae: 0.0075 - val_loss: 2.1590e-05 - val_mae: 0.0034\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.1506e-05 - mae: 0.0053 - val_loss: 6.6694e-06 - val_mae: 0.0020\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5303e-05 - mae: 0.0044 - val_loss: 5.1970e-06 - val_mae: 0.0018\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.6357e-05 - mae: 0.0038 - val_loss: 5.3121e-06 - val_mae: 0.0017\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5406e-05 - mae: 0.0037 - val_loss: 6.4723e-06 - val_mae: 0.0020\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5383e-05 - mae: 0.0036 - val_loss: 4.3238e-06 - val_mae: 0.0015\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.7720e-05 - mae: 0.0030 - val_loss: 5.1131e-06 - val_mae: 0.0017\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6436e-05 - mae: 0.0030 - val_loss: 6.3816e-06 - val_mae: 0.0021\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7662e-05 - mae: 0.0031 - val_loss: 2.9494e-06 - val_mae: 0.0014\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0150e-05 - mae: 0.0024 - val_loss: 2.8200e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.7681e-06 - mae: 0.0023 - val_loss: 2.3123e-06 - val_mae: 0.0012\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.5089e-06 - mae: 0.0021 - val_loss: 2.1188e-06 - val_mae: 0.0012\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.3175e-06 - mae: 0.0020 - val_loss: 2.7344e-06 - val_mae: 0.0014\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0243e-05 - mae: 0.0021 - val_loss: 3.3942e-06 - val_mae: 0.0015\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 6.6087e-06 - mae: 0.0019 - val_loss: 2.1924e-06 - val_mae: 0.0013\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.3478e-06 - mae: 0.0020 - val_loss: 2.2573e-06 - val_mae: 0.0013\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 5.0392e-06 - mae: 0.0017 - val_loss: 1.5559e-06 - val_mae: 0.0010\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 6.9418e-06 - mae: 0.0019 - val_loss: 3.2238e-06 - val_mae: 0.0016\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.3722e-06 - mae: 0.0018 - val_loss: 1.7536e-06 - val_mae: 0.0012\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1465e-06 - mae: 0.0015 - val_loss: 1.8351e-06 - val_mae: 0.0012\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8173e-06 - mae: 0.0016 - val_loss: 1.7817e-06 - val_mae: 0.0012\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2409e-06 - mae: 0.0017 - val_loss: 1.8595e-06 - val_mae: 0.0012\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.7602e-06 - mae: 0.0015 - val_loss: 1.0992e-06 - val_mae: 9.4368e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9638e-06 - mae: 0.0017 - val_loss: 6.6032e-07 - val_mae: 6.4755e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4699e-06 - mae: 0.0014 - val_loss: 6.2523e-07 - val_mae: 6.7374e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.3413e-06 - mae: 0.0015 - val_loss: 4.9742e-07 - val_mae: 5.7646e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4.5312e-06 - mae: 0.0014 - val_loss: 4.1914e-07 - val_mae: 5.3366e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.0425e-06 - mae: 0.0013 - val_loss: 5.1873e-07 - val_mae: 6.4014e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.9212e-06 - mae: 0.0011 - val_loss: 8.7356e-07 - val_mae: 8.4795e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.5731e-06 - mae: 0.0012 - val_loss: 2.5468e-07 - val_mae: 3.6788e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.3040e-06 - mae: 0.0013 - val_loss: 2.3030e-06 - val_mae: 0.0015\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.0725e-06 - mae: 0.0013 - val_loss: 1.6460e-07 - val_mae: 3.4998e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8946e-06 - mae: 0.0012 - val_loss: 3.6784e-07 - val_mae: 5.5315e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.0379e-06 - mae: 0.0011 - val_loss: 9.9446e-07 - val_mae: 9.5992e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.9053e-06 - mae: 0.0012 - val_loss: 1.7278e-07 - val_mae: 3.7086e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.4181e-06 - mae: 0.0011 - val_loss: 4.9807e-08 - val_mae: 2.0213e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.2871e-06 - mae: 0.0010 - val_loss: 2.4379e-07 - val_mae: 4.6492e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0206e-06 - mae: 0.0012 - val_loss: 4.5088e-07 - val_mae: 6.5564e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 3.8892e-06 - mae: 0.0012 - val_loss: 2.1722e-08 - val_mae: 1.3844e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.4242e-06 - mae: 0.0011 - val_loss: 1.7466e-06 - val_mae: 0.0013\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.4041e-06 - mae: 0.0011 - val_loss: 1.7035e-06 - val_mae: 0.0013\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.5239e-06 - mae: 0.0012 - val_loss: 1.1618e-07 - val_mae: 3.2575e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8786e-06 - mae: 9.9951e-04 - val_loss: 2.5804e-07 - val_mae: 4.9883e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1693e-06 - mae: 0.0011 - val_loss: 3.0095e-06 - val_mae: 0.0017\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1199e-06 - mae: 0.0011 - val_loss: 9.6982e-08 - val_mae: 3.0152e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7002e-06 - mae: 0.0011 - val_loss: 7.6387e-09 - val_mae: 8.1968e-05\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8217e-06 - mae: 7.9149e-04 - val_loss: 4.0482e-07 - val_mae: 6.3268e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0287e-06 - mae: 7.9898e-04 - val_loss: 1.6979e-07 - val_mae: 4.0703e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7397e-07 - mae: 4.1139e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: natividade, Test Loss: 1.6979356587398797e-07, Test MAE: 0.00040702507249079645\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 133ms/step\n",
      "Completed processing for city: natividade\n",
      "\n",
      "Processing city: nilópolis\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 54ms/step - loss: 5.7730e-04 - mae: 0.0186 - val_loss: 2.9188e-05 - val_mae: 0.0044\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4386e-04 - mae: 0.0093 - val_loss: 1.8794e-05 - val_mae: 0.0037\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 8.5860e-05 - mae: 0.0074 - val_loss: 1.9091e-05 - val_mae: 0.0039\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4899e-05 - mae: 0.0065 - val_loss: 2.2973e-05 - val_mae: 0.0045\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2989e-05 - mae: 0.0043 - val_loss: 3.0587e-06 - val_mae: 0.0015\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0230e-05 - mae: 0.0033 - val_loss: 1.7624e-06 - val_mae: 0.0011\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5648e-05 - mae: 0.0027 - val_loss: 1.7462e-06 - val_mae: 0.0011\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1055e-05 - mae: 0.0021 - val_loss: 6.7371e-07 - val_mae: 6.8318e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.7776e-06 - mae: 0.0019 - val_loss: 2.0296e-07 - val_mae: 3.8861e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.2129e-06 - mae: 0.0014 - val_loss: 1.6052e-07 - val_mae: 2.8523e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7805e-06 - mae: 0.0014 - val_loss: 4.4989e-07 - val_mae: 5.9040e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3805e-06 - mae: 0.0012 - val_loss: 1.5691e-07 - val_mae: 3.7231e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5852e-06 - mae: 0.0013 - val_loss: 4.9202e-07 - val_mae: 6.0324e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0915e-06 - mae: 0.0013 - val_loss: 1.2409e-07 - val_mae: 3.0972e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.9540e-06 - mae: 0.0012 - val_loss: 1.2035e-07 - val_mae: 2.8049e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1854e-06 - mae: 0.0011 - val_loss: 2.0219e-07 - val_mae: 3.0686e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0256e-06 - mae: 0.0010 - val_loss: 6.6805e-07 - val_mae: 7.4777e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8518e-06 - mae: 9.5734e-04 - val_loss: 1.1999e-07 - val_mae: 2.5832e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8630e-06 - mae: 8.3548e-04 - val_loss: 5.5966e-07 - val_mae: 6.7757e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4427e-06 - mae: 8.9123e-04 - val_loss: 6.6242e-07 - val_mae: 7.4907e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1455e-06 - mae: 7.8223e-04 - val_loss: 5.8354e-07 - val_mae: 6.9905e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2826e-06 - mae: 9.1279e-04 - val_loss: 9.5126e-07 - val_mae: 9.2579e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1732e-06 - mae: 9.2601e-04 - val_loss: 1.0361e-07 - val_mae: 3.0082e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6865e-06 - mae: 6.9506e-04 - val_loss: 3.7731e-07 - val_mae: 5.4890e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3881e-06 - mae: 8.5017e-04 - val_loss: 9.6576e-08 - val_mae: 2.9066e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4977e-06 - mae: 7.1561e-04 - val_loss: 1.0726e-07 - val_mae: 3.0825e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.6081e-06 - mae: 6.5084e-04 - val_loss: 3.1346e-07 - val_mae: 4.9913e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4502e-06 - mae: 8.6680e-04 - val_loss: 7.8907e-08 - val_mae: 2.5003e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8861e-06 - mae: 8.1376e-04 - val_loss: 2.2820e-07 - val_mae: 3.8988e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1799e-06 - mae: 6.1354e-04 - val_loss: 1.7718e-06 - val_mae: 0.0013\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7071e-06 - mae: 8.9596e-04 - val_loss: 3.0210e-06 - val_mae: 0.0017\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5232e-06 - mae: 0.0010 - val_loss: 4.1968e-07 - val_mae: 5.9390e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.2354e-06 - mae: 8.6017e-04 - val_loss: 7.4725e-08 - val_mae: 2.5519e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1624e-06 - mae: 5.6309e-04 - val_loss: 9.2723e-08 - val_mae: 1.8306e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5362e-06 - mae: 6.1201e-04 - val_loss: 1.4336e-07 - val_mae: 2.8607e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2142e-06 - mae: 6.4073e-04 - val_loss: 1.0449e-07 - val_mae: 2.1723e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0807e-06 - mae: 8.0308e-04 - val_loss: 6.1978e-08 - val_mae: 2.2236e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.3380e-06 - mae: 7.5388e-04 - val_loss: 1.4708e-07 - val_mae: 2.9146e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.2285e-06 - mae: 6.5968e-04 - val_loss: 1.0584e-07 - val_mae: 2.1787e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1471e-06 - mae: 5.8736e-04 - val_loss: 3.3578e-07 - val_mae: 5.2808e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5493e-06 - mae: 7.0201e-04 - val_loss: 1.5230e-06 - val_mae: 0.0012\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7678e-06 - mae: 8.0340e-04 - val_loss: 7.1489e-07 - val_mae: 8.0835e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2589e-06 - mae: 6.4482e-04 - val_loss: 5.3343e-07 - val_mae: 6.8728e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6829e-06 - mae: 7.6483e-04 - val_loss: 4.7534e-07 - val_mae: 6.4337e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6755e-06 - mae: 7.2002e-04 - val_loss: 1.3040e-07 - val_mae: 3.3069e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5761e-06 - mae: 7.3001e-04 - val_loss: 1.5265e-06 - val_mae: 0.0012\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0867e-06 - mae: 9.5212e-04 - val_loss: 7.7983e-08 - val_mae: 2.6335e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4024e-06 - mae: 6.3035e-04 - val_loss: 8.7095e-07 - val_mae: 9.0087e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.5210e-06 - mae: 6.8889e-04 - val_loss: 4.7786e-07 - val_mae: 6.4725e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2079e-06 - mae: 6.9969e-04 - val_loss: 4.1639e-07 - val_mae: 5.9576e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.2588e-07 - mae: 6.0261e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: nilópolis, Test Loss: 4.163879339103005e-07, Test MAE: 0.0005957615212537348\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 150ms/step\n",
      "Completed processing for city: nilópolis\n",
      "\n",
      "Processing city: niterói\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 54ms/step - loss: 7.9097e-04 - mae: 0.0213 - val_loss: 7.2127e-05 - val_mae: 0.0065\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4137e-04 - mae: 0.0111 - val_loss: 4.0969e-05 - val_mae: 0.0058\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2536e-04 - mae: 0.0094 - val_loss: 1.4380e-05 - val_mae: 0.0033\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9414e-04 - mae: 0.0078 - val_loss: 7.1102e-06 - val_mae: 0.0020\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4170e-04 - mae: 0.0068 - val_loss: 7.5516e-06 - val_mae: 0.0020\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3263e-04 - mae: 0.0067 - val_loss: 5.5831e-05 - val_mae: 0.0056\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1586e-04 - mae: 0.0061 - val_loss: 1.9732e-05 - val_mae: 0.0027\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.3074e-04 - mae: 0.0056 - val_loss: 6.0090e-06 - val_mae: 0.0017\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1643e-04 - mae: 0.0056 - val_loss: 5.1507e-06 - val_mae: 0.0017\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0449e-04 - mae: 0.0052 - val_loss: 1.1142e-05 - val_mae: 0.0017\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2300e-04 - mae: 0.0053 - val_loss: 3.1082e-05 - val_mae: 0.0036\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9305e-04 - mae: 0.0065 - val_loss: 1.1315e-05 - val_mae: 0.0022\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.3318e-05 - mae: 0.0048 - val_loss: 1.3731e-05 - val_mae: 0.0021\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1860e-04 - mae: 0.0049 - val_loss: 1.8913e-05 - val_mae: 0.0025\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1494e-04 - mae: 0.0048 - val_loss: 6.6073e-05 - val_mae: 0.0052\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.9500e-05 - mae: 0.0047 - val_loss: 6.7353e-05 - val_mae: 0.0054\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0332e-04 - mae: 0.0054 - val_loss: 1.4695e-05 - val_mae: 0.0023\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1333e-04 - mae: 0.0049 - val_loss: 5.4008e-06 - val_mae: 0.0012\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.6536e-05 - mae: 0.0044 - val_loss: 1.5789e-05 - val_mae: 0.0018\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.1883e-04 - mae: 0.0048 - val_loss: 4.8469e-05 - val_mae: 0.0043\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1808e-04 - mae: 0.0051 - val_loss: 7.2847e-05 - val_mae: 0.0063\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2763e-04 - mae: 0.0058 - val_loss: 6.0221e-06 - val_mae: 0.0015\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 8.6296e-05 - mae: 0.0044 - val_loss: 4.5743e-05 - val_mae: 0.0046\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.5584e-05 - mae: 0.0050 - val_loss: 2.8877e-05 - val_mae: 0.0026\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.6786e-05 - mae: 0.0042 - val_loss: 1.0630e-04 - val_mae: 0.0076\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.5091e-05 - mae: 0.0048 - val_loss: 2.1602e-05 - val_mae: 0.0028\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.2181e-05 - mae: 0.0045 - val_loss: 4.4557e-05 - val_mae: 0.0033\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2308e-04 - mae: 0.0049 - val_loss: 3.9026e-05 - val_mae: 0.0035\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1601e-04 - mae: 0.0047 - val_loss: 3.3585e-05 - val_mae: 0.0035\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.9368e-05 - mae: 0.0040 - val_loss: 4.5294e-05 - val_mae: 0.0045\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5225e-05 - mae: 0.0040 - val_loss: 6.0580e-05 - val_mae: 0.0045\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.0630e-04 - mae: 0.0046 - val_loss: 1.7896e-05 - val_mae: 0.0021\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 8.2772e-05 - mae: 0.0043 - val_loss: 5.6889e-05 - val_mae: 0.0049\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.1968e-04 - mae: 0.0048 - val_loss: 6.7792e-05 - val_mae: 0.0053\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1788e-04 - mae: 0.0051 - val_loss: 3.5667e-05 - val_mae: 0.0031\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.8792e-05 - mae: 0.0041 - val_loss: 3.3457e-05 - val_mae: 0.0027\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.8591e-05 - mae: 0.0040 - val_loss: 3.8172e-05 - val_mae: 0.0037\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0342e-04 - mae: 0.0050 - val_loss: 4.6045e-05 - val_mae: 0.0036\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.1718e-05 - mae: 0.0041 - val_loss: 6.7159e-05 - val_mae: 0.0050\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.1029e-05 - mae: 0.0044 - val_loss: 5.0039e-05 - val_mae: 0.0044\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0630e-04 - mae: 0.0048 - val_loss: 1.0032e-05 - val_mae: 0.0013\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.7546e-05 - mae: 0.0043 - val_loss: 3.9356e-05 - val_mae: 0.0036\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0236e-04 - mae: 0.0047 - val_loss: 5.4931e-05 - val_mae: 0.0050\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.0989e-05 - mae: 0.0048 - val_loss: 4.5338e-05 - val_mae: 0.0033\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0404e-04 - mae: 0.0047 - val_loss: 2.5195e-05 - val_mae: 0.0020\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.3656e-05 - mae: 0.0036 - val_loss: 8.0132e-05 - val_mae: 0.0049\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.2906e-05 - mae: 0.0045 - val_loss: 6.9012e-05 - val_mae: 0.0040\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.0415e-05 - mae: 0.0039 - val_loss: 1.4220e-04 - val_mae: 0.0080\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0412e-04 - mae: 0.0051 - val_loss: 5.7303e-05 - val_mae: 0.0037\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.1066e-05 - mae: 0.0042 - val_loss: 5.0431e-05 - val_mae: 0.0033\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9545e-05 - mae: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: niterói, Test Loss: 5.0430873670848086e-05, Test MAE: 0.0033326195552945137\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 125ms/step\n",
      "Completed processing for city: niterói\n",
      "\n",
      "Processing city: nova friburgo\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 53ms/step - loss: 8.8653e-04 - mae: 0.0232 - val_loss: 1.3535e-04 - val_mae: 0.0096\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.6853e-04 - mae: 0.0151 - val_loss: 4.1445e-05 - val_mae: 0.0054\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.2070e-04 - mae: 0.0111 - val_loss: 2.4391e-05 - val_mae: 0.0041\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3419e-04 - mae: 0.0088 - val_loss: 7.4448e-06 - val_mae: 0.0023\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1890e-04 - mae: 0.0078 - val_loss: 4.9713e-06 - val_mae: 0.0019\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.3404e-05 - mae: 0.0066 - val_loss: 8.6671e-06 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.6981e-05 - mae: 0.0050 - val_loss: 1.3852e-05 - val_mae: 0.0036\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.3963e-05 - mae: 0.0056 - val_loss: 3.2091e-06 - val_mae: 0.0017\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3699e-05 - mae: 0.0040 - val_loss: 1.5905e-06 - val_mae: 0.0012\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.0218e-05 - mae: 0.0036 - val_loss: 3.9930e-06 - val_mae: 0.0019\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5217e-05 - mae: 0.0041 - val_loss: 8.9663e-07 - val_mae: 8.9149e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.0765e-05 - mae: 0.0032 - val_loss: 4.8426e-07 - val_mae: 5.7660e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.8398e-05 - mae: 0.0040 - val_loss: 6.1238e-07 - val_mae: 7.0299e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.3042e-05 - mae: 0.0032 - val_loss: 3.1700e-06 - val_mae: 0.0017\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3707e-05 - mae: 0.0031 - val_loss: 1.3461e-05 - val_mae: 0.0036\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.2599e-05 - mae: 0.0038 - val_loss: 1.5519e-06 - val_mae: 0.0012\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.4560e-05 - mae: 0.0034 - val_loss: 1.1600e-05 - val_mae: 0.0033\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9704e-05 - mae: 0.0037 - val_loss: 1.9847e-06 - val_mae: 0.0014\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.4258e-05 - mae: 0.0039 - val_loss: 1.9844e-06 - val_mae: 0.0014\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.6571e-05 - mae: 0.0028 - val_loss: 1.1605e-05 - val_mae: 0.0033\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.6003e-05 - mae: 0.0038 - val_loss: 4.3685e-06 - val_mae: 0.0020\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.4438e-05 - mae: 0.0035 - val_loss: 4.0567e-07 - val_mae: 4.1871e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.6832e-05 - mae: 0.0033 - val_loss: 2.3266e-06 - val_mae: 0.0015\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.3611e-05 - mae: 0.0037 - val_loss: 9.3098e-07 - val_mae: 9.1077e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1077e-05 - mae: 0.0029 - val_loss: 6.2611e-06 - val_mae: 0.0024\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0409e-05 - mae: 0.0035 - val_loss: 6.6766e-06 - val_mae: 0.0025\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.7039e-05 - mae: 0.0037 - val_loss: 1.2945e-06 - val_mae: 0.0011\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.1233e-05 - mae: 0.0035 - val_loss: 1.9556e-06 - val_mae: 0.0013\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.8696e-05 - mae: 0.0034 - val_loss: 8.5329e-07 - val_mae: 8.6671e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3173e-05 - mae: 0.0027 - val_loss: 4.0584e-07 - val_mae: 4.2095e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.0502e-05 - mae: 0.0030 - val_loss: 5.2773e-07 - val_mae: 6.2474e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1011e-05 - mae: 0.0031 - val_loss: 1.3694e-06 - val_mae: 0.0011\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.7960e-05 - mae: 0.0036 - val_loss: 4.3768e-07 - val_mae: 5.0857e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4894e-05 - mae: 0.0031 - val_loss: 6.6879e-07 - val_mae: 7.4728e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.3564e-05 - mae: 0.0031 - val_loss: 4.0784e-07 - val_mae: 4.3462e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.8923e-05 - mae: 0.0034 - val_loss: 6.8696e-07 - val_mae: 7.6051e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6133e-05 - mae: 0.0029 - val_loss: 8.8475e-06 - val_mae: 0.0029\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.8140e-05 - mae: 0.0036 - val_loss: 4.9597e-07 - val_mae: 5.9056e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.6531e-05 - mae: 0.0026 - val_loss: 1.5413e-06 - val_mae: 0.0012\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.7094e-05 - mae: 0.0033 - val_loss: 4.0940e-07 - val_mae: 3.8883e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.5132e-05 - mae: 0.0031 - val_loss: 7.2989e-06 - val_mae: 0.0026\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.2831e-05 - mae: 0.0036 - val_loss: 4.5464e-06 - val_mae: 0.0021\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3827e-05 - mae: 0.0028 - val_loss: 7.0291e-06 - val_mae: 0.0026\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5503e-05 - mae: 0.0034 - val_loss: 1.1040e-06 - val_mae: 9.9948e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.6096e-05 - mae: 0.0030 - val_loss: 1.5925e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8574e-05 - mae: 0.0028 - val_loss: 1.1593e-06 - val_mae: 0.0010\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5955e-05 - mae: 0.0029 - val_loss: 7.5690e-07 - val_mae: 8.0783e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 5.8327e-05 - mae: 0.0039 - val_loss: 6.5368e-07 - val_mae: 7.3593e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.5359e-05 - mae: 0.0027 - val_loss: 6.2847e-06 - val_mae: 0.0024\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.2283e-05 - mae: 0.0033 - val_loss: 4.1914e-07 - val_mae: 4.7005e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3.3892e-07 - mae: 4.6196e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: nova friburgo, Test Loss: 4.191441291823139e-07, Test MAE: 0.00047005165833979845\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 166ms/step\n",
      "Completed processing for city: nova friburgo\n",
      "\n",
      "Processing city: nova iguaçu\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 52ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 9.0645e-05 - val_mae: 0.0083\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.4947e-04 - mae: 0.0095 - val_loss: 5.5951e-05 - val_mae: 0.0064\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.2562e-05 - mae: 0.0074 - val_loss: 4.4106e-05 - val_mae: 0.0056\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.5854e-05 - mae: 0.0066 - val_loss: 2.4475e-05 - val_mae: 0.0042\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.2469e-05 - mae: 0.0056 - val_loss: 8.9633e-06 - val_mae: 0.0026\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7893e-05 - mae: 0.0046 - val_loss: 3.3085e-06 - val_mae: 0.0016\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.4200e-05 - mae: 0.0041 - val_loss: 2.9063e-06 - val_mae: 0.0014\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3149e-05 - mae: 0.0034 - val_loss: 1.0171e-05 - val_mae: 0.0030\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3297e-05 - mae: 0.0036 - val_loss: 4.2753e-06 - val_mae: 0.0019\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0907e-05 - mae: 0.0032 - val_loss: 2.8685e-06 - val_mae: 0.0015\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8005e-05 - mae: 0.0028 - val_loss: 7.9326e-07 - val_mae: 7.8372e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.8243e-05 - mae: 0.0030 - val_loss: 5.7884e-06 - val_mae: 0.0023\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8871e-05 - mae: 0.0030 - val_loss: 1.1508e-06 - val_mae: 9.3986e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4322e-05 - mae: 0.0024 - val_loss: 1.0535e-05 - val_mae: 0.0032\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.8321e-05 - mae: 0.0029 - val_loss: 3.6226e-06 - val_mae: 0.0018\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3877e-05 - mae: 0.0025 - val_loss: 4.3888e-06 - val_mae: 0.0020\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3230e-05 - mae: 0.0024 - val_loss: 3.4938e-07 - val_mae: 5.2341e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5239e-05 - mae: 0.0025 - val_loss: 6.1536e-07 - val_mae: 7.1408e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.7441e-05 - mae: 0.0027 - val_loss: 2.1802e-06 - val_mae: 0.0014\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5845e-05 - mae: 0.0026 - val_loss: 1.5064e-06 - val_mae: 0.0011\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6141e-05 - mae: 0.0027 - val_loss: 6.2867e-06 - val_mae: 0.0025\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8196e-05 - mae: 0.0028 - val_loss: 1.5671e-06 - val_mae: 0.0012\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4985e-05 - mae: 0.0024 - val_loss: 2.8579e-06 - val_mae: 0.0016\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3256e-05 - mae: 0.0023 - val_loss: 8.2731e-07 - val_mae: 8.2690e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3039e-05 - mae: 0.0024 - val_loss: 1.0644e-05 - val_mae: 0.0032\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4636e-05 - mae: 0.0027 - val_loss: 3.8761e-06 - val_mae: 0.0019\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3814e-05 - mae: 0.0025 - val_loss: 7.5665e-06 - val_mae: 0.0027\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4447e-05 - mae: 0.0026 - val_loss: 2.6300e-06 - val_mae: 0.0016\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.3952e-05 - mae: 0.0025 - val_loss: 4.2838e-06 - val_mae: 0.0020\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2493e-05 - mae: 0.0023 - val_loss: 6.0916e-06 - val_mae: 0.0024\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3279e-05 - mae: 0.0025 - val_loss: 1.5108e-06 - val_mae: 0.0011\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2303e-05 - mae: 0.0023 - val_loss: 7.0115e-07 - val_mae: 7.4691e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2109e-05 - mae: 0.0022 - val_loss: 1.6934e-06 - val_mae: 0.0012\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2478e-05 - mae: 0.0023 - val_loss: 1.9723e-06 - val_mae: 0.0013\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6227e-05 - mae: 0.0025 - val_loss: 6.6527e-06 - val_mae: 0.0025\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4894e-05 - mae: 0.0025 - val_loss: 4.1291e-06 - val_mae: 0.0020\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1815e-05 - mae: 0.0023 - val_loss: 9.6475e-06 - val_mae: 0.0031\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2063e-05 - mae: 0.0024 - val_loss: 9.7857e-06 - val_mae: 0.0031\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7909e-05 - mae: 0.0029 - val_loss: 3.3859e-06 - val_mae: 0.0018\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1535e-05 - mae: 0.0022 - val_loss: 2.4681e-06 - val_mae: 0.0015\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3766e-05 - mae: 0.0025 - val_loss: 3.7659e-06 - val_mae: 0.0019\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4277e-05 - mae: 0.0025 - val_loss: 2.5850e-07 - val_mae: 4.0238e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2193e-05 - mae: 0.0022 - val_loss: 2.5267e-06 - val_mae: 0.0015\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3134e-05 - mae: 0.0025 - val_loss: 3.3035e-06 - val_mae: 0.0017\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4982e-05 - mae: 0.0026 - val_loss: 1.5030e-06 - val_mae: 0.0011\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4165e-05 - mae: 0.0025 - val_loss: 1.7067e-06 - val_mae: 0.0012\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3751e-05 - mae: 0.0024 - val_loss: 8.4109e-07 - val_mae: 7.9588e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3072e-05 - mae: 0.0023 - val_loss: 1.7319e-06 - val_mae: 0.0012\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0886e-05 - mae: 0.0021 - val_loss: 2.4390e-06 - val_mae: 0.0015\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3710e-05 - mae: 0.0024 - val_loss: 7.5741e-06 - val_mae: 0.0027\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.5403e-06 - mae: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: nova iguaçu, Test Loss: 7.574142273369944e-06, Test MAE: 0.002701281337067485\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 151ms/step\n",
      "Completed processing for city: nova iguaçu\n",
      "\n",
      "Processing city: paracambi\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 66ms/step - loss: 0.0021 - mae: 0.0308 - val_loss: 1.0350e-04 - val_mae: 0.0079\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3256e-04 - mae: 0.0116 - val_loss: 1.7668e-05 - val_mae: 0.0034\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.0443e-04 - mae: 0.0076 - val_loss: 1.0238e-05 - val_mae: 0.0028\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.1132e-05 - mae: 0.0058 - val_loss: 2.2345e-05 - val_mae: 0.0040\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.4273e-05 - mae: 0.0044 - val_loss: 8.3950e-06 - val_mae: 0.0026\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7518e-05 - mae: 0.0032 - val_loss: 9.3969e-06 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8689e-05 - mae: 0.0033 - val_loss: 9.5560e-06 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5360e-05 - mae: 0.0030 - val_loss: 7.4389e-06 - val_mae: 0.0023\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0710e-05 - mae: 0.0025 - val_loss: 6.5616e-06 - val_mae: 0.0021\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1094e-05 - mae: 0.0025 - val_loss: 6.5593e-06 - val_mae: 0.0022\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0564e-05 - mae: 0.0023 - val_loss: 3.6918e-06 - val_mae: 0.0016\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.6801e-06 - mae: 0.0021 - val_loss: 3.0166e-06 - val_mae: 0.0015\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.4814e-06 - mae: 0.0019 - val_loss: 3.4011e-06 - val_mae: 0.0016\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9452e-06 - mae: 0.0018 - val_loss: 1.8886e-06 - val_mae: 0.0012\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9190e-06 - mae: 0.0016 - val_loss: 1.6760e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3434e-06 - mae: 0.0016 - val_loss: 1.2466e-06 - val_mae: 9.4633e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9089e-06 - mae: 0.0014 - val_loss: 1.3029e-06 - val_mae: 0.0010\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9558e-06 - mae: 0.0012 - val_loss: 8.6457e-07 - val_mae: 7.5358e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.7919e-06 - mae: 0.0014 - val_loss: 2.7589e-06 - val_mae: 0.0015\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4.5424e-06 - mae: 0.0014 - val_loss: 1.6046e-06 - val_mae: 0.0011\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2043e-06 - mae: 0.0012 - val_loss: 5.6760e-07 - val_mae: 6.8697e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 4.0475e-06 - mae: 0.0012 - val_loss: 9.1622e-07 - val_mae: 8.6222e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.1021e-06 - mae: 0.0012 - val_loss: 3.5899e-07 - val_mae: 5.0259e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7984e-06 - mae: 0.0010 - val_loss: 9.6160e-07 - val_mae: 8.6729e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7041e-06 - mae: 9.9800e-04 - val_loss: 1.1386e-06 - val_mae: 9.5237e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1408e-06 - mae: 9.5046e-04 - val_loss: 2.5720e-07 - val_mae: 4.7433e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0493e-06 - mae: 8.6495e-04 - val_loss: 8.8479e-07 - val_mae: 8.3795e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8682e-06 - mae: 8.8140e-04 - val_loss: 5.7142e-07 - val_mae: 6.6298e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4337e-06 - mae: 7.4308e-04 - val_loss: 1.5104e-07 - val_mae: 3.4778e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9606e-06 - mae: 8.2067e-04 - val_loss: 4.1219e-07 - val_mae: 5.2253e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3514e-06 - mae: 7.6360e-04 - val_loss: 3.4537e-07 - val_mae: 5.0437e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8265e-06 - mae: 7.7361e-04 - val_loss: 2.4350e-06 - val_mae: 0.0015\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1184e-06 - mae: 9.6669e-04 - val_loss: 1.2462e-06 - val_mae: 0.0011\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7452e-06 - mae: 8.2217e-04 - val_loss: 8.0195e-07 - val_mae: 8.3401e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8301e-06 - mae: 8.3454e-04 - val_loss: 1.6917e-07 - val_mae: 3.4022e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3944e-06 - mae: 7.3792e-04 - val_loss: 1.0671e-06 - val_mae: 9.8792e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0152e-06 - mae: 9.2711e-04 - val_loss: 1.1682e-07 - val_mae: 2.7343e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.4890e-06 - mae: 6.1521e-04 - val_loss: 1.1743e-06 - val_mae: 0.0010\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3398e-06 - mae: 7.9585e-04 - val_loss: 9.5507e-08 - val_mae: 2.5101e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5005e-06 - mae: 7.4022e-04 - val_loss: 5.5142e-07 - val_mae: 6.7447e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5164e-06 - mae: 7.5403e-04 - val_loss: 3.9983e-07 - val_mae: 5.5553e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4457e-06 - mae: 7.2931e-04 - val_loss: 8.3339e-07 - val_mae: 8.6519e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6466e-06 - mae: 8.0756e-04 - val_loss: 3.2738e-07 - val_mae: 4.9030e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6294e-06 - mae: 7.7042e-04 - val_loss: 8.6417e-08 - val_mae: 2.4857e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7423e-06 - mae: 9.2888e-04 - val_loss: 1.4556e-07 - val_mae: 3.3681e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0412e-06 - mae: 7.5746e-04 - val_loss: 8.3055e-07 - val_mae: 8.6690e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2441e-06 - mae: 7.1144e-04 - val_loss: 1.7005e-07 - val_mae: 3.0488e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6925e-06 - mae: 7.5467e-04 - val_loss: 4.6008e-07 - val_mae: 6.1638e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3063e-06 - mae: 6.4468e-04 - val_loss: 7.5426e-07 - val_mae: 8.1998e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0185e-06 - mae: 8.4041e-04 - val_loss: 3.5703e-07 - val_mae: 5.1745e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.9785e-07 - mae: 5.4931e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: paracambi, Test Loss: 3.570250441953249e-07, Test MAE: 0.0005174477118998766\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 152ms/step\n",
      "Completed processing for city: paracambi\n",
      "\n",
      "Processing city: paraty\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 52ms/step - loss: 0.0018 - mae: 0.0311 - val_loss: 8.4140e-05 - val_mae: 0.0079\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7132e-04 - mae: 0.0129 - val_loss: 3.3148e-05 - val_mae: 0.0043\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7829e-04 - mae: 0.0102 - val_loss: 5.3081e-05 - val_mae: 0.0065\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3292e-04 - mae: 0.0089 - val_loss: 2.0932e-05 - val_mae: 0.0037\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.1759e-05 - mae: 0.0070 - val_loss: 1.6187e-05 - val_mae: 0.0035\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9161e-05 - mae: 0.0058 - val_loss: 1.0352e-05 - val_mae: 0.0027\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1376e-05 - mae: 0.0048 - val_loss: 1.7557e-05 - val_mae: 0.0033\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0860e-05 - mae: 0.0047 - val_loss: 2.2741e-05 - val_mae: 0.0038\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.2141e-05 - mae: 0.0036 - val_loss: 3.7211e-05 - val_mae: 0.0051\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9734e-05 - mae: 0.0033 - val_loss: 1.6714e-05 - val_mae: 0.0028\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4896e-05 - mae: 0.0027 - val_loss: 1.6134e-05 - val_mae: 0.0029\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.3182e-05 - mae: 0.0023 - val_loss: 4.8011e-06 - val_mae: 0.0014\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.9725e-06 - mae: 0.0020 - val_loss: 1.0842e-05 - val_mae: 0.0027\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.2916e-06 - mae: 0.0019 - val_loss: 6.2334e-06 - val_mae: 0.0016\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 5.5893e-06 - mae: 0.0016 - val_loss: 3.3298e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.3691e-06 - mae: 0.0014 - val_loss: 2.5371e-06 - val_mae: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.6700e-06 - mae: 0.0013 - val_loss: 1.2638e-06 - val_mae: 7.2344e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.7414e-06 - mae: 0.0014 - val_loss: 1.0621e-06 - val_mae: 6.7062e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6467e-06 - mae: 0.0012 - val_loss: 1.3410e-06 - val_mae: 7.2694e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.2563e-06 - mae: 0.0011 - val_loss: 1.3919e-06 - val_mae: 7.3661e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6849e-06 - mae: 0.0011 - val_loss: 9.2180e-07 - val_mae: 7.9869e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6264e-06 - mae: 0.0011 - val_loss: 8.1777e-07 - val_mae: 6.0227e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9777e-06 - mae: 0.0011 - val_loss: 1.0763e-06 - val_mae: 9.3236e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9168e-06 - mae: 0.0011 - val_loss: 1.2207e-06 - val_mae: 0.0010\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1367e-06 - mae: 0.0011 - val_loss: 7.9491e-07 - val_mae: 6.7097e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.2875e-06 - mae: 0.0011 - val_loss: 8.2260e-07 - val_mae: 7.2059e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3234e-06 - mae: 9.6459e-04 - val_loss: 8.3531e-07 - val_mae: 4.8783e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2932e-06 - mae: 9.0257e-04 - val_loss: 7.7707e-07 - val_mae: 6.6689e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5974e-06 - mae: 7.4552e-04 - val_loss: 3.0551e-06 - val_mae: 0.0015\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.6424e-06 - mae: 0.0011 - val_loss: 7.5512e-07 - val_mae: 6.3540e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4527e-06 - mae: 7.7181e-04 - val_loss: 1.6187e-06 - val_mae: 9.3716e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7324e-06 - mae: 7.7608e-04 - val_loss: 1.0523e-06 - val_mae: 5.7383e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.6169e-06 - mae: 9.5412e-04 - val_loss: 7.5741e-07 - val_mae: 6.5619e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.5045e-06 - mae: 9.3930e-04 - val_loss: 7.5729e-07 - val_mae: 6.5752e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0230e-06 - mae: 8.3259e-04 - val_loss: 8.1212e-07 - val_mae: 4.6051e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9250e-06 - mae: 8.9731e-04 - val_loss: 7.4305e-07 - val_mae: 5.1102e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4497e-06 - mae: 7.1348e-04 - val_loss: 8.1745e-07 - val_mae: 7.5237e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9332e-06 - mae: 8.4453e-04 - val_loss: 1.6837e-06 - val_mae: 9.8048e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5596e-06 - mae: 9.7352e-04 - val_loss: 1.1253e-06 - val_mae: 9.9198e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7804e-06 - mae: 7.8210e-04 - val_loss: 8.0578e-07 - val_mae: 7.4432e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2747e-06 - mae: 0.0010 - val_loss: 1.6261e-06 - val_mae: 9.5304e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1722e-06 - mae: 9.1582e-04 - val_loss: 1.5771e-06 - val_mae: 9.2757e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5223e-06 - mae: 7.7276e-04 - val_loss: 9.5262e-07 - val_mae: 4.8990e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4514e-06 - mae: 7.1532e-04 - val_loss: 9.6506e-07 - val_mae: 8.8497e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2404e-06 - mae: 8.0146e-04 - val_loss: 7.5698e-07 - val_mae: 4.6895e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 2.1100e-06 - mae: 9.2192e-04 - val_loss: 7.7679e-07 - val_mae: 4.5281e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8216e-06 - mae: 8.0792e-04 - val_loss: 1.1873e-06 - val_mae: 6.8765e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4603e-06 - mae: 7.7467e-04 - val_loss: 1.0795e-06 - val_mae: 6.0447e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9976e-06 - mae: 7.5989e-04 - val_loss: 1.0595e-06 - val_mae: 5.8752e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6755e-06 - mae: 7.6408e-04 - val_loss: 7.1369e-07 - val_mae: 5.5412e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.2091e-07 - mae: 4.9335e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: paraty, Test Loss: 7.136914632610569e-07, Test MAE: 0.0005541177233681083\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 193ms/step\n",
      "Completed processing for city: paraty\n",
      "\n",
      "Processing city: paraíba do sul\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 54ms/step - loss: 0.0019 - mae: 0.0319 - val_loss: 1.4307e-04 - val_mae: 0.0097\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5243e-04 - mae: 0.0127 - val_loss: 7.3755e-05 - val_mae: 0.0077\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7735e-04 - mae: 0.0101 - val_loss: 3.6772e-05 - val_mae: 0.0050\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0030e-04 - mae: 0.0077 - val_loss: 3.9550e-05 - val_mae: 0.0057\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.2646e-05 - mae: 0.0071 - val_loss: 1.9359e-05 - val_mae: 0.0040\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7677e-05 - mae: 0.0054 - val_loss: 6.5857e-06 - val_mae: 0.0022\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9348e-05 - mae: 0.0041 - val_loss: 4.9355e-06 - val_mae: 0.0019\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2707e-05 - mae: 0.0035 - val_loss: 4.1457e-06 - val_mae: 0.0018\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4368e-05 - mae: 0.0029 - val_loss: 2.4384e-06 - val_mae: 0.0013\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2636e-05 - mae: 0.0027 - val_loss: 2.2716e-06 - val_mae: 0.0012\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0263e-05 - mae: 0.0023 - val_loss: 1.8838e-06 - val_mae: 0.0011\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.8749e-06 - mae: 0.0020 - val_loss: 1.9826e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.8791e-06 - mae: 0.0018 - val_loss: 2.2301e-06 - val_mae: 0.0014\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5121e-06 - mae: 0.0016 - val_loss: 1.6040e-06 - val_mae: 9.1121e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7082e-06 - mae: 0.0015 - val_loss: 1.1881e-06 - val_mae: 8.6847e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.9644e-06 - mae: 0.0015 - val_loss: 2.7260e-06 - val_mae: 0.0015\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.3264e-06 - mae: 0.0016 - val_loss: 9.4118e-07 - val_mae: 7.5712e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1214e-06 - mae: 0.0012 - val_loss: 7.6765e-07 - val_mae: 6.6070e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4886e-06 - mae: 0.0012 - val_loss: 1.1844e-06 - val_mae: 8.1353e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6983e-06 - mae: 0.0012 - val_loss: 1.1467e-06 - val_mae: 9.6065e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7528e-06 - mae: 9.7260e-04 - val_loss: 6.7897e-07 - val_mae: 5.9407e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3713e-06 - mae: 9.3399e-04 - val_loss: 3.7223e-07 - val_mae: 4.6381e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6280e-06 - mae: 0.0011 - val_loss: 7.2335e-07 - val_mae: 6.6664e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4918e-06 - mae: 9.0581e-04 - val_loss: 2.6571e-07 - val_mae: 3.9217e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.9407e-06 - mae: 9.4496e-04 - val_loss: 1.5600e-06 - val_mae: 0.0012\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6834e-06 - mae: 0.0010 - val_loss: 7.3793e-07 - val_mae: 7.7351e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2226e-06 - mae: 8.9403e-04 - val_loss: 1.5867e-06 - val_mae: 0.0012\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2318e-06 - mae: 8.6062e-04 - val_loss: 1.6809e-06 - val_mae: 0.0013\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7479e-06 - mae: 0.0010 - val_loss: 3.3489e-06 - val_mae: 0.0018\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6616e-06 - mae: 0.0011 - val_loss: 9.8051e-07 - val_mae: 9.5883e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 2.3247e-06 - mae: 9.0785e-04 - val_loss: 5.4628e-08 - val_mae: 1.8740e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.9750e-06 - mae: 8.7258e-04 - val_loss: 2.6165e-07 - val_mae: 4.7892e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2346e-06 - mae: 8.8920e-04 - val_loss: 5.9829e-08 - val_mae: 1.9958e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0117e-06 - mae: 7.3884e-04 - val_loss: 1.2979e-07 - val_mae: 3.3223e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0574e-06 - mae: 8.1141e-04 - val_loss: 7.5048e-07 - val_mae: 8.5985e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7021e-06 - mae: 9.5833e-04 - val_loss: 6.6530e-08 - val_mae: 2.3512e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5999e-06 - mae: 9.5051e-04 - val_loss: 1.7756e-07 - val_mae: 4.0492e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3548e-06 - mae: 6.7715e-04 - val_loss: 4.9881e-08 - val_mae: 1.9768e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2948e-06 - mae: 5.8541e-04 - val_loss: 2.7612e-06 - val_mae: 0.0017\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7280e-06 - mae: 7.8594e-04 - val_loss: 9.6759e-07 - val_mae: 9.8071e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2743e-06 - mae: 6.4211e-04 - val_loss: 1.2511e-07 - val_mae: 3.4397e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.1108e-06 - mae: 7.3010e-04 - val_loss: 3.2442e-08 - val_mae: 1.6055e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.4540e-06 - mae: 7.7828e-04 - val_loss: 1.8411e-07 - val_mae: 4.2294e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4602e-06 - mae: 6.1245e-04 - val_loss: 3.8463e-07 - val_mae: 6.1429e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.2059e-06 - mae: 6.2748e-04 - val_loss: 5.6154e-09 - val_mae: 5.9003e-05\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5505e-06 - mae: 6.9348e-04 - val_loss: 6.8436e-07 - val_mae: 8.2460e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6565e-06 - mae: 7.1661e-04 - val_loss: 8.3477e-07 - val_mae: 9.1179e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4198e-06 - mae: 6.4688e-04 - val_loss: 7.6048e-09 - val_mae: 7.5372e-05\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2824e-06 - mae: 5.9145e-04 - val_loss: 1.6895e-08 - val_mae: 1.1587e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2881e-06 - mae: 5.6365e-04 - val_loss: 6.0835e-08 - val_mae: 2.3531e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.6204e-08 - mae: 2.4595e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: paraíba do sul, Test Loss: 6.08345374075725e-08, Test MAE: 0.00023531122133135796\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 189ms/step\n",
      "Completed processing for city: paraíba do sul\n",
      "\n",
      "Processing city: paty do alferes\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 52ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 1.1853e-04 - val_mae: 0.0090\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0750e-04 - mae: 0.0130 - val_loss: 3.3984e-05 - val_mae: 0.0046\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.8234e-04 - mae: 0.0105 - val_loss: 2.1143e-05 - val_mae: 0.0033\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.8393e-05 - mae: 0.0069 - val_loss: 2.8301e-06 - val_mae: 0.0014\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9600e-05 - mae: 0.0048 - val_loss: 2.0200e-06 - val_mae: 0.0011\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4853e-05 - mae: 0.0040 - val_loss: 2.1438e-06 - val_mae: 0.0012\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5733e-05 - mae: 0.0035 - val_loss: 6.9319e-07 - val_mae: 5.7767e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3201e-05 - mae: 0.0029 - val_loss: 1.1345e-06 - val_mae: 9.3618e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 9.7925e-06 - mae: 0.0021 - val_loss: 2.0627e-06 - val_mae: 0.0014\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.3851e-06 - mae: 0.0018 - val_loss: 6.9327e-07 - val_mae: 8.0777e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4017e-06 - mae: 0.0014 - val_loss: 1.1386e-07 - val_mae: 3.0122e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9748e-06 - mae: 0.0012 - val_loss: 1.5233e-08 - val_mae: 9.6117e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.8202e-06 - mae: 0.0011 - val_loss: 9.8194e-08 - val_mae: 2.9532e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6691e-06 - mae: 0.0010 - val_loss: 1.0920e-08 - val_mae: 7.5633e-05\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7581e-06 - mae: 7.8764e-04 - val_loss: 8.3941e-07 - val_mae: 9.1135e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8778e-06 - mae: 9.2145e-04 - val_loss: 3.7834e-07 - val_mae: 6.0800e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4638e-06 - mae: 8.2291e-04 - val_loss: 6.2246e-08 - val_mae: 2.3367e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5395e-06 - mae: 6.5739e-04 - val_loss: 8.8329e-08 - val_mae: 2.8475e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4978e-06 - mae: 6.7836e-04 - val_loss: 3.6305e-08 - val_mae: 1.7462e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6232e-06 - mae: 7.7960e-04 - val_loss: 9.1604e-08 - val_mae: 2.9273e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.8004e-06 - mae: 6.8738e-04 - val_loss: 1.9251e-07 - val_mae: 4.3233e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2126e-06 - mae: 7.2570e-04 - val_loss: 2.9975e-08 - val_mae: 1.5768e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3539e-06 - mae: 7.8412e-04 - val_loss: 2.7893e-07 - val_mae: 5.2355e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4210e-06 - mae: 7.1322e-04 - val_loss: 7.5794e-07 - val_mae: 8.6804e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7627e-06 - mae: 7.6980e-04 - val_loss: 6.7145e-08 - val_mae: 2.5110e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.4909e-06 - mae: 7.6535e-04 - val_loss: 1.8541e-06 - val_mae: 0.0014\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 8.7619e-07 - mae: 6.2858e-04 - val_loss: 3.1883e-08 - val_mae: 1.6820e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6848e-07 - mae: 5.1586e-04 - val_loss: 4.3186e-08 - val_mae: 1.9954e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6492e-07 - mae: 4.3311e-04 - val_loss: 1.8500e-07 - val_mae: 4.2636e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2062e-06 - mae: 5.9811e-04 - val_loss: 7.8890e-09 - val_mae: 8.0577e-05\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.6572e-07 - mae: 4.4222e-04 - val_loss: 3.0204e-07 - val_mae: 5.4708e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0391e-06 - mae: 7.4125e-04 - val_loss: 2.0245e-07 - val_mae: 4.4704e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.4579e-07 - mae: 5.1925e-04 - val_loss: 1.3995e-07 - val_mae: 3.7069e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.9320e-07 - mae: 5.1854e-04 - val_loss: 3.2613e-07 - val_mae: 5.6903e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.6387e-07 - mae: 4.5452e-04 - val_loss: 5.0397e-07 - val_mae: 7.0836e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7017e-06 - mae: 7.8512e-04 - val_loss: 4.5971e-07 - val_mae: 6.7649e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2307e-06 - mae: 7.4446e-04 - val_loss: 1.1181e-06 - val_mae: 0.0011\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3048e-06 - mae: 6.8537e-04 - val_loss: 6.2225e-09 - val_mae: 6.6575e-05\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.9439e-07 - mae: 4.2472e-04 - val_loss: 3.6909e-07 - val_mae: 6.0606e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.7363e-07 - mae: 5.3214e-04 - val_loss: 1.7489e-07 - val_mae: 4.1613e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0032e-07 - mae: 4.9451e-04 - val_loss: 8.2895e-07 - val_mae: 9.0954e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4107e-06 - mae: 7.0838e-04 - val_loss: 1.3156e-08 - val_mae: 1.0904e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.3913e-07 - mae: 4.6526e-04 - val_loss: 2.6973e-07 - val_mae: 5.1783e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4408e-06 - mae: 6.9190e-04 - val_loss: 5.3144e-07 - val_mae: 7.2797e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.4478e-07 - mae: 6.5084e-04 - val_loss: 1.1362e-07 - val_mae: 3.3491e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.1633e-07 - mae: 5.1793e-04 - val_loss: 2.5651e-09 - val_mae: 4.5686e-05\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.9454e-07 - mae: 5.6028e-04 - val_loss: 1.7504e-07 - val_mae: 4.1685e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0674e-06 - mae: 6.4259e-04 - val_loss: 4.0079e-08 - val_mae: 1.9706e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.4797e-07 - mae: 4.4407e-04 - val_loss: 8.2962e-07 - val_mae: 9.1021e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0150e-07 - mae: 5.7222e-04 - val_loss: 3.9493e-08 - val_mae: 1.9589e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.8856e-08 - mae: 1.9476e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: paty do alferes, Test Loss: 3.949297422423115e-08, Test MAE: 0.0001958940119948238\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 143ms/step\n",
      "Completed processing for city: paty do alferes\n",
      "\n",
      "Processing city: petrópolis\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 64ms/step - loss: 6.9280e-04 - mae: 0.0202 - val_loss: 2.4578e-04 - val_mae: 0.0117\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7571e-04 - mae: 0.0130 - val_loss: 1.3288e-04 - val_mae: 0.0087\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.9727e-04 - mae: 0.0107 - val_loss: 2.8701e-05 - val_mae: 0.0047\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.2783e-05 - mae: 0.0063 - val_loss: 1.0451e-05 - val_mae: 0.0026\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.0691e-05 - mae: 0.0052 - val_loss: 1.1949e-05 - val_mae: 0.0030\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4745e-05 - mae: 0.0038 - val_loss: 9.4376e-06 - val_mae: 0.0026\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8243e-05 - mae: 0.0031 - val_loss: 1.1815e-05 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5306e-05 - mae: 0.0026 - val_loss: 4.8467e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1977e-05 - mae: 0.0024 - val_loss: 3.1660e-06 - val_mae: 0.0016\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7.7879e-06 - mae: 0.0019 - val_loss: 2.4840e-06 - val_mae: 0.0014\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.5381e-06 - mae: 0.0016 - val_loss: 2.2367e-06 - val_mae: 0.0011\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.5188e-06 - mae: 0.0016 - val_loss: 1.1708e-06 - val_mae: 9.9485e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2048e-06 - mae: 0.0013 - val_loss: 3.9545e-06 - val_mae: 0.0018\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 3.8175e-06 - mae: 0.0012 - val_loss: 1.5783e-06 - val_mae: 0.0010\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6585e-06 - mae: 9.8042e-04 - val_loss: 1.1228e-06 - val_mae: 8.7164e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8098e-06 - mae: 9.9504e-04 - val_loss: 2.7718e-07 - val_mae: 3.9703e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0756e-06 - mae: 9.7026e-04 - val_loss: 7.6461e-07 - val_mae: 8.0565e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4440e-06 - mae: 9.4467e-04 - val_loss: 1.9260e-06 - val_mae: 0.0013\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2122e-06 - mae: 9.2762e-04 - val_loss: 8.9261e-07 - val_mae: 9.0171e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4954e-06 - mae: 7.6743e-04 - val_loss: 5.3537e-07 - val_mae: 6.9005e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.0594e-06 - mae: 8.3808e-04 - val_loss: 5.1913e-08 - val_mae: 1.5668e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.7079e-06 - mae: 8.5665e-04 - val_loss: 6.2938e-07 - val_mae: 7.7227e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.1612e-06 - mae: 9.2619e-04 - val_loss: 1.3296e-07 - val_mae: 3.4180e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1253e-06 - mae: 8.9610e-04 - val_loss: 6.9002e-08 - val_mae: 2.1960e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4972e-06 - mae: 6.7362e-04 - val_loss: 4.1804e-07 - val_mae: 6.2881e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5728e-06 - mae: 7.8592e-04 - val_loss: 2.3817e-07 - val_mae: 4.7003e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7681e-06 - mae: 8.5124e-04 - val_loss: 3.4433e-07 - val_mae: 5.6783e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.8608e-06 - mae: 8.3168e-04 - val_loss: 1.6982e-06 - val_mae: 0.0013\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6467e-06 - mae: 8.5782e-04 - val_loss: 5.5196e-07 - val_mae: 7.2815e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.4415e-06 - mae: 7.5177e-04 - val_loss: 4.2475e-08 - val_mae: 1.8366e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5357e-06 - mae: 7.6493e-04 - val_loss: 7.3518e-08 - val_mae: 2.5354e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1755e-06 - mae: 6.5447e-04 - val_loss: 6.6932e-07 - val_mae: 8.0479e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.1381e-06 - mae: 7.4738e-04 - val_loss: 5.9595e-08 - val_mae: 1.9481e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.8794e-07 - mae: 6.0341e-04 - val_loss: 7.1679e-07 - val_mae: 8.3375e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6195e-06 - mae: 7.7872e-04 - val_loss: 6.3620e-08 - val_mae: 2.0515e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.3645e-06 - mae: 6.7004e-04 - val_loss: 1.2999e-07 - val_mae: 3.2927e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2618e-06 - mae: 7.2322e-04 - val_loss: 1.0021e-07 - val_mae: 2.8044e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6709e-06 - mae: 6.8037e-04 - val_loss: 4.5143e-08 - val_mae: 1.9184e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 8.3722e-07 - mae: 5.6265e-04 - val_loss: 6.6042e-07 - val_mae: 7.9929e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6088e-06 - mae: 7.9352e-04 - val_loss: 1.1918e-06 - val_mae: 0.0011\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0428e-06 - mae: 6.8818e-04 - val_loss: 1.9963e-07 - val_mae: 4.2977e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1422e-06 - mae: 6.9762e-04 - val_loss: 3.6880e-08 - val_mae: 1.2660e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8102e-06 - mae: 7.1685e-04 - val_loss: 1.2255e-06 - val_mae: 0.0011\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.2561e-06 - mae: 7.0000e-04 - val_loss: 3.3759e-08 - val_mae: 1.2084e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0193e-06 - mae: 6.6074e-04 - val_loss: 2.9975e-07 - val_mae: 5.2751e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.3637e-06 - mae: 8.2031e-04 - val_loss: 5.8485e-07 - val_mae: 7.5059e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.2245e-06 - mae: 7.4042e-04 - val_loss: 1.0080e-06 - val_mae: 9.9326e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.1706e-06 - mae: 8.1037e-04 - val_loss: 1.7226e-07 - val_mae: 3.9882e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 9.1843e-07 - mae: 6.4295e-04 - val_loss: 7.7166e-07 - val_mae: 8.6615e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 9.2651e-07 - mae: 6.4717e-04 - val_loss: 1.3967e-06 - val_mae: 0.0012\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4586e-06 - mae: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: petrópolis, Test Loss: 1.396682819176931e-06, Test MAE: 0.0011727146338671446\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 177ms/step\n",
      "Completed processing for city: petrópolis\n",
      "\n",
      "Processing city: pinheiral\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 58ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 3.0853e-04 - val_mae: 0.0144\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1939e-04 - mae: 0.0164 - val_loss: 8.6989e-05 - val_mae: 0.0076\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6156e-04 - mae: 0.0126 - val_loss: 7.1222e-05 - val_mae: 0.0072\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.4591e-04 - mae: 0.0088 - val_loss: 4.4343e-05 - val_mae: 0.0053\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2927e-05 - mae: 0.0072 - val_loss: 1.5023e-05 - val_mae: 0.0033\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6482e-05 - mae: 0.0065 - val_loss: 1.2507e-05 - val_mae: 0.0029\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.2737e-05 - mae: 0.0056 - val_loss: 1.2965e-05 - val_mae: 0.0029\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7555e-05 - mae: 0.0048 - val_loss: 6.4771e-06 - val_mae: 0.0022\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.8906e-05 - mae: 0.0046 - val_loss: 6.1577e-06 - val_mae: 0.0019\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.4775e-05 - mae: 0.0038 - val_loss: 4.0025e-06 - val_mae: 0.0016\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.1001e-05 - mae: 0.0033 - val_loss: 3.7884e-06 - val_mae: 0.0014\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6571e-05 - mae: 0.0029 - val_loss: 2.3812e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5009e-05 - mae: 0.0026 - val_loss: 2.9322e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.6006e-06 - mae: 0.0021 - val_loss: 1.5833e-06 - val_mae: 0.0010\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.4764e-06 - mae: 0.0020 - val_loss: 1.3196e-06 - val_mae: 9.2855e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 7.7457e-06 - mae: 0.0018 - val_loss: 1.8408e-06 - val_mae: 0.0012\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.5159e-06 - mae: 0.0016 - val_loss: 1.0229e-06 - val_mae: 7.9131e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.5904e-06 - mae: 0.0013 - val_loss: 1.7167e-06 - val_mae: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4.0524e-06 - mae: 0.0014 - val_loss: 9.2700e-07 - val_mae: 7.3420e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2650e-06 - mae: 0.0015 - val_loss: 4.3741e-07 - val_mae: 5.7493e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8140e-06 - mae: 0.0012 - val_loss: 7.0810e-07 - val_mae: 6.6751e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.5903e-06 - mae: 0.0012 - val_loss: 1.2829e-06 - val_mae: 9.5859e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4245e-06 - mae: 0.0013 - val_loss: 5.2393e-07 - val_mae: 5.8468e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.7621e-06 - mae: 0.0011 - val_loss: 8.2639e-07 - val_mae: 7.1182e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3215e-06 - mae: 0.0010 - val_loss: 9.8895e-07 - val_mae: 8.5637e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1340e-06 - mae: 0.0010 - val_loss: 4.4664e-07 - val_mae: 5.1481e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 1.5165e-06 - mae: 8.5481e-04 - val_loss: 2.4017e-07 - val_mae: 4.4721e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7540e-06 - mae: 9.3192e-04 - val_loss: 2.9504e-07 - val_mae: 4.6251e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8439e-06 - mae: 8.8623e-04 - val_loss: 3.1281e-07 - val_mae: 4.7269e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4068e-06 - mae: 8.0847e-04 - val_loss: 3.7651e-07 - val_mae: 5.2193e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5240e-06 - mae: 8.2169e-04 - val_loss: 6.9441e-07 - val_mae: 7.2911e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 1.5071e-06 - mae: 9.7981e-04 - val_loss: 3.2246e-07 - val_mae: 4.0689e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.7922e-06 - mae: 8.4938e-04 - val_loss: 8.3681e-07 - val_mae: 8.3033e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.1563e-06 - mae: 9.1671e-04 - val_loss: 2.7732e-07 - val_mae: 3.6985e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0158e-06 - mae: 8.7968e-04 - val_loss: 1.2359e-06 - val_mae: 0.0011\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.5228e-06 - mae: 8.6800e-04 - val_loss: 1.9898e-07 - val_mae: 3.1519e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1428e-06 - mae: 7.0971e-04 - val_loss: 1.2234e-07 - val_mae: 2.8658e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 1.1794e-06 - mae: 7.1267e-04 - val_loss: 8.5871e-07 - val_mae: 8.7123e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4853e-06 - mae: 8.9708e-04 - val_loss: 4.7054e-07 - val_mae: 6.1630e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0054e-06 - mae: 6.6178e-04 - val_loss: 1.3018e-07 - val_mae: 2.5515e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0577e-06 - mae: 5.9730e-04 - val_loss: 2.0274e-07 - val_mae: 3.4634e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0882e-06 - mae: 7.5979e-04 - val_loss: 1.1351e-07 - val_mae: 3.0583e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4901e-06 - mae: 7.1168e-04 - val_loss: 3.1390e-07 - val_mae: 4.9901e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.2095e-07 - mae: 6.3089e-04 - val_loss: 1.2995e-06 - val_mae: 0.0011\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5656e-06 - mae: 8.0043e-04 - val_loss: 6.4312e-07 - val_mae: 7.6183e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.4261e-07 - mae: 6.0938e-04 - val_loss: 1.2466e-06 - val_mae: 0.0011\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.3047e-06 - mae: 7.7358e-04 - val_loss: 5.5823e-08 - val_mae: 2.0964e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 9.7513e-07 - mae: 6.1029e-04 - val_loss: 6.4541e-08 - val_mae: 1.7882e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 8.7976e-07 - mae: 5.6699e-04 - val_loss: 4.1664e-07 - val_mae: 6.0684e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0359e-06 - mae: 7.1370e-04 - val_loss: 5.4573e-07 - val_mae: 7.0822e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.4121e-07 - mae: 7.0350e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: pinheiral, Test Loss: 5.457270617625909e-07, Test MAE: 0.0007082224474288523\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 175ms/step\n",
      "Completed processing for city: pinheiral\n",
      "\n",
      "Processing city: piraí\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 55ms/step - loss: 4.7446e-04 - mae: 0.0162 - val_loss: 3.3016e-05 - val_mae: 0.0044\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.3757e-05 - mae: 0.0073 - val_loss: 1.9310e-05 - val_mae: 0.0038\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.9969e-05 - mae: 0.0050 - val_loss: 1.6207e-05 - val_mae: 0.0034\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.0410e-05 - mae: 0.0042 - val_loss: 5.7162e-06 - val_mae: 0.0018\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.6862e-05 - mae: 0.0038 - val_loss: 5.3806e-06 - val_mae: 0.0017\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8575e-05 - mae: 0.0034 - val_loss: 6.1791e-06 - val_mae: 0.0018\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.3519e-05 - mae: 0.0028 - val_loss: 3.3798e-06 - val_mae: 0.0014\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2374e-05 - mae: 0.0027 - val_loss: 3.4558e-06 - val_mae: 0.0013\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.0461e-05 - mae: 0.0025 - val_loss: 2.8472e-06 - val_mae: 0.0012\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.2204e-06 - mae: 0.0023 - val_loss: 2.2480e-06 - val_mae: 0.0012\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.2203e-06 - mae: 0.0019 - val_loss: 5.3161e-06 - val_mae: 0.0021\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8251e-06 - mae: 0.0020 - val_loss: 3.7971e-06 - val_mae: 0.0018\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.5587e-06 - mae: 0.0019 - val_loss: 2.2752e-06 - val_mae: 0.0014\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.8043e-06 - mae: 0.0018 - val_loss: 1.2998e-06 - val_mae: 9.0189e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.6307e-06 - mae: 0.0017 - val_loss: 1.7523e-06 - val_mae: 8.2455e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6364e-06 - mae: 0.0013 - val_loss: 3.4388e-06 - val_mae: 0.0017\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8271e-06 - mae: 0.0016 - val_loss: 9.3800e-07 - val_mae: 7.7087e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9530e-06 - mae: 0.0014 - val_loss: 8.0646e-07 - val_mae: 6.0921e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.9271e-06 - mae: 0.0014 - val_loss: 1.0279e-06 - val_mae: 9.6313e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.7340e-06 - mae: 0.0014 - val_loss: 1.1602e-06 - val_mae: 0.0010\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.3327e-06 - mae: 0.0012 - val_loss: 4.4347e-07 - val_mae: 4.5432e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5349e-06 - mae: 0.0011 - val_loss: 1.1434e-06 - val_mae: 0.0010\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8166e-06 - mae: 0.0011 - val_loss: 1.0576e-06 - val_mae: 9.6957e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.0959e-06 - mae: 9.9516e-04 - val_loss: 1.4182e-06 - val_mae: 0.0011\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6973e-06 - mae: 0.0011 - val_loss: 2.8696e-07 - val_mae: 4.4828e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 2.3493e-06 - mae: 0.0011 - val_loss: 2.2866e-07 - val_mae: 3.1112e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5161e-06 - mae: 0.0011 - val_loss: 3.8289e-07 - val_mae: 4.6772e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7686e-06 - mae: 0.0011 - val_loss: 1.6833e-07 - val_mae: 2.8593e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0685e-06 - mae: 9.8745e-04 - val_loss: 7.4996e-07 - val_mae: 8.1185e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.4083e-06 - mae: 0.0010 - val_loss: 8.5319e-07 - val_mae: 8.6785e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.0460e-06 - mae: 9.8084e-04 - val_loss: 3.5510e-07 - val_mae: 5.4707e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.5558e-06 - mae: 0.0010 - val_loss: 1.5833e-07 - val_mae: 2.6825e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6930e-06 - mae: 0.0011 - val_loss: 2.0958e-07 - val_mae: 3.4394e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.1776e-06 - mae: 9.4068e-04 - val_loss: 8.6587e-07 - val_mae: 8.7554e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6418e-06 - mae: 8.9112e-04 - val_loss: 1.0867e-07 - val_mae: 2.3329e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.6519e-06 - mae: 8.2305e-04 - val_loss: 1.4672e-06 - val_mae: 0.0012\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1138e-06 - mae: 9.5631e-04 - val_loss: 1.0380e-07 - val_mae: 2.3662e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6238e-06 - mae: 8.0685e-04 - val_loss: 1.3198e-07 - val_mae: 3.0529e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.2882e-06 - mae: 8.5159e-04 - val_loss: 1.4584e-07 - val_mae: 3.2711e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4453e-06 - mae: 9.0962e-04 - val_loss: 2.8359e-07 - val_mae: 4.8378e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.0616e-06 - mae: 9.1770e-04 - val_loss: 2.4961e-07 - val_mae: 4.1776e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1083e-06 - mae: 9.5670e-04 - val_loss: 8.9067e-07 - val_mae: 9.0591e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8186e-06 - mae: 8.6387e-04 - val_loss: 5.4293e-06 - val_mae: 0.0023\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1265e-06 - mae: 0.0010 - val_loss: 8.6090e-08 - val_mae: 2.4204e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6133e-06 - mae: 7.5678e-04 - val_loss: 1.5186e-07 - val_mae: 3.1846e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.2005e-06 - mae: 8.7219e-04 - val_loss: 5.3617e-07 - val_mae: 6.8742e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8988e-06 - mae: 9.7982e-04 - val_loss: 7.9098e-07 - val_mae: 8.5254e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 1.6882e-06 - mae: 8.6637e-04 - val_loss: 1.8480e-07 - val_mae: 3.5642e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2349e-06 - mae: 9.7475e-04 - val_loss: 8.0281e-07 - val_mae: 8.6208e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2960e-06 - mae: 9.9487e-04 - val_loss: 2.1430e-07 - val_mae: 3.9698e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2583e-07 - mae: 4.0602e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: piraí, Test Loss: 2.142973301033635e-07, Test MAE: 0.0003969798854086548\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 158ms/step\n",
      "Completed processing for city: piraí\n",
      "\n",
      "Processing city: porciúncula\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 61ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 1.8961e-04 - val_mae: 0.0112\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6479e-04 - mae: 0.0148 - val_loss: 8.8583e-05 - val_mae: 0.0079\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.3003e-04 - mae: 0.0118 - val_loss: 4.9276e-05 - val_mae: 0.0058\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.4104e-04 - mae: 0.0090 - val_loss: 2.3829e-05 - val_mae: 0.0043\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 9.5603e-05 - mae: 0.0075 - val_loss: 2.1154e-05 - val_mae: 0.0038\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.8365e-05 - mae: 0.0057 - val_loss: 1.0530e-05 - val_mae: 0.0029\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6516e-05 - mae: 0.0044 - val_loss: 5.6084e-06 - val_mae: 0.0022\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.2403e-05 - mae: 0.0032 - val_loss: 4.9766e-07 - val_mae: 6.4957e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.7654e-05 - mae: 0.0028 - val_loss: 1.7060e-06 - val_mae: 0.0013\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.2988e-05 - mae: 0.0024 - val_loss: 1.1003e-06 - val_mae: 0.0010\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.2000e-06 - mae: 0.0017 - val_loss: 5.7134e-06 - val_mae: 0.0024\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.4365e-06 - mae: 0.0018 - val_loss: 5.0069e-08 - val_mae: 1.4467e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.0845e-06 - mae: 0.0016 - val_loss: 1.9602e-06 - val_mae: 0.0014\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7186e-06 - mae: 0.0015 - val_loss: 6.4730e-08 - val_mae: 1.3443e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 5.1994e-06 - mae: 0.0014 - val_loss: 2.1043e-06 - val_mae: 0.0014\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 4.1584e-06 - mae: 0.0013 - val_loss: 1.0737e-06 - val_mae: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6574e-06 - mae: 0.0013 - val_loss: 7.5060e-07 - val_mae: 8.5802e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0360e-06 - mae: 0.0013 - val_loss: 4.7745e-08 - val_mae: 9.9951e-05\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.0207e-06 - mae: 0.0012 - val_loss: 6.5122e-07 - val_mae: 7.9781e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.8043e-06 - mae: 0.0014 - val_loss: 8.7137e-07 - val_mae: 9.2563e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.7508e-06 - mae: 0.0012 - val_loss: 5.4655e-08 - val_mae: 1.6329e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.7546e-06 - mae: 0.0012 - val_loss: 5.2985e-08 - val_mae: 1.5816e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9518e-06 - mae: 8.7914e-04 - val_loss: 1.3241e-07 - val_mae: 2.9585e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.1184e-06 - mae: 0.0011 - val_loss: 4.4885e-08 - val_mae: 1.1269e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6556e-06 - mae: 0.0010 - val_loss: 1.5172e-06 - val_mae: 0.0012\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6923e-06 - mae: 9.7643e-04 - val_loss: 6.2516e-07 - val_mae: 7.8122e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3070e-06 - mae: 0.0010 - val_loss: 9.8179e-08 - val_mae: 2.7250e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.5252e-06 - mae: 8.9249e-04 - val_loss: 2.0706e-06 - val_mae: 0.0014\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.1314e-06 - mae: 8.1574e-04 - val_loss: 1.5583e-07 - val_mae: 3.3309e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1702e-06 - mae: 0.0010 - val_loss: 6.1824e-08 - val_mae: 1.8681e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9991e-06 - mae: 9.0717e-04 - val_loss: 7.9607e-08 - val_mae: 2.3243e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.3616e-06 - mae: 9.0173e-04 - val_loss: 3.8805e-07 - val_mae: 5.8580e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.6885e-06 - mae: 0.0011 - val_loss: 3.2192e-07 - val_mae: 5.5294e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.6465e-06 - mae: 9.5774e-04 - val_loss: 5.3314e-07 - val_mae: 7.1948e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 3.0908e-06 - mae: 9.7802e-04 - val_loss: 6.9891e-08 - val_mae: 1.5814e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.7093e-06 - mae: 8.4081e-04 - val_loss: 1.9022e-07 - val_mae: 4.1363e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.4104e-06 - mae: 8.9969e-04 - val_loss: 4.3875e-07 - val_mae: 6.5013e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8210e-06 - mae: 7.0697e-04 - val_loss: 5.1166e-07 - val_mae: 6.8321e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.7137e-06 - mae: 0.0010 - val_loss: 1.0988e-07 - val_mae: 2.9449e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.9258e-06 - mae: 8.3736e-04 - val_loss: 2.3376e-07 - val_mae: 4.6486e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.8060e-06 - mae: 8.5002e-04 - val_loss: 5.3239e-08 - val_mae: 1.5897e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.5000e-06 - mae: 7.4137e-04 - val_loss: 4.7092e-08 - val_mae: 9.9553e-05\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6500e-06 - mae: 6.9513e-04 - val_loss: 3.2894e-07 - val_mae: 5.5930e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.8558e-06 - mae: 6.5495e-04 - val_loss: 4.7259e-08 - val_mae: 9.9588e-05\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6883e-06 - mae: 6.7942e-04 - val_loss: 2.3215e-07 - val_mae: 4.3275e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2427e-06 - mae: 9.8503e-04 - val_loss: 5.9706e-08 - val_mae: 1.8025e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.3345e-06 - mae: 9.0967e-04 - val_loss: 2.5798e-07 - val_mae: 4.9081e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.6462e-06 - mae: 8.8695e-04 - val_loss: 3.7673e-07 - val_mae: 6.0066e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7278e-06 - mae: 8.7242e-04 - val_loss: 1.9234e-07 - val_mae: 4.1629e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.0071e-06 - mae: 9.9585e-04 - val_loss: 1.9849e-06 - val_mae: 0.0014\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2.0185e-06 - mae: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: porciúncula, Test Loss: 1.9849185264320113e-06, Test MAE: 0.0013996962225064635\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 149ms/step\n",
      "Completed processing for city: porciúncula\n",
      "\n",
      "Processing city: porto real\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 48ms/step - loss: 6.3359e-04 - mae: 0.0184 - val_loss: 1.1442e-04 - val_mae: 0.0090\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.1587e-04 - mae: 0.0108 - val_loss: 3.8817e-05 - val_mae: 0.0049\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.0024e-04 - mae: 0.0077 - val_loss: 1.3198e-05 - val_mae: 0.0031\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 6.7133e-05 - mae: 0.0059 - val_loss: 8.4556e-06 - val_mae: 0.0026\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.2403e-05 - mae: 0.0044 - val_loss: 1.0390e-05 - val_mae: 0.0028\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.6575e-05 - mae: 0.0045 - val_loss: 5.1219e-06 - val_mae: 0.0020\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.7560e-05 - mae: 0.0039 - val_loss: 3.6455e-06 - val_mae: 0.0016\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6995e-05 - mae: 0.0030 - val_loss: 2.1432e-06 - val_mae: 0.0012\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.1471e-05 - mae: 0.0024 - val_loss: 5.7304e-07 - val_mae: 6.1996e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0610e-05 - mae: 0.0021 - val_loss: 2.9121e-07 - val_mae: 4.8103e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 8.7667e-06 - mae: 0.0017 - val_loss: 3.7652e-07 - val_mae: 5.9570e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 7.4799e-06 - mae: 0.0016 - val_loss: 4.0256e-08 - val_mae: 1.2610e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 8.8963e-06 - mae: 0.0016 - val_loss: 1.7946e-07 - val_mae: 3.9327e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.9880e-06 - mae: 0.0017 - val_loss: 4.7506e-08 - val_mae: 2.0815e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.5106e-06 - mae: 0.0013 - val_loss: 1.2921e-07 - val_mae: 3.4658e-04\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6899e-06 - mae: 0.0012 - val_loss: 2.4832e-08 - val_mae: 1.2236e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.2955e-06 - mae: 0.0012 - val_loss: 8.1971e-07 - val_mae: 8.9384e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.5510e-06 - mae: 0.0012 - val_loss: 2.3868e-08 - val_mae: 9.7066e-05\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.0090e-06 - mae: 0.0011 - val_loss: 1.5176e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.0067e-06 - mae: 0.0013 - val_loss: 2.5467e-08 - val_mae: 1.4169e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.1839e-06 - mae: 9.5922e-04 - val_loss: 2.0837e-07 - val_mae: 4.3872e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 5.9707e-06 - mae: 0.0011 - val_loss: 4.0763e-08 - val_mae: 1.7094e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7091e-06 - mae: 9.2032e-04 - val_loss: 1.6951e-07 - val_mae: 3.9539e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7009e-06 - mae: 9.4530e-04 - val_loss: 1.7815e-06 - val_mae: 0.0013\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.9181e-06 - mae: 0.0012 - val_loss: 4.9051e-08 - val_mae: 2.0796e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.8715e-06 - mae: 0.0010 - val_loss: 3.9537e-08 - val_mae: 1.7734e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 6.8169e-06 - mae: 0.0012 - val_loss: 4.3594e-08 - val_mae: 1.9629e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.3416e-06 - mae: 9.1763e-04 - val_loss: 7.1095e-08 - val_mae: 2.4398e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.7220e-06 - mae: 9.8198e-04 - val_loss: 1.3390e-08 - val_mae: 5.5986e-05\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 4.5974e-06 - mae: 9.0698e-04 - val_loss: 3.8018e-08 - val_mae: 1.6814e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 2.6413e-06 - mae: 7.2622e-04 - val_loss: 2.0473e-06 - val_mae: 0.0014\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 4.9612e-06 - mae: 0.0012 - val_loss: 2.6873e-06 - val_mae: 0.0016\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 3.7636e-06 - mae: 0.0010 - val_loss: 2.3689e-07 - val_mae: 4.7429e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.4411e-06 - mae: 9.8903e-04 - val_loss: 1.6368e-08 - val_mae: 1.0362e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.1831e-06 - mae: 8.2038e-04 - val_loss: 8.6313e-07 - val_mae: 9.2274e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.8034e-06 - mae: 8.9431e-04 - val_loss: 9.4368e-07 - val_mae: 9.6547e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.0924e-06 - mae: 0.0011 - val_loss: 1.8540e-08 - val_mae: 1.0803e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7277e-06 - mae: 8.8417e-04 - val_loss: 1.7304e-07 - val_mae: 4.0201e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.7762e-06 - mae: 9.1155e-04 - val_loss: 1.0660e-06 - val_mae: 0.0010\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.7420e-06 - mae: 9.4746e-04 - val_loss: 2.0999e-06 - val_mae: 0.0014\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.5695e-06 - mae: 0.0010 - val_loss: 1.1569e-06 - val_mae: 0.0011\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.7845e-06 - mae: 9.2012e-04 - val_loss: 2.3741e-08 - val_mae: 1.3015e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 3.2174e-06 - mae: 8.3214e-04 - val_loss: 1.1108e-08 - val_mae: 5.1023e-05\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8130e-06 - mae: 5.7780e-04 - val_loss: 3.2092e-06 - val_mae: 0.0018\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 5.6845e-06 - mae: 0.0013 - val_loss: 1.3394e-07 - val_mae: 3.4923e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4.6263e-06 - mae: 9.9268e-04 - val_loss: 7.5552e-08 - val_mae: 2.5959e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.3885e-06 - mae: 9.0008e-04 - val_loss: 1.5158e-06 - val_mae: 0.0012\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.5436e-06 - mae: 0.0010 - val_loss: 1.3238e-06 - val_mae: 0.0011\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3935e-06 - mae: 9.5847e-04 - val_loss: 1.1000e-08 - val_mae: 4.7967e-05\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.5523e-06 - mae: 9.6654e-04 - val_loss: 5.1260e-08 - val_mae: 2.0869e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.7409e-08 - mae: 1.9900e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: porto real, Test Loss: 5.125985680365375e-08, Test MAE: 0.00020869314903393388\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 118ms/step\n",
      "Completed processing for city: porto real\n",
      "\n",
      "Processing city: quatis\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 36ms/step - loss: 4.4120e-04 - mae: 0.0168 - val_loss: 6.4266e-05 - val_mae: 0.0067\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4902e-04 - mae: 0.0095 - val_loss: 3.3142e-05 - val_mae: 0.0050\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1098e-04 - mae: 0.0082 - val_loss: 2.6917e-05 - val_mae: 0.0045\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.5894e-05 - mae: 0.0069 - val_loss: 4.0279e-05 - val_mae: 0.0058\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5263e-05 - mae: 0.0070 - val_loss: 1.1861e-05 - val_mae: 0.0030\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2627e-05 - mae: 0.0052 - val_loss: 3.5338e-06 - val_mae: 0.0016\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.8136e-05 - mae: 0.0048 - val_loss: 9.9810e-06 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.0049e-05 - mae: 0.0043 - val_loss: 6.6807e-06 - val_mae: 0.0022\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.2599e-05 - mae: 0.0038 - val_loss: 7.1730e-06 - val_mae: 0.0023\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8180e-05 - mae: 0.0036 - val_loss: 2.7195e-06 - val_mae: 0.0013\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6184e-05 - mae: 0.0031 - val_loss: 2.2654e-06 - val_mae: 0.0013\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1002e-05 - mae: 0.0025 - val_loss: 2.1982e-06 - val_mae: 0.0013\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3392e-05 - mae: 0.0027 - val_loss: 2.9140e-06 - val_mae: 0.0015\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.4490e-06 - mae: 0.0023 - val_loss: 2.9510e-06 - val_mae: 0.0015\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.1552e-06 - mae: 0.0022 - val_loss: 2.2261e-06 - val_mae: 0.0013\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.7566e-06 - mae: 0.0019 - val_loss: 1.7703e-06 - val_mae: 0.0011\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.5577e-06 - mae: 0.0018 - val_loss: 2.0970e-06 - val_mae: 0.0012\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.1200e-06 - mae: 0.0018 - val_loss: 1.5455e-06 - val_mae: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.8498e-06 - mae: 0.0017 - val_loss: 1.0657e-06 - val_mae: 8.8217e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5469e-06 - mae: 0.0016 - val_loss: 1.2010e-06 - val_mae: 9.2132e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6916e-06 - mae: 0.0015 - val_loss: 1.4506e-06 - val_mae: 9.7788e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1188e-06 - mae: 0.0012 - val_loss: 1.1087e-06 - val_mae: 8.7371e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4672e-06 - mae: 0.0015 - val_loss: 1.1850e-06 - val_mae: 8.7382e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6407e-06 - mae: 0.0014 - val_loss: 1.3165e-06 - val_mae: 9.2875e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.6351e-06 - mae: 0.0012 - val_loss: 6.3078e-07 - val_mae: 6.8983e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9035e-06 - mae: 0.0014 - val_loss: 9.6617e-07 - val_mae: 8.0613e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.0062e-06 - mae: 0.0013 - val_loss: 2.5857e-06 - val_mae: 0.0015\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5783e-06 - mae: 0.0011 - val_loss: 3.5577e-07 - val_mae: 5.2830e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.9885e-06 - mae: 9.9094e-04 - val_loss: 3.3042e-07 - val_mae: 5.1503e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.5908e-06 - mae: 0.0012 - val_loss: 4.9499e-07 - val_mae: 5.9527e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.8069e-06 - mae: 0.0011 - val_loss: 3.5692e-07 - val_mae: 4.8218e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5016e-06 - mae: 9.8210e-04 - val_loss: 3.9574e-07 - val_mae: 5.3248e-04\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.8089e-06 - mae: 0.0011 - val_loss: 2.3187e-07 - val_mae: 4.3361e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.4337e-06 - mae: 0.0012 - val_loss: 6.0818e-07 - val_mae: 6.4240e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7985e-06 - mae: 9.8908e-04 - val_loss: 2.7495e-07 - val_mae: 4.1124e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6229e-06 - mae: 8.9199e-04 - val_loss: 2.0405e-07 - val_mae: 3.8368e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8786e-06 - mae: 8.5907e-04 - val_loss: 1.2247e-06 - val_mae: 0.0010\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3268e-06 - mae: 9.7370e-04 - val_loss: 1.6480e-07 - val_mae: 3.5814e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7533e-06 - mae: 8.7696e-04 - val_loss: 3.3013e-07 - val_mae: 4.3687e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.5161e-06 - mae: 0.0010 - val_loss: 1.5996e-07 - val_mae: 3.5541e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7671e-06 - mae: 7.2972e-04 - val_loss: 1.5722e-06 - val_mae: 0.0012\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7682e-06 - mae: 0.0010 - val_loss: 5.2115e-07 - val_mae: 6.1179e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6216e-06 - mae: 7.2248e-04 - val_loss: 1.1477e-06 - val_mae: 0.0010\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.3317e-06 - mae: 0.0010 - val_loss: 3.6158e-07 - val_mae: 4.8223e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4223e-06 - mae: 7.9509e-04 - val_loss: 1.7310e-07 - val_mae: 3.5467e-04\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.7802e-06 - mae: 7.3426e-04 - val_loss: 1.2157e-06 - val_mae: 0.0010\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.8483e-06 - mae: 9.8669e-04 - val_loss: 3.4485e-07 - val_mae: 4.8777e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.3900e-06 - mae: 7.7573e-04 - val_loss: 2.5020e-07 - val_mae: 3.9615e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.5920e-06 - mae: 8.7361e-04 - val_loss: 3.0852e-07 - val_mae: 4.7520e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7608e-06 - mae: 9.4197e-04 - val_loss: 1.7632e-07 - val_mae: 3.2901e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4895e-07 - mae: 2.9235e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: quatis, Test Loss: 1.7632427784519678e-07, Test MAE: 0.0003290139138698578\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 97ms/step\n",
      "Completed processing for city: quatis\n",
      "\n",
      "Processing city: queimados\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - loss: 6.7999e-04 - mae: 0.0207 - val_loss: 3.3399e-05 - val_mae: 0.0050\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3199e-04 - mae: 0.0119 - val_loss: 5.1392e-05 - val_mae: 0.0062\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3119e-04 - mae: 0.0089 - val_loss: 6.2859e-05 - val_mae: 0.0071\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0321e-04 - mae: 0.0077 - val_loss: 2.2941e-05 - val_mae: 0.0040\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.4065e-05 - mae: 0.0056 - val_loss: 2.8495e-05 - val_mae: 0.0041\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.3286e-05 - mae: 0.0050 - val_loss: 1.6799e-05 - val_mae: 0.0035\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 3.0616e-05 - mae: 0.0041 - val_loss: 1.1512e-05 - val_mae: 0.0028\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4520e-05 - mae: 0.0036 - val_loss: 1.4491e-05 - val_mae: 0.0035\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.6970e-05 - mae: 0.0031 - val_loss: 5.0214e-06 - val_mae: 0.0020\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1.0820e-05 - mae: 0.0025 - val_loss: 8.5840e-06 - val_mae: 0.0028\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.1387e-05 - mae: 0.0025 - val_loss: 3.3636e-06 - val_mae: 0.0017\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.8306e-06 - mae: 0.0021 - val_loss: 2.2970e-07 - val_mae: 3.8900e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.7903e-06 - mae: 0.0021 - val_loss: 3.9998e-07 - val_mae: 5.8952e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.1665e-06 - mae: 0.0018 - val_loss: 1.4046e-07 - val_mae: 3.3906e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 5.6018e-06 - mae: 0.0017 - val_loss: 3.1373e-06 - val_mae: 0.0018\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.3543e-06 - mae: 0.0018 - val_loss: 1.3772e-07 - val_mae: 3.4823e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.4635e-06 - mae: 0.0015 - val_loss: 2.3922e-06 - val_mae: 0.0015\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.9782e-06 - mae: 0.0016 - val_loss: 3.7785e-06 - val_mae: 0.0019\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.0429e-06 - mae: 0.0012 - val_loss: 7.3783e-07 - val_mae: 8.5369e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.9996e-06 - mae: 0.0014 - val_loss: 3.1985e-07 - val_mae: 5.6026e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1457e-06 - mae: 0.0010 - val_loss: 7.1754e-07 - val_mae: 8.4415e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6777e-06 - mae: 0.0011 - val_loss: 2.1704e-08 - val_mae: 1.3411e-04\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7367e-06 - mae: 0.0011 - val_loss: 8.2253e-09 - val_mae: 7.4228e-05\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.4632e-06 - mae: 0.0011 - val_loss: 8.6573e-07 - val_mae: 9.2882e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 2.5360e-06 - mae: 0.0010 - val_loss: 6.7064e-07 - val_mae: 8.1718e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.9126e-06 - mae: 9.6925e-04 - val_loss: 7.0160e-07 - val_mae: 8.3629e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.3656e-06 - mae: 0.0010 - val_loss: 2.0457e-07 - val_mae: 4.5045e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6000e-06 - mae: 8.5210e-04 - val_loss: 9.3411e-09 - val_mae: 9.1195e-05\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6482e-06 - mae: 8.7418e-04 - val_loss: 2.2653e-08 - val_mae: 1.4667e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5664e-06 - mae: 7.1193e-04 - val_loss: 9.3943e-07 - val_mae: 9.6863e-04\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5322e-06 - mae: 8.6861e-04 - val_loss: 8.2791e-07 - val_mae: 9.0923e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5362e-06 - mae: 8.5449e-04 - val_loss: 1.3267e-06 - val_mae: 0.0012\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5397e-06 - mae: 8.9198e-04 - val_loss: 6.5936e-07 - val_mae: 8.1134e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.8236e-07 - mae: 6.4364e-04 - val_loss: 9.6007e-08 - val_mae: 3.0815e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2605e-06 - mae: 7.1597e-04 - val_loss: 7.4140e-07 - val_mae: 8.6039e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1030e-06 - mae: 7.0031e-04 - val_loss: 2.7390e-07 - val_mae: 5.2236e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 1.1124e-06 - mae: 6.9807e-04 - val_loss: 4.0699e-08 - val_mae: 1.9911e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5142e-06 - mae: 8.5130e-04 - val_loss: 1.0446e-07 - val_mae: 3.2160e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4463e-06 - mae: 6.6032e-04 - val_loss: 9.1672e-08 - val_mae: 3.0105e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1565e-06 - mae: 6.1892e-04 - val_loss: 8.2550e-08 - val_mae: 2.8556e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.5733e-06 - mae: 7.6272e-04 - val_loss: 1.1650e-07 - val_mae: 3.3985e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 8.9995e-07 - mae: 6.0253e-04 - val_loss: 7.0891e-07 - val_mae: 8.4137e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1816e-06 - mae: 6.6512e-04 - val_loss: 5.6973e-07 - val_mae: 7.5415e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.4576e-07 - mae: 6.2928e-04 - val_loss: 4.7800e-08 - val_mae: 2.1633e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.4223e-06 - mae: 7.3241e-04 - val_loss: 4.9086e-09 - val_mae: 6.5049e-05\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.6303e-07 - mae: 5.6215e-04 - val_loss: 2.8968e-07 - val_mae: 5.3729e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.6144e-07 - mae: 5.3321e-04 - val_loss: 6.1660e-09 - val_mae: 7.1880e-05\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0712e-06 - mae: 6.5421e-04 - val_loss: 8.4025e-07 - val_mae: 9.1611e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 9.1156e-07 - mae: 6.7728e-04 - val_loss: 8.5060e-08 - val_mae: 2.8993e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.0233e-06 - mae: 6.1701e-04 - val_loss: 8.6739e-08 - val_mae: 2.9280e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.6003e-08 - mae: 2.9166e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: queimados, Test Loss: 8.673922025081993e-08, Test MAE: 0.0002927991736214608\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 153ms/step\n",
      "Completed processing for city: queimados\n",
      "\n",
      "Processing city: quissamã\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 42ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 1.3967e-04 - val_mae: 0.0095\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9423e-04 - mae: 0.0109 - val_loss: 9.1892e-05 - val_mae: 0.0072\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3174e-04 - mae: 0.0089 - val_loss: 5.4219e-05 - val_mae: 0.0057\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.1427e-05 - mae: 0.0059 - val_loss: 1.9097e-05 - val_mae: 0.0037\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.6940e-05 - mae: 0.0050 - val_loss: 6.7511e-06 - val_mae: 0.0022\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3968e-05 - mae: 0.0041 - val_loss: 1.0901e-05 - val_mae: 0.0027\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.0619e-05 - mae: 0.0031 - val_loss: 7.5565e-06 - val_mae: 0.0023\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.2034e-05 - mae: 0.0024 - val_loss: 4.5374e-06 - val_mae: 0.0019\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.3780e-06 - mae: 0.0021 - val_loss: 3.2371e-06 - val_mae: 0.0016\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.2591e-06 - mae: 0.0017 - val_loss: 2.2931e-06 - val_mae: 0.0014\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.6710e-06 - mae: 0.0015 - val_loss: 1.6644e-06 - val_mae: 0.0012\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.1846e-06 - mae: 0.0016 - val_loss: 1.4174e-06 - val_mae: 0.0011\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.2097e-06 - mae: 0.0013 - val_loss: 1.8015e-06 - val_mae: 0.0011\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1434e-06 - mae: 0.0012 - val_loss: 1.6629e-06 - val_mae: 0.0010\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2843e-06 - mae: 0.0011 - val_loss: 1.8712e-06 - val_mae: 0.0011\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.7478e-06 - mae: 0.0011 - val_loss: 1.2626e-06 - val_mae: 8.7743e-04\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6083e-06 - mae: 9.1569e-04 - val_loss: 1.1726e-06 - val_mae: 9.0107e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.6179e-06 - mae: 0.0010 - val_loss: 3.2886e-07 - val_mae: 5.0957e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0500e-06 - mae: 7.3707e-04 - val_loss: 1.7570e-06 - val_mae: 0.0012\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9778e-06 - mae: 8.6204e-04 - val_loss: 9.0828e-07 - val_mae: 8.2576e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1968e-06 - mae: 8.7661e-04 - val_loss: 9.0507e-07 - val_mae: 8.3493e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.1195e-06 - mae: 6.0428e-04 - val_loss: 3.9160e-06 - val_mae: 0.0019\n",
      "Epoch 23/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.6371e-06 - mae: 8.4387e-04 - val_loss: 3.5688e-07 - val_mae: 4.9554e-04\n",
      "Epoch 24/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.5971e-06 - mae: 7.9040e-04 - val_loss: 8.6629e-07 - val_mae: 8.4875e-04\n",
      "Epoch 25/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0810e-06 - mae: 6.8409e-04 - val_loss: 1.5848e-07 - val_mae: 3.3325e-04\n",
      "Epoch 26/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9.7766e-07 - mae: 5.8718e-04 - val_loss: 1.3447e-07 - val_mae: 3.0900e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3675e-06 - mae: 7.3105e-04 - val_loss: 1.5305e-07 - val_mae: 3.0615e-04\n",
      "Epoch 28/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0235e-06 - mae: 5.4817e-04 - val_loss: 4.2974e-07 - val_mae: 5.9529e-04\n",
      "Epoch 29/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6985e-06 - mae: 6.7374e-04 - val_loss: 2.6236e-07 - val_mae: 4.5758e-04\n",
      "Epoch 30/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0100e-06 - mae: 5.8396e-04 - val_loss: 1.4666e-06 - val_mae: 0.0012\n",
      "Epoch 31/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.1137e-06 - mae: 6.8277e-04 - val_loss: 1.0695e-07 - val_mae: 2.4073e-04\n",
      "Epoch 32/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.6732e-07 - mae: 4.2839e-04 - val_loss: 3.1937e-06 - val_mae: 0.0018\n",
      "Epoch 33/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.3048e-06 - mae: 7.6813e-04 - val_loss: 1.1946e-07 - val_mae: 2.4313e-04\n",
      "Epoch 34/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7946e-07 - mae: 5.0863e-04 - val_loss: 9.2435e-08 - val_mae: 2.2117e-04\n",
      "Epoch 35/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.5205e-07 - mae: 5.7849e-04 - val_loss: 2.6380e-07 - val_mae: 4.1403e-04\n",
      "Epoch 36/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2060e-06 - mae: 6.7269e-04 - val_loss: 3.1667e-07 - val_mae: 5.2569e-04\n",
      "Epoch 37/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1467e-07 - mae: 5.1013e-04 - val_loss: 1.3351e-07 - val_mae: 3.2429e-04\n",
      "Epoch 38/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.0111e-06 - mae: 5.0232e-04 - val_loss: 9.3821e-08 - val_mae: 2.4311e-04\n",
      "Epoch 39/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.4630e-07 - mae: 5.2226e-04 - val_loss: 2.8957e-07 - val_mae: 4.4779e-04\n",
      "Epoch 40/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.2877e-07 - mae: 4.5271e-04 - val_loss: 4.7513e-07 - val_mae: 6.2099e-04\n",
      "Epoch 41/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.3557e-07 - mae: 5.2396e-04 - val_loss: 3.0040e-07 - val_mae: 4.5778e-04\n",
      "Epoch 42/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7817e-07 - mae: 6.3400e-04 - val_loss: 9.9106e-08 - val_mae: 2.1085e-04\n",
      "Epoch 43/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.6845e-07 - mae: 3.9878e-04 - val_loss: 9.2937e-08 - val_mae: 2.0264e-04\n",
      "Epoch 44/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.4177e-07 - mae: 3.9906e-04 - val_loss: 6.9606e-07 - val_mae: 7.7932e-04\n",
      "Epoch 45/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 4.1738e-07 - mae: 5.0883e-04 - val_loss: 1.5464e-06 - val_mae: 0.0012\n",
      "Epoch 46/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.7745e-07 - mae: 7.0293e-04 - val_loss: 1.9134e-07 - val_mae: 3.2454e-04\n",
      "Epoch 47/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 9.2192e-07 - mae: 4.1292e-04 - val_loss: 7.9019e-07 - val_mae: 8.5530e-04\n",
      "Epoch 48/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 9.7561e-07 - mae: 6.3572e-04 - val_loss: 2.8899e-07 - val_mae: 4.4887e-04\n",
      "Epoch 49/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 9.0704e-07 - mae: 7.1462e-04 - val_loss: 2.0049e-07 - val_mae: 4.1590e-04\n",
      "Epoch 50/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.2468e-07 - mae: 3.5491e-04 - val_loss: 8.6852e-08 - val_mae: 2.0972e-04\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4161e-08 - mae: 1.8804e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: quissamã, Test Loss: 8.685177732559168e-08, Test MAE: 0.00020971526100765914\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 110ms/step\n",
      "Completed processing for city: quissamã\n",
      "\n",
      "Processing city: resende\n",
      "Epoch 1/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 1.1455e-04 - val_mae: 0.0079\n",
      "Epoch 2/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5223e-04 - mae: 0.0115 - val_loss: 1.2008e-04 - val_mae: 0.0090\n",
      "Epoch 3/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5582e-04 - mae: 0.0088 - val_loss: 4.2822e-05 - val_mae: 0.0054\n",
      "Epoch 4/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6739e-04 - mae: 0.0083 - val_loss: 3.4439e-05 - val_mae: 0.0046\n",
      "Epoch 5/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3017e-04 - mae: 0.0071 - val_loss: 2.8331e-05 - val_mae: 0.0037\n",
      "Epoch 6/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0238e-04 - mae: 0.0057 - val_loss: 1.5244e-05 - val_mae: 0.0028\n",
      "Epoch 7/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.3969e-05 - mae: 0.0054 - val_loss: 1.0198e-05 - val_mae: 0.0029\n",
      "Epoch 8/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0041e-04 - mae: 0.0057 - val_loss: 3.0503e-06 - val_mae: 0.0014\n",
      "Epoch 9/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2208e-05 - mae: 0.0052 - val_loss: 5.8240e-06 - val_mae: 0.0021\n",
      "Epoch 10/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1852e-05 - mae: 0.0044 - val_loss: 1.5727e-06 - val_mae: 0.0011\n",
      "Epoch 11/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.4285e-05 - mae: 0.0046 - val_loss: 1.7671e-06 - val_mae: 0.0010\n",
      "Epoch 12/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.8311e-05 - mae: 0.0049 - val_loss: 1.4888e-06 - val_mae: 9.9875e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.8515e-05 - mae: 0.0037 - val_loss: 1.7431e-06 - val_mae: 0.0011\n",
      "Epoch 14/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.7116e-05 - mae: 0.0044 - val_loss: 4.3250e-06 - val_mae: 0.0018\n",
      "Epoch 15/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2690e-05 - mae: 0.0043 - val_loss: 4.6445e-06 - val_mae: 0.0019\n",
      "Epoch 16/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.1403e-05 - mae: 0.0037 - val_loss: 1.7010e-06 - val_mae: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.6919e-05 - mae: 0.0043 - val_loss: 3.4199e-06 - val_mae: 0.0016\n",
      "Epoch 18/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.2777e-05 - mae: 0.0041 - val_loss: 4.0245e-06 - val_mae: 0.0017\n",
      "Epoch 19/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.2349e-05 - mae: 0.0038 - val_loss: 1.3300e-06 - val_mae: 9.6545e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.2233e-05 - mae: 0.0043 - val_loss: 1.1375e-06 - val_mae: 8.2751e-04\n",
      "Epoch 21/50\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.2174e-05 - mae: 0.0036 - val_loss: 1.2907e-06 - val_mae: 9.3066e-04\n",
      "Epoch 22/50\n",
      "\u001B[1m12/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 8.7944e-05 - mae: 0.0045 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 38\u001B[0m\n\u001B[0;32m     35\u001B[0m model \u001B[38;5;241m=\u001B[39m build_lstm_model(input_shape)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train_city\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_city\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test_city\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_city\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m     44\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m     47\u001B[0m test_loss, test_mae \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(X_test_city, y_test_city)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[0;32m    370\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 371\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    372\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:222\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mhas_value():\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopt_outputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    224\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m step, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\n\u001B[0;32m    225\u001B[0m         \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_execution), iterator\n\u001B[0;32m    226\u001B[0m     ):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:186\u001B[0m, in \u001B[0;36m_OptionalImpl.get_value\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptionalGetValue\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    184\u001B[0m                     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor]) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[0;32m    185\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 186\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_optional_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptional_get_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variant_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscope\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_flat_tensor_types\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_element_spec\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_flat_tensor_shapes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_element_spec\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    192\u001B[0m   \u001B[38;5;66;03m# NOTE: We do not colocate the deserialization of composite tensors\u001B[39;00m\n\u001B[0;32m    193\u001B[0m   \u001B[38;5;66;03m# because not all ops are guaranteed to have non-GPU kernels.\u001B[39;00m\n\u001B[0;32m    194\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m structure\u001B[38;5;241m.\u001B[39mfrom_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec, result)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:95\u001B[0m, in \u001B[0;36moptional_get_value\u001B[1;34m(optional, output_types, output_shapes, name)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m     94\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 95\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOptionalGetValue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m     99\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:55:38.207256Z",
     "start_time": "2025-02-15T13:55:38.206257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot Actual vs Predicted and calculate RMSE\n",
    "def plot_actual_vs_predicted(city, y_test_city, predictions_city, target_scaler):\n",
    "    # Ensure to only pass the target variable (numeric values) to the scaler\n",
    "    y_test_values = y_test_city['cases'].values  # Assuming 'cases' is the target column\n",
    "    predictions_original_scale = target_scaler.inverse_transform(predictions_city)\n",
    "    actual_values_original_scale = target_scaler.inverse_transform(y_test_values.reshape(-1, 1))  # Reshape for scaling\n",
    "\n",
    "    # Ensure both predictions and actual values have the same length\n",
    "    min_length = min(len(actual_values_original_scale), len(predictions_original_scale))\n",
    "\n",
    "    actual_values_original_scale = actual_values_original_scale[:min_length].flatten()\n",
    "    predictions_original_scale = predictions_original_scale[:min_length].flatten()\n",
    "    predictions_original_scale[predictions_original_scale < 0] = 0\n",
    "\n",
    "    time_index = np.arange(min_length)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"City: {city} - Actual Values Shape:\", actual_values_original_scale.shape)\n",
    "    print(f\"City: {city} - Predicted Values Shape:\", predictions_original_scale.shape)\n",
    "\n",
    "    # Plot Actual vs Predicted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_index, actual_values_original_scale, label=\"Actual Values\", color='blue', linewidth=2)\n",
    "    plt.plot(time_index, predictions_original_scale, label=\"Predicted Values\", color='orange', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"Time (Sequential Index)\")\n",
    "    plt.ylabel(\"Cases per 100k (Original Scale)\")\n",
    "    plt.title(f\"{city} - Actual vs Predicted Cases per 100k Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(actual_values_original_scale, predictions_original_scale))\n",
    "    print(f\"City: {city} - RMSE: {rmse}\")\n",
    "\n",
    "# Loop through each city's predictions and plot\n",
    "for city in city_predictions.keys():\n",
    "    predictions_city = city_predictions[city]\n",
    "    y_test_city = city_groups_ytest.get_group(city)\n",
    "\n",
    "    # Call the function to plot and calculate RMSE\n",
    "    plot_actual_vs_predicted(city, y_test_city, predictions_city, target_scaler)"
   ],
   "id": "91b6fdb072ccfffb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
