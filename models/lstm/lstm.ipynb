{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c906af0ea434f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T10:33:02.570192Z",
     "start_time": "2025-01-08T10:33:02.079634Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                    0\n",
       "week                                    0\n",
       "cases                                   0\n",
       "population                              0\n",
       "tempe_min                               0\n",
       "humidity_max                            0\n",
       "humidity_avg                            0\n",
       "humidity_min                            0\n",
       "temp_avg                                0\n",
       "temp_max                                0\n",
       "city                                    0\n",
       "geocode                                 0\n",
       "vim                                     0\n",
       "vim_monthly                             0\n",
       "precipitation_avg_ordinary_kriging      0\n",
       "precipitation_max_ordinary_kriging      0\n",
       "precipitation_avg_regression_kriging    0\n",
       "precipitation_max_regression_kriging    0\n",
       "long                                    0\n",
       "lat                                     0\n",
       "cases_per_100k                          0\n",
       "nearby_cases_weighted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = pd.read_csv('data/filtered_RJ_lat_long_data.csv')\n",
    "final = pd.read_csv('data/final_combined_dataset.csv')\n",
    "\n",
    "final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f93880cf7262c66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T10:33:28.203166Z",
     "start_time": "2025-01-08T10:33:28.080173Z"
    }
   },
   "outputs": [],
   "source": [
    "geo['CITY_lower'] = geo['CITY'].str.lower()\n",
    "final['city_lower'] = final['city'].str.lower()\n",
    "\n",
    "# Merge datasets using the lowercase city columns\n",
    "final = pd.merge(final, geo[['CITY_lower', 'LONG', 'LAT']], left_on='city_lower', right_on='CITY_lower', how='left')\n",
    "\n",
    "final = final.drop(columns=['CITY_lower', 'city_lower'])\n",
    "\n",
    "# rename \n",
    "final = final.rename(columns={'LONG': 'long', 'LAT': 'lat'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d855728cd67e54",
   "metadata": {},
   "source": [
    "Spatial Aggregation: Create additional features that represent the cases of nearby cities.\n",
    "For example:\n",
    "Average cases of neighboring cities.\n",
    "\n",
    "nearby_cases_weighted: Weighted average of cases in the 3 nearest cities for the same week.\n",
    "\n",
    "here we will consider cases_per_100k as cases. Because we want to consider the population of the city in the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3062319f68a5a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T10:33:45.763197Z",
     "start_time": "2025-01-08T10:33:44.780007Z"
    }
   },
   "outputs": [],
   "source": [
    "final.to_csv('data/final_combined_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b95eaa3444be1960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T10:42:39.965997Z",
     "start_time": "2025-01-08T10:35:13.183713Z"
    }
   },
   "outputs": [],
   "source": [
    "# First part: Weeks from 201201 to 201701\n",
    "first_part_weeks = list(range(201201, 201701))\n",
    "\n",
    "# Update for the first part\n",
    "first_part_data = data[data['week'].isin(first_part_weeks)]\n",
    "nearby_weighted_cases_first_part = []\n",
    "\n",
    "for week in first_part_data['week'].unique():\n",
    "    weekly_data = first_part_data[first_part_data['week'] == week]\n",
    "    print(f'Processing week {week}')\n",
    "    for _, row in weekly_data.iterrows():\n",
    "        weighted_cases = calculate_weighted_cases(row, weekly_data)\n",
    "        nearby_weighted_cases_first_part.append(weighted_cases)\n",
    "\n",
    "data.loc[data['week'].isin(first_part_weeks), 'nearby_cases_weighted'] = nearby_weighted_cases_first_part\n",
    "\n",
    "# Save the updated data back to CSV\n",
    "data.to_csv('data/final_combined_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf381d5306ba7d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T10:47:25.520513Z",
     "start_time": "2025-01-08T10:47:25.484460Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa4ca82526ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
